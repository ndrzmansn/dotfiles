{"mode":"editor","version":1,"windowDimensions":{"x":1920,"y":22,"width":1920,"height":1058,"maximized":true},"syntax":{"deserializer":"Syntax","grammarOverridesByPath":{}},"project":{"path":"/Users/zwei/Workspace/oracle/fastr-svm-home","buffers":[{"text":"# The format of this file is described in the documentation for my.py.\nmxversion=1.0\nsuite=graal\n\njrelibrary@JFR@jar=jfr.jar\n\nlibrary@JUNIT@path=lib/junit-4.11.jar\nlibrary@JUNIT@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/junit-4.11.jar,http://repo1.maven.org/maven2/junit/junit/4.11/junit-4.11.jar\nlibrary@JUNIT@sha1=4e031bb61df09069aeb2bffb4019e7a5034a4ee0\nlibrary@JUNIT@eclipse.container=org.eclipse.jdt.junit.JUNIT_CONTAINER/4\nlibrary@JUNIT@sourcePath=lib/junit-4.11-sources.jar\nlibrary@JUNIT@sourceUrls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/junit-4.11-sources.jar,http://repo1.maven.org/maven2/junit/junit/4.11/junit-4.11-sources.jar\nlibrary@JUNIT@sourceSha1=28e0ad201304e4a4abf999ca0570b7cffc352c3c\nlibrary@JUNIT@dependencies=HAMCREST\n\nlibrary@HAMCREST@path=lib/hamcrest-core-1.3.jar\nlibrary@HAMCREST@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/hamcrest-core-1.3.jar,http://repo1.maven.org/maven2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar\nlibrary@HAMCREST@sha1=42a25dc3219429f0e5d060061f71acb49bf010a0\nlibrary@HAMCREST@sourcePath=lib/hamcrest-core-1.3-sources.jar\nlibrary@HAMCREST@sourceUrls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/hamcrest-core-1.3-sources.jar,http://repo1.maven.org/maven2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3-sources.jar\nlibrary@HAMCREST@sourceSha1=1dc37250fbc78e23a65a67fbbaf71d2e9cbc3c0b\n\nlibrary@CHECKSTYLE@path=lib/checkstyle-5.5-all.jar\nlibrary@CHECKSTYLE@urls=jar:http://sourceforge.net/projects/checkstyle/files/checkstyle/5.5/checkstyle-5.5-bin.zip/download!/checkstyle-5.5/checkstyle-5.5-all.jar\nlibrary@CHECKSTYLE@sha1=6f4bb2b3dafb9426a67fa9c47f96ffed3b44749a\n\nlibrary@FINDBUGS@path=lib/findbugs-3.0.0.jar\nlibrary@FINDBUGS@urls=jar:http://lafo.ssw.uni-linz.ac.at/graal-external-deps/findbugs-3.0.0.zip!/findbugs-3.0.0/lib/findbugs.jar,jar:http://sourceforge.net/projects/findbugs/files/findbugs/3.0.0/findbugs-3.0.0.zip/download!/findbugs-3.0.0/lib/findbugs.jar\nlibrary@FINDBUGS@sha1=e9a938f0cb34e2ab5853f9ecb1989f6f590ee385\n\nlibrary@DACAPO@path=lib/dacapo-9.12-bach.jar\nlibrary@DACAPO@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/dacapo-9.12-bach.jar,http://softlayer.dl.sourceforge.net/project/dacapobench/9.12-bach/dacapo-9.12-bach.jar\nlibrary@DACAPO@sha1=2626a9546df09009f6da0df854e6dc1113ef7dd4\n\nlibrary@JACOCOAGENT@path=lib/jacocoagent.jar\nlibrary@JACOCOAGENT@urls=http://lafo.ssw.uni-linz.ac.at/jacoco/jacocoagent-0.7.1-1.jar\nlibrary@JACOCOAGENT@sha1=2f73a645b02e39290e577ce555f00b02004650b0\n\nlibrary@JACOCOREPORT@path=lib/jacocoreport.jar\nlibrary@JACOCOREPORT@urls=http://lafo.ssw.uni-linz.ac.at/jacoco/jacocoreport-0.7.1-2.jar\nlibrary@JACOCOREPORT@sha1=a630436391832d697a12c8f7daef8655d7a1efd2\n\nlibrary@DACAPO_SCALA@path=lib/dacapo-scala-0.1.0-20120216.jar\nlibrary@DACAPO_SCALA@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/dacapo-scala-0.1.0-20120216.jar,http://repo.scalabench.org/snapshots/org/scalabench/benchmarks/scala-benchmark-suite/0.1.0-SNAPSHOT/scala-benchmark-suite-0.1.0-20120216.103539-3.jar\nlibrary@DACAPO_SCALA@sha1=59b64c974662b5cf9dbd3cf9045d293853dd7a51\n\nlibrary@OKRA@path=lib/okra-1.10.jar\nlibrary@OKRA@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/okra-1.10.jar,http://cr.openjdk.java.net/~tdeneau/okra-1.10.jar\nlibrary@OKRA@sha1=96eb3c0ec808ed944ba88d1eb9311058fe0f3d1e\nlibrary@OKRA@sourcePath=lib/okra-1.10-src.jar\nlibrary@OKRA@sourceUrls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/okra-1.10-src.jar,http://cr.openjdk.java.net/~tdeneau/okra-1.10-src.jar\nlibrary@OKRA@sourceSha1=75751bb148fcebaba78ff590f883a114b2b09176\n\nlibrary@OKRA_WITH_SIM@path=lib/okra-1.10-with-sim.jar\nlibrary@OKRA_WITH_SIM@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/okra-1.10-with-sim.jar,http://cr.openjdk.java.net/~tdeneau/okra-1.10-with-sim.jar\nlibrary@OKRA_WITH_SIM@sha1=7b8db879f1dbcf571290add78d9af24e15a2a50d\nlibrary@OKRA_WITH_SIM@sourcePath=lib/okra-1.10-with-sim-src.jar\nlibrary@OKRA_WITH_SIM@sourceSha1=7eefd94f16a3e3fd3b8f470cf91e265c6f5e7767\nlibrary@OKRA_WITH_SIM@sourceUrls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/okra-1.10-with-sim-src.jar,http://cr.openjdk.java.net/~tdeneau/okra-1.10-with-sim-src.jar\n\nlibrary@JAVA_ALLOCATION_INSTRUMENTER@path=lib/java-allocation-instrumenter.jar\nlibrary@JAVA_ALLOCATION_INSTRUMENTER@sourcePath=lib/java-allocation-instrumenter.jar\nlibrary@JAVA_ALLOCATION_INSTRUMENTER@urls=http://lafo.ssw.uni-linz.ac.at/java-allocation-instrumenter/java-allocation-instrumenter-8f0db117e64e.jar\nlibrary@JAVA_ALLOCATION_INSTRUMENTER@sha1=476d9a44cd19d6b55f81571077dfa972a4f8a083\n\nlibrary@VECMATH@path=lib/vecmath-1.3.1.jar\nlibrary@VECMATH@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/vecmath-1.3.1.jar,http://mirrors.ibiblio.org/pub/mirrors/maven/java3d/jars/vecmath-1.3.1.jar\nlibrary@VECMATH@sha1=a0ae4f51da409fa0c20fa0ca59e6bbc9413ae71d\n\nlibrary@JRUBYPARSER@path=lib/jrubyparser-0.5.0.jar\nlibrary@JRUBYPARSER@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jrubyparser-0.5.0.jar,http://repo1.maven.org/maven2/org/jruby/jrubyparser/0.5.0/jrubyparser-0.5.0.jar\nlibrary@JRUBYPARSER@sha1=eadecb3154a033b17e24130afaaf2ca71bacb24f\n\nlibrary@JLINE@path=lib/jline-2.11.jar\nlibrary@JLINE@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jline-2.11.jar,http://repo1.maven.org/maven2/jline/jline/2.11/jline-2.11.jar\nlibrary@JLINE@sha1=9504d5e2da5d78237239c5226e8200ec21182040\n\nlibrary@JRUBYSTDLIB@path=lib/jruby-stdlib-1.7.12.jar\nlibrary@JRUBYSTDLIB@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jruby-stdlib-1.7.12.jar,http://repo1.maven.org/maven2/org/jruby/jruby-stdlib/1.7.12/jruby-stdlib-1.7.12.jar\nlibrary@JRUBYSTDLIB@sha1=1aa175d70deaa99c9555d23593fc43b761e8c419\n\nlibrary@JNR_INVOKE@path=lib/jnr-invoke-0.1.jar\nlibrary@JNR_INVOKE@urls=http://repo1.maven.org/maven2/com/github/jnr/jnr-invoke/0.1/jnr-invoke-0.1.jar\nlibrary@JNR_INVOKE@sha1=d0f846c3d3cb98dfd5e2bbd3cca236337fb0afa1\n\nlibrary@JNR_POSIX@path=lib/jnr-posix-3.0.1.jar\nlibrary@JNR_POSIX@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jnr-posix-3.0.1.jar,http://repo1.maven.org/maven2/com/github/jnr/jnr-posix/3.0.1/jnr-posix-3.0.1.jar\nlibrary@JNR_POSIX@sha1=5ac18caed12108123c959c8acedef76ca4f28cb3\n\nlibrary@JNR_CONSTANTS@path=lib/jnr-constants-0.8.5.jar\nlibrary@JNR_CONSTANTS@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jnr-constants-0.8.5.jar,http://repo1.maven.org/maven2/com/github/jnr/jnr-constants/0.8.5/jnr-constants-0.8.5.jar\nlibrary@JNR_CONSTANTS@sha1=f84cca9e21f1f763a9eaf33de3d6a66a20ed7af0\n\nlibrary@JNR_FFI@path=lib/jnr-ffi-1.0.10.jar\nlibrary@JNR_FFI@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jnr-ffi-1.0.10.jar,http://repo1.maven.org/maven2/com/github/jnr/jnr-ffi/1.0.10/jnr-ffi-1.0.10.jar\nlibrary@JNR_FFI@sha1=646428e83a0e2ab4743091781ea98e3164c6d707\n\nlibrary@JFFI@path=lib/jffi-1.2.7.jar\nlibrary@JFFI@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jffi-1.2.7.jar,http://repo1.maven.org/maven2/com/github/jnr/jffi/1.2.7/jffi-1.2.7.jar\nlibrary@JFFI@sha1=acda5c46140404e08b3526f39db1504874b34b4c\n\nlibrary@JFFI_NATIVE@path=lib/jffi-1.2.7-native.jar\nlibrary@JFFI_NATIVE@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jffi-1.2.7-native.jar,http://search.maven.org/remotecontent?filepath=com/github/jnr/jffi/1.2.7/jffi-1.2.7-native.jar\nlibrary@JFFI_NATIVE@sha1=4e8c876383acb37da4347902a0a775aefd51de09\n\nlibrary@JNR_X86ASM@path=lib/jnr-x86asm-1.0.2.jar\nlibrary@JNR_X86ASM@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jnr-x86asm-1.0.2.jar,http://repo1.maven.org/maven2/com/github/jnr/jnr-x86asm/1.0.2/jnr-x86asm-1.0.2.jar\nlibrary@JNR_X86ASM@sha1=006936bbd6c5b235665d87bd450f5e13b52d4b48\n\nlibrary@ASM@path=lib/asm-4.0.jar\nlibrary@ASM@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/asm-4.0.jar,http://repo1.maven.org/maven2/org/ow2/asm/asm/4.0/asm-4.0.jar\nlibrary@ASM@sha1=659add6efc75a4715d738e73f07505246edf4d66\n\nlibrary@ASM_ANALYSIS@path=lib/asm-analysis-4.0.jar\nlibrary@ASM_ANALYSIS@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/asm-analysis-4.0.jar,http://repo1.maven.org/maven2/org/ow2/asm/asm-analysis/4.0/asm-analysis-4.0.jar\nlibrary@ASM_ANALYSIS@sha1=1c45d52b6f6c638db13cf3ac12adeb56b254cdd7\n\nlibrary@ASM_COMMONS@path=lib/asm-commons-4.0.jar\nlibrary@ASM_COMMONS@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/asm-commons-4.0.jar,http://repo1.maven.org/maven2/org/ow2/asm/asm-commons/4.0/asm-commons-4.0.jar\nlibrary@ASM_COMMONS@sha1=a839ec6737d2b5ba7d1878e1a596b8f58aa545d9\n\nlibrary@ASM_TREE@path=lib/asm-tree-4.0.jar\nlibrary@ASM_TREE@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/asm-tree-4.0.jar,http://repo1.maven.org/maven2/org/ow2/asm/asm-tree/4.0/asm-tree-4.0.jar\nlibrary@ASM_TREE@sha1=67bd266cd17adcee486b76952ece4cc85fe248b8\n\nlibrary@ASM_UTIL@path=lib/asm-util-4.0.jar\nlibrary@ASM_UTIL@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/asm-util-4.0.jar,http://repo1.maven.org/maven2/org/ow2/asm/asm-util/4.0/asm-util-4.0.jar\nlibrary@ASM_UTIL@sha1=d7a65f54cda284f9706a750c23d64830bb740c39\n\nlibrary@AVATAR_JS@path=lib/avatar/avatar-js.jar\nlibrary@AVATAR_JS@urls=jar:http://lafo.ssw.uni-linz.ac.at/truffle/avatar/avatarjs-0.12.zip!/avatar-js.jar\nlibrary@AVATAR_JS@sha1=c74d0862ce3dc8ed212872c110e6ad9ac12b2ee9\n\nlibrary@JRUBY@path=lib/jruby-complete-9000.dev.df2aaff.jar\nlibrary@JRUBY@urls=http://lafo.ssw.uni-linz.ac.at/truffle/ruby/jruby-complete-9000.dev.df2aaff.jar\nlibrary@JRUBY@sha1=7d306add29a6fb440fe7322d5de9252647f2bc5b\n\ndistribution@GRAAL@path=graal.jar\ndistribution@GRAAL@subDir=graal\ndistribution@GRAAL@sourcesPath=graal.src.zip\ndistribution@GRAAL@dependencies=\\\ncom.oracle.graal.hotspot.amd64,\\\ncom.oracle.graal.hotspot.ptx,\\\ncom.oracle.graal.truffle,\\\ncom.oracle.graal.truffle.hotspot.amd64,\\\ncom.oracle.graal.hotspot.sparc,\\\ncom.oracle.graal.hotspot,\\\ncom.oracle.graal.hotspot.jfr,\\\ncom.oracle.graal.hotspot.hsail\ndistribution@GRAAL@exclude=FINDBUGS\n\ndistribution@GRAAL_LOADER@path=graal-loader.jar\ndistribution@GRAAL_LOADER@subDir=graal\ndistribution@GRAAL_LOADER@sourcesPath=graal-loader.src.zip\ndistribution@GRAAL_LOADER@dependencies=com.oracle.graal.hotspot.loader\n\ndistribution@TRUFFLE@path=truffle.jar\ndistribution@TRUFFLE@subDir=graal\ndistribution@TRUFFLE@sourcesPath=truffle-sources.jar\ndistribution@TRUFFLE@dependencies=\\\ncom.oracle.truffle.api.dsl\n\ndistribution@TRUFFLE-DSL-PROCESSOR@path=truffle-dsl-processor.jar\ndistribution@TRUFFLE-DSL-PROCESSOR@subDir=graal\ndistribution@TRUFFLE-DSL-PROCESSOR@sourcesPath=truffle-dsl-processor-sources.jar\ndistribution@TRUFFLE-DSL-PROCESSOR@dependencies=\\\ncom.oracle.truffle.dsl.processor\ndistribution@TRUFFLE-DSL-PROCESSOR@distDependencies=TRUFFLE\n\ndistribution@TRUFFLE-OM@path=truffle-om.jar\ndistribution@TRUFFLE-OM@sourcesPath=truffle-om-sources.jar\ndistribution@TRUFFLE-OM@subDir=graal\ndistribution@TRUFFLE-OM@dependencies=com.oracle.truffle.om\ndistribution@TRUFFLE-OM@distDependencies=TRUFFLE\n\ndistribution@TRUFFLEJS@path=trufflejs.jar\ndistribution@TRUFFLEJS@sourcesPath=trufflejs-sources.jar\ndistribution@TRUFFLEJS@mainClass=com.oracle.truffle.js.shell.Shell\ndistribution@TRUFFLEJS@dependencies=\\\ncom.oracle.truffle.js.shell,\\\ncom.oracle.truffle.js.repl\n\ndistribution@AVATARTRUFFLEJS@path=avatartrufflejs.jar\ndistribution@AVATARTRUFFLEJS@sourcesPath=avatartrufflejs-sources.jar\ndistribution@AVATARTRUFFLEJS@mainClass=com.oracle.truffle.avatar.js.runtime.AvatarTruffle\ndistribution@AVATARTRUFFLEJS@dependencies=\\\ncom.oracle.truffle.js.shell,\\\ncom.oracle.truffle.avatar.js.runtime\n\nlibrary@NASHORN_JONI_REGEX@path=lib/joni-regex-2.jar\nlibrary@NASHORN_JONI_REGEX@urls=http://lafo.ssw.uni-linz.ac.at/truffle/js/joni-regex-2.jar\nlibrary@NASHORN_JONI_REGEX@sha1=ac1f450b4716a2a5b365912fb70198d1e723cdab\n\nlibrary@NASHORN_INTERNAL_TESTS@path=lib/nashorn-internal-tests-18edd7a1b166.jar\nlibrary@NASHORN_INTERNAL_TESTS@urls=http://lafo.ssw.uni-linz.ac.at/truffle/js/nashorn-internal-tests-18edd7a1b166.jar\nlibrary@NASHORN_INTERNAL_TESTS@sha1=2cc1da0a22d85bbeac9f80314c1d4ec9b6c40694\n\n# graal.api.collections\nproject@com.oracle.graal.api.collections@subDir=graal\nproject@com.oracle.graal.api.collections@sourceDirs=src\nproject@com.oracle.graal.api.collections@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.api.collections@javaCompliance=1.8\nproject@com.oracle.graal.api.collections@workingSets=API,Graal\n\n# graal.api.runtime\nproject@com.oracle.graal.api.runtime@subDir=graal\nproject@com.oracle.graal.api.runtime@sourceDirs=src\nproject@com.oracle.graal.api.runtime@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.api.runtime@javaCompliance=1.8\nproject@com.oracle.graal.api.runtime@workingSets=API,Graal\n\n# graal.api.test\nproject@com.oracle.graal.api.test@subDir=graal\nproject@com.oracle.graal.api.test@sourceDirs=src\nproject@com.oracle.graal.api.test@dependencies=JUNIT,com.oracle.graal.api.runtime\nproject@com.oracle.graal.api.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.api.test@javaCompliance=1.8\nproject@com.oracle.graal.api.test@workingSets=API,Graal,Test\n\n# graal.api.meta\nproject@com.oracle.graal.api.meta@subDir=graal\nproject@com.oracle.graal.api.meta@sourceDirs=src\nproject@com.oracle.graal.api.meta@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.api.meta@javaCompliance=1.8\nproject@com.oracle.graal.api.meta@workingSets=API,Graal\n\n# graal.api.meta.test\nproject@com.oracle.graal.api.meta.test@subDir=graal\nproject@com.oracle.graal.api.meta.test@sourceDirs=src\nproject@com.oracle.graal.api.meta.test@dependencies=JUNIT,com.oracle.graal.runtime,com.oracle.graal.java\nproject@com.oracle.graal.api.meta.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.api.meta.test@javaCompliance=1.8\nproject@com.oracle.graal.api.meta.test@workingSets=API,Graal,Test\n\n# graal.api.code\nproject@com.oracle.graal.api.code@subDir=graal\nproject@com.oracle.graal.api.code@sourceDirs=src\nproject@com.oracle.graal.api.code@dependencies=com.oracle.graal.api.meta\nproject@com.oracle.graal.api.code@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.api.code@javaCompliance=1.8\nproject@com.oracle.graal.api.code@workingSets=API,Graal\n\n# graal.api.replacements\nproject@com.oracle.graal.api.replacements@subDir=graal\nproject@com.oracle.graal.api.replacements@sourceDirs=src\nproject@com.oracle.graal.api.replacements@dependencies=com.oracle.graal.api.meta\nproject@com.oracle.graal.api.replacements@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.api.replacements@javaCompliance=1.8\nproject@com.oracle.graal.api.replacements@workingSets=API,Graal,Replacements\n\n# graal.service.processor\nproject@com.oracle.graal.service.processor@subDir=graal\nproject@com.oracle.graal.service.processor@sourceDirs=src\nproject@com.oracle.graal.service.processor@dependencies=com.oracle.graal.api.runtime\nproject@com.oracle.graal.service.processor@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.service.processor@javaCompliance=1.8\nproject@com.oracle.graal.service.processor@workingSets=Codegen,HotSpot\n\n# graal.amd64\nproject@com.oracle.graal.amd64@subDir=graal\nproject@com.oracle.graal.amd64@sourceDirs=src\nproject@com.oracle.graal.amd64@dependencies=com.oracle.graal.api.code\nproject@com.oracle.graal.amd64@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.amd64@javaCompliance=1.8\nproject@com.oracle.graal.amd64@workingSets=Graal,AMD64\n\n# graal.ptx\nproject@com.oracle.graal.ptx@subDir=graal\nproject@com.oracle.graal.ptx@sourceDirs=src\nproject@com.oracle.graal.ptx@dependencies=com.oracle.graal.api.code\nproject@com.oracle.graal.ptx@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.ptx@javaCompliance=1.8\nproject@com.oracle.graal.ptx@workingSets=Graal,PTX\n\n# graal.sparc\nproject@com.oracle.graal.sparc@subDir=graal\nproject@com.oracle.graal.sparc@sourceDirs=src\nproject@com.oracle.graal.sparc@dependencies=com.oracle.graal.api.code\nproject@com.oracle.graal.sparc@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.sparc@javaCompliance=1.8\nproject@com.oracle.graal.sparc@workingSets=Graal,SPARC\n\n# graal.hotspotvmconfig\nproject@com.oracle.graal.hotspotvmconfig@subDir=graal\nproject@com.oracle.graal.hotspotvmconfig@sourceDirs=src\nproject@com.oracle.graal.hotspotvmconfig@dependencies=com.oracle.graal.compiler.common\nproject@com.oracle.graal.hotspotvmconfig@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hotspotvmconfig@annotationProcessors=com.oracle.graal.service.processor\nproject@com.oracle.graal.hotspotvmconfig@annotationProcessorForDependents=true\nproject@com.oracle.graal.hotspotvmconfig@javaCompliance=1.8\nproject@com.oracle.graal.hotspotvmconfig@workingSets=Graal,HotSpot\n\n# graal.hotspot\nproject@com.oracle.graal.hotspot@subDir=graal\nproject@com.oracle.graal.hotspot@sourceDirs=src\nproject@com.oracle.graal.hotspot@dependencies=com.oracle.graal.replacements,com.oracle.graal.runtime,com.oracle.graal.printer,com.oracle.graal.baseline,com.oracle.graal.hotspotvmconfig\nproject@com.oracle.graal.hotspot@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hotspot@annotationProcessors=com.oracle.graal.replacements.verifier,com.oracle.graal.service.processor\nproject@com.oracle.graal.hotspot@javaCompliance=1.8\nproject@com.oracle.graal.hotspot@workingSets=Graal,HotSpot\n\n# graal.hotspot.loader\nproject@com.oracle.graal.hotspot.loader@subDir=graal\nproject@com.oracle.graal.hotspot.loader@sourceDirs=src\nproject@com.oracle.graal.hotspot.loader@dependencies=\nproject@com.oracle.graal.hotspot.loader@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hotspot.loader@javaCompliance=1.8\nproject@com.oracle.graal.hotspot.loader@workingSets=Graal,HotSpot\n\n# graal.hotspot.sourcegen\nproject@com.oracle.graal.hotspot.sourcegen@subDir=graal\nproject@com.oracle.graal.hotspot.sourcegen@sourceDirs=src\nproject@com.oracle.graal.hotspot.sourcegen@dependencies=com.oracle.graal.hotspot\nproject@com.oracle.graal.hotspot.sourcegen@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hotspot.sourcegen@javaCompliance=1.8\nproject@com.oracle.graal.hotspot.sourcegen@workingSets=Graal,HotSpot\n\n# graal.hotspot.jfr\nproject@com.oracle.graal.hotspot.jfr@subDir=graal\nproject@com.oracle.graal.hotspot.jfr@sourceDirs=src\nproject@com.oracle.graal.hotspot.jfr@dependencies=com.oracle.graal.hotspot,JFR\nproject@com.oracle.graal.hotspot.jfr@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hotspot.jfr@annotationProcessors=com.oracle.graal.service.processor\nproject@com.oracle.graal.hotspot.jfr@javaCompliance=1.8\nproject@com.oracle.graal.hotspot.jfr@profile=\nproject@com.oracle.graal.hotspot.jfr@workingSets=Graal,HotSpot\n\n# graal.hotspot.amd64\nproject@com.oracle.graal.hotspot.amd64@subDir=graal\nproject@com.oracle.graal.hotspot.amd64@sourceDirs=src\nproject@com.oracle.graal.hotspot.amd64@dependencies=com.oracle.graal.compiler.amd64,com.oracle.graal.hotspot,com.oracle.graal.replacements.amd64\nproject@com.oracle.graal.hotspot.amd64@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hotspot.amd64@annotationProcessors=com.oracle.graal.service.processor\nproject@com.oracle.graal.hotspot.amd64@javaCompliance=1.8\nproject@com.oracle.graal.hotspot.amd64@workingSets=Graal,HotSpot,AMD64\n\n# graal.hotspot.sparc\nproject@com.oracle.graal.hotspot.sparc@subDir=graal\nproject@com.oracle.graal.hotspot.sparc@sourceDirs=src\nproject@com.oracle.graal.hotspot.sparc@dependencies=com.oracle.graal.compiler.sparc\nproject@com.oracle.graal.hotspot.sparc@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hotspot.sparc@annotationProcessors=com.oracle.graal.service.processor\nproject@com.oracle.graal.hotspot.sparc@javaCompliance=1.8\nproject@com.oracle.graal.hotspot.sparc@workingSets=Graal,HotSpot,SPARC\n\n# graal.hotspot.ptx\nproject@com.oracle.graal.hotspot.ptx@subDir=graal\nproject@com.oracle.graal.hotspot.ptx@sourceDirs=src\nproject@com.oracle.graal.hotspot.ptx@dependencies=com.oracle.graal.ptx,com.oracle.graal.compiler.ptx,com.oracle.graal.hotspot,com.oracle.graal.gpu\nproject@com.oracle.graal.hotspot.ptx@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hotspot.ptx@annotationProcessors=com.oracle.graal.service.processor\nproject@com.oracle.graal.hotspot.ptx@javaCompliance=1.8\nproject@com.oracle.graal.hotspot.ptx@workingSets=Graal,HotSpot,PTX\n\n# graal.hotspot.hsail\nproject@com.oracle.graal.hotspot.hsail@subDir=graal\nproject@com.oracle.graal.hotspot.hsail@sourceDirs=src\nproject@com.oracle.graal.hotspot.hsail@dependencies=com.oracle.graal.replacements.hsail,com.oracle.graal.hotspot,com.oracle.graal.gpu\nproject@com.oracle.graal.hotspot.hsail@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hotspot.hsail@annotationProcessors=com.oracle.graal.service.processor\nproject@com.oracle.graal.hotspot.hsail@javaCompliance=1.8\nproject@com.oracle.graal.hotspot.hsail@workingSets=Graal,HotSpot,PTX\n\n# graal.hotspot.server\nproject@com.oracle.graal.hotspot.server@subDir=graal\nproject@com.oracle.graal.hotspot.server@sourceDirs=src\nproject@com.oracle.graal.hotspot.server@dependencies=com.oracle.graal.hotspot\nproject@com.oracle.graal.hotspot.server@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hotspot.server@javaCompliance=1.8\nproject@com.oracle.graal.hotspot.server@workingSets=Graal,HotSpot\n\n# graal.hotspot.test\nproject@com.oracle.graal.hotspot.test@subDir=graal\nproject@com.oracle.graal.hotspot.test@sourceDirs=src\nproject@com.oracle.graal.hotspot.test@dependencies=com.oracle.graal.replacements.test,com.oracle.graal.hotspot\nproject@com.oracle.graal.hotspot.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hotspot.test@javaCompliance=1.8\nproject@com.oracle.graal.hotspot.test@workingSets=Graal,HotSpot,Test\n\n# graal.hotspot.jdk8.test\nproject@com.oracle.graal.hotspot.jdk8.test@subDir=graal\nproject@com.oracle.graal.hotspot.jdk8.test@sourceDirs=src\nproject@com.oracle.graal.hotspot.jdk8.test@dependencies=com.oracle.graal.compiler.test\nproject@com.oracle.graal.hotspot.jdk8.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hotspot.jdk8.test@javaCompliance=1.8\nproject@com.oracle.graal.hotspot.jdk8.test@workingSets=Graal,HotSpot,Test\n\n# graal.hotspot.amd64.test\nproject@com.oracle.graal.hotspot.amd64.test@subDir=graal\nproject@com.oracle.graal.hotspot.amd64.test@sourceDirs=src\nproject@com.oracle.graal.hotspot.amd64.test@dependencies=com.oracle.graal.asm.amd64,com.oracle.graal.compiler.test\nproject@com.oracle.graal.hotspot.amd64.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hotspot.amd64.test@javaCompliance=1.8\nproject@com.oracle.graal.hotspot.amd64.test@workingSets=Graal,HotSpot,AMD64,Test\n\n# graal.options\nproject@com.oracle.graal.options@subDir=graal\nproject@com.oracle.graal.options@sourceDirs=src\nproject@com.oracle.graal.options@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.options@javaCompliance=1.8\nproject@com.oracle.graal.options@annotationProcessorForDependents=true\nproject@com.oracle.graal.options@workingSets=Graal,Codegen\n\n# graal.options.test\nproject@com.oracle.graal.options.test@subDir=graal\nproject@com.oracle.graal.options.test@sourceDirs=src\nproject@com.oracle.graal.options.test@dependencies=com.oracle.graal.options,JUNIT\nproject@com.oracle.graal.options.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.options.test@javaCompliance=1.8\nproject@com.oracle.graal.options.test@workingSets=Graal\n\n# graal.graph\nproject@com.oracle.graal.graph@subDir=graal\nproject@com.oracle.graal.graph@sourceDirs=src\nproject@com.oracle.graal.graph@dependencies=com.oracle.graal.debug,com.oracle.graal.compiler.common,com.oracle.graal.api.collections,com.oracle.graal.api.runtime,FINDBUGS\nproject@com.oracle.graal.graph@javaCompliance=1.8\nproject@com.oracle.graal.graph@workingSets=Graal,Graph\n\n# graal.graph.test\nproject@com.oracle.graal.graph.test@subDir=graal\nproject@com.oracle.graal.graph.test@sourceDirs=src\nproject@com.oracle.graal.graph.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.graph.test@dependencies=JUNIT,com.oracle.graal.graph\nproject@com.oracle.graal.graph.test@javaCompliance=1.8\nproject@com.oracle.graal.graph.test@workingSets=Graal,Graph,Test\n\n# graal.debug\nproject@com.oracle.graal.debug@subDir=graal\nproject@com.oracle.graal.debug@sourceDirs=src\nproject@com.oracle.graal.debug@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.debug@javaCompliance=1.8\nproject@com.oracle.graal.debug@workingSets=Graal,Debug\n\n# graal.debug.test\nproject@com.oracle.graal.debug.test@subDir=graal\nproject@com.oracle.graal.debug.test@sourceDirs=src\nproject@com.oracle.graal.debug.test@dependencies=JUNIT,com.oracle.graal.debug\nproject@com.oracle.graal.debug.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.debug.test@javaCompliance=1.8\nproject@com.oracle.graal.debug.test@workingSets=Graal,Debug,Test\n\n# graal.lir\nproject@com.oracle.graal.lir@subDir=graal\nproject@com.oracle.graal.lir@sourceDirs=src\nproject@com.oracle.graal.lir@dependencies=com.oracle.graal.debug,com.oracle.graal.compiler.common,com.oracle.graal.asm\nproject@com.oracle.graal.lir@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.lir@javaCompliance=1.8\nproject@com.oracle.graal.lir@workingSets=Graal,LIR\n\n# graal.lir.test\nproject@com.oracle.graal.lir.test@subDir=graal\nproject@com.oracle.graal.lir.test@sourceDirs=src\nproject@com.oracle.graal.lir.test@dependencies=JUNIT,com.oracle.graal.lir\nproject@com.oracle.graal.lir.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.lir.test@javaCompliance=1.8\nproject@com.oracle.graal.lir.test@workingSets=Graal,LIR\n\n# graal.lir.amd64\nproject@com.oracle.graal.lir.amd64@subDir=graal\nproject@com.oracle.graal.lir.amd64@sourceDirs=src\nproject@com.oracle.graal.lir.amd64@dependencies=com.oracle.graal.lir,com.oracle.graal.asm.amd64\nproject@com.oracle.graal.lir.amd64@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.lir.amd64@javaCompliance=1.8\nproject@com.oracle.graal.lir.amd64@workingSets=Graal,LIR,AMD64\n\n# graal.lir.ptx\nproject@com.oracle.graal.lir.ptx@subDir=graal\nproject@com.oracle.graal.lir.ptx@sourceDirs=src\nproject@com.oracle.graal.lir.ptx@dependencies=com.oracle.graal.asm.ptx\nproject@com.oracle.graal.lir.ptx@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.lir.ptx@javaCompliance=1.8\nproject@com.oracle.graal.lir.ptx@workingSets=Graal,LIR,PTX\n\n# graal.lir.sparc\nproject@com.oracle.graal.lir.sparc@subDir=graal\nproject@com.oracle.graal.lir.sparc@sourceDirs=src\nproject@com.oracle.graal.lir.sparc@dependencies=com.oracle.graal.asm.sparc\nproject@com.oracle.graal.lir.sparc@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.lir.sparc@javaCompliance=1.8\nproject@com.oracle.graal.lir.sparc@workingSets=Graal,LIR,SPARC\n\n# graal.alloc\nproject@com.oracle.graal.alloc@subDir=graal\nproject@com.oracle.graal.alloc@sourceDirs=src\nproject@com.oracle.graal.alloc@dependencies=com.oracle.graal.compiler.common\nproject@com.oracle.graal.alloc@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.alloc@javaCompliance=1.8\nproject@com.oracle.graal.alloc@workingSets=Graal\n\n# graal.word\nproject@com.oracle.graal.word@subDir=graal\nproject@com.oracle.graal.word@sourceDirs=src\nproject@com.oracle.graal.word@dependencies=com.oracle.graal.phases\nproject@com.oracle.graal.word@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.word@javaCompliance=1.8\nproject@com.oracle.graal.word@workingSets=API,Graal\n\n# graal.replacements\nproject@com.oracle.graal.replacements@subDir=graal\nproject@com.oracle.graal.replacements@sourceDirs=src\nproject@com.oracle.graal.replacements@dependencies=com.oracle.graal.compiler,com.oracle.graal.java,com.oracle.graal.word\nproject@com.oracle.graal.replacements@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.replacements@javaCompliance=1.8\nproject@com.oracle.graal.replacements@annotationProcessors=com.oracle.graal.replacements.verifier,com.oracle.graal.service.processor\nproject@com.oracle.graal.replacements@workingSets=Graal,Replacements\n\n# graal.replacements.amd64\nproject@com.oracle.graal.replacements.amd64@subDir=graal\nproject@com.oracle.graal.replacements.amd64@sourceDirs=src\nproject@com.oracle.graal.replacements.amd64@dependencies=com.oracle.graal.replacements\nproject@com.oracle.graal.replacements.amd64@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.replacements.amd64@javaCompliance=1.8\nproject@com.oracle.graal.replacements.amd64@annotationProcessors=com.oracle.graal.service.processor\nproject@com.oracle.graal.replacements.amd64@workingSets=Graal,Replacements,AMD64\n\n# graal.replacements.hsail\nproject@com.oracle.graal.replacements.hsail@subDir=graal\nproject@com.oracle.graal.replacements.hsail@sourceDirs=src\nproject@com.oracle.graal.replacements.hsail@dependencies=com.oracle.graal.compiler.hsail\nproject@com.oracle.graal.replacements.hsail@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.replacements.hsail@javaCompliance=1.8\nproject@com.oracle.graal.replacements.hsail@workingSets=Graal,Replacements,HSAIL\n\n# graal.replacements.test\nproject@com.oracle.graal.replacements.test@subDir=graal\nproject@com.oracle.graal.replacements.test@sourceDirs=src\nproject@com.oracle.graal.replacements.test@dependencies=com.oracle.graal.compiler.test,com.oracle.graal.replacements\nproject@com.oracle.graal.replacements.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.replacements.test@javaCompliance=1.8\nproject@com.oracle.graal.replacements.test@workingSets=Graal,Replacements,Test\n\n# graal.replacements.verifier\nproject@com.oracle.graal.replacements.verifier@subDir=graal\nproject@com.oracle.graal.replacements.verifier@sourceDirs=src\nproject@com.oracle.graal.replacements.verifier@dependencies=com.oracle.graal.api.replacements,com.oracle.graal.graph\nproject@com.oracle.graal.replacements.verifier@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.replacements.verifier@javaCompliance=1.8\nproject@com.oracle.graal.replacements.verifier@workingSets=Graal,Replacements\n\n# graal.nodes\nproject@com.oracle.graal.nodes@subDir=graal\nproject@com.oracle.graal.nodes@sourceDirs=src\nproject@com.oracle.graal.nodes@dependencies=com.oracle.graal.graph,com.oracle.graal.api.replacements,com.oracle.graal.lir\nproject@com.oracle.graal.nodes@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.nodes@javaCompliance=1.8\nproject@com.oracle.graal.nodes@annotationProcessors=com.oracle.graal.replacements.verifier\nproject@com.oracle.graal.nodes@workingSets=Graal,Graph\n\n# graal.nodes.test\nproject@com.oracle.graal.nodes.test@subDir=graal\nproject@com.oracle.graal.nodes.test@sourceDirs=src\nproject@com.oracle.graal.nodes.test@dependencies=com.oracle.graal.compiler.test\nproject@com.oracle.graal.nodes.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.nodes.test@javaCompliance=1.8\nproject@com.oracle.graal.nodes.test@workingSets=Graal,Graph\n\n# graal.phases\nproject@com.oracle.graal.phases@subDir=graal\nproject@com.oracle.graal.phases@sourceDirs=src\nproject@com.oracle.graal.phases@dependencies=com.oracle.graal.nodes\nproject@com.oracle.graal.phases@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.phases@javaCompliance=1.8\nproject@com.oracle.graal.phases@workingSets=Graal,Phases\n\n# graal.phases.common\nproject@com.oracle.graal.phases.common@subDir=graal\nproject@com.oracle.graal.phases.common@sourceDirs=src\nproject@com.oracle.graal.phases.common@dependencies=com.oracle.graal.phases\nproject@com.oracle.graal.phases.common@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.phases.common@javaCompliance=1.8\nproject@com.oracle.graal.phases.common@workingSets=Graal,Phases\n\n# graal.virtual\nproject@com.oracle.graal.virtual@subDir=graal\nproject@com.oracle.graal.virtual@sourceDirs=src\nproject@com.oracle.graal.virtual@dependencies=com.oracle.graal.phases.common\nproject@com.oracle.graal.virtual@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.virtual@javaCompliance=1.8\nproject@com.oracle.graal.virtual@workingSets=Graal,Phases\n\n# graal.loop\nproject@com.oracle.graal.loop@subDir=graal\nproject@com.oracle.graal.loop@sourceDirs=src\nproject@com.oracle.graal.loop@dependencies=com.oracle.graal.phases.common\nproject@com.oracle.graal.loop@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.loop@javaCompliance=1.8\nproject@com.oracle.graal.loop@workingSets=Graal,Phases\n\n# graal.compiler\nproject@com.oracle.graal.compiler@subDir=graal\nproject@com.oracle.graal.compiler@sourceDirs=src\nproject@com.oracle.graal.compiler@dependencies=com.oracle.graal.virtual,com.oracle.graal.loop,com.oracle.graal.alloc\nproject@com.oracle.graal.compiler@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.compiler@javaCompliance=1.8\nproject@com.oracle.graal.compiler@annotationProcessors=com.oracle.graal.service.processor\nproject@com.oracle.graal.compiler@annotationProcessorForDependents=true\nproject@com.oracle.graal.compiler@workingSets=Graal\n\n# graal.compiler.amd64\nproject@com.oracle.graal.compiler.amd64@subDir=graal\nproject@com.oracle.graal.compiler.amd64@sourceDirs=src\nproject@com.oracle.graal.compiler.amd64@dependencies=com.oracle.graal.compiler,com.oracle.graal.lir.amd64\nproject@com.oracle.graal.compiler.amd64@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.compiler.amd64@javaCompliance=1.8\nproject@com.oracle.graal.compiler.amd64@workingSets=Graal,AMD64\n\n# graal.compiler.amd64.test\nproject@com.oracle.graal.compiler.amd64.test@subDir=graal\nproject@com.oracle.graal.compiler.amd64.test@sourceDirs=src\nproject@com.oracle.graal.compiler.amd64.test@dependencies=com.oracle.graal.compiler.test\nproject@com.oracle.graal.compiler.amd64.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.compiler.amd64.test@javaCompliance=1.8\nproject@com.oracle.graal.compiler.amd64.test@workingSets=Graal,AMD64,Test\n\n# graal.compiler.ptx\nproject@com.oracle.graal.compiler.ptx@subDir=graal\nproject@com.oracle.graal.compiler.ptx@sourceDirs=src\nproject@com.oracle.graal.compiler.ptx@dependencies=com.oracle.graal.lir.ptx,com.oracle.graal.compiler\nproject@com.oracle.graal.compiler.ptx@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.compiler.ptx@javaCompliance=1.8\nproject@com.oracle.graal.compiler.ptx@workingSets=Graal,PTX\n\n# graal.compiler.ptx.test\nproject@com.oracle.graal.compiler.ptx.test@subDir=graal\nproject@com.oracle.graal.compiler.ptx.test@sourceDirs=src\nproject@com.oracle.graal.compiler.ptx.test@dependencies=com.oracle.graal.hotspot.ptx,com.oracle.graal.compiler.test\nproject@com.oracle.graal.compiler.ptx.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.compiler.ptx.test@javaCompliance=1.8\nproject@com.oracle.graal.compiler.ptx.test@workingSets=Graal,PTX,Test\n\n# graal.compiler.sparc\nproject@com.oracle.graal.compiler.sparc@subDir=graal\nproject@com.oracle.graal.compiler.sparc@sourceDirs=src\nproject@com.oracle.graal.compiler.sparc@dependencies=com.oracle.graal.lir.sparc\nproject@com.oracle.graal.compiler.sparc@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.compiler.sparc@javaCompliance=1.8\nproject@com.oracle.graal.compiler.sparc@workingSets=Graal,SPARC\n\n# graal.compiler.sparc.test\nproject@com.oracle.graal.compiler.sparc.test@subDir=graal\nproject@com.oracle.graal.compiler.sparc.test@sourceDirs=src\nproject@com.oracle.graal.compiler.sparc.test@dependencies=com.oracle.graal.compiler.test\nproject@com.oracle.graal.compiler.sparc.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.compiler.sparc.test@javaCompliance=1.8\nproject@com.oracle.graal.compiler.sparc.test@workingSets=Graal,SPARC,Test\n\n# graal.runtime\nproject@com.oracle.graal.runtime@subDir=graal\nproject@com.oracle.graal.runtime@sourceDirs=src\nproject@com.oracle.graal.runtime@dependencies=com.oracle.graal.compiler\nproject@com.oracle.graal.runtime@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.runtime@javaCompliance=1.8\nproject@com.oracle.graal.runtime@workingSets=Graal\n\n# graal.bytecode\nproject@com.oracle.graal.bytecode@subDir=graal\nproject@com.oracle.graal.bytecode@sourceDirs=src\nproject@com.oracle.graal.bytecode@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.bytecode@javaCompliance=1.8\nproject@com.oracle.graal.bytecode@workingSets=Graal,Java\n\n# graal.java\nproject@com.oracle.graal.java@subDir=graal\nproject@com.oracle.graal.java@sourceDirs=src\nproject@com.oracle.graal.java@dependencies=com.oracle.graal.phases,com.oracle.graal.bytecode\nproject@com.oracle.graal.java@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.java@javaCompliance=1.8\nproject@com.oracle.graal.java@workingSets=Graal,Java\n\n# graal.compiler.common\nproject@com.oracle.graal.compiler.common@subDir=graal\nproject@com.oracle.graal.compiler.common@sourceDirs=src\nproject@com.oracle.graal.compiler.common@dependencies=com.oracle.graal.api.code,com.oracle.graal.options\nproject@com.oracle.graal.compiler.common@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.compiler.common@javaCompliance=1.8\nproject@com.oracle.graal.compiler.common@workingSets=Graal,Java\n\n# graal.baseline\nproject@com.oracle.graal.baseline@subDir=graal\nproject@com.oracle.graal.baseline@sourceDirs=src\nproject@com.oracle.graal.baseline@dependencies=com.oracle.graal.compiler,com.oracle.graal.java\nproject@com.oracle.graal.baseline@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.baseline@javaCompliance=1.8\nproject@com.oracle.graal.baseline@workingSets=Graal,Java\n\n# graal.java.decompiler\nproject@com.oracle.graal.java.decompiler@subDir=graal\nproject@com.oracle.graal.java.decompiler@sourceDirs=src\nproject@com.oracle.graal.java.decompiler@dependencies=com.oracle.graal.java\nproject@com.oracle.graal.java.decompiler@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.java.decompiler@javaCompliance=1.8\nproject@com.oracle.graal.java.decompiler@workingSets=Graal\n\n# graal.java.decompiler.test\nproject@com.oracle.graal.java.decompiler.test@subDir=graal\nproject@com.oracle.graal.java.decompiler.test@sourceDirs=src\nproject@com.oracle.graal.java.decompiler.test@dependencies=JUNIT,com.oracle.graal.printer,com.oracle.graal.runtime\nproject@com.oracle.graal.java.decompiler.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.java.decompiler.test@javaCompliance=1.8\nproject@com.oracle.graal.java.decompiler.test@workingSets=Graal,Test\n\n# graal.printer\nproject@com.oracle.graal.printer@subDir=graal\nproject@com.oracle.graal.printer@sourceDirs=src\nproject@com.oracle.graal.printer@dependencies=com.oracle.graal.java.decompiler,com.oracle.graal.compiler\nproject@com.oracle.graal.printer@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.printer@javaCompliance=1.8\nproject@com.oracle.graal.printer@workingSets=Graal,Graph\n\n# graal.test\nproject@com.oracle.graal.test@subDir=graal\nproject@com.oracle.graal.test@sourceDirs=src\nproject@com.oracle.graal.test@dependencies=JUNIT,com.oracle.graal.debug\nproject@com.oracle.graal.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.test@javaCompliance=1.8\nproject@com.oracle.graal.test@workingSets=Graal,Test\n\n# graal.compiler.test\nproject@com.oracle.graal.compiler.test@subDir=graal\nproject@com.oracle.graal.compiler.test@sourceDirs=src\nproject@com.oracle.graal.compiler.test@dependencies=com.oracle.graal.test,com.oracle.graal.printer,com.oracle.graal.runtime,com.oracle.graal.baseline,JAVA_ALLOCATION_INSTRUMENTER\nproject@com.oracle.graal.compiler.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.compiler.test@javaCompliance=1.8\nproject@com.oracle.graal.compiler.test@workingSets=Graal,Test\n\n# graal.jtt\nproject@com.oracle.graal.jtt@subDir=graal\nproject@com.oracle.graal.jtt@sourceDirs=src\nproject@com.oracle.graal.jtt@dependencies=com.oracle.graal.compiler.test\nproject@com.oracle.graal.jtt@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.jtt@javaCompliance=1.8\nproject@com.oracle.graal.jtt@workingSets=Graal,Test\n\n# graal.asm\nproject@com.oracle.graal.asm@subDir=graal\nproject@com.oracle.graal.asm@sourceDirs=src\nproject@com.oracle.graal.asm@dependencies=com.oracle.graal.api.code\nproject@com.oracle.graal.asm@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.asm@javaCompliance=1.8\nproject@com.oracle.graal.asm@workingSets=Graal,Assembler\n\n# graal.asm.test\nproject@com.oracle.graal.asm.test@subDir=graal\nproject@com.oracle.graal.asm.test@sourceDirs=src\nproject@com.oracle.graal.asm.test@dependencies=com.oracle.graal.test,com.oracle.graal.runtime\nproject@com.oracle.graal.asm.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.asm.test@javaCompliance=1.8\nproject@com.oracle.graal.asm.test@workingSets=Graal,Assembler,Test\n\n# graal.asm.amd64\nproject@com.oracle.graal.asm.amd64@subDir=graal\nproject@com.oracle.graal.asm.amd64@sourceDirs=src\nproject@com.oracle.graal.asm.amd64@dependencies=com.oracle.graal.asm,com.oracle.graal.amd64\nproject@com.oracle.graal.asm.amd64@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.asm.amd64@javaCompliance=1.8\nproject@com.oracle.graal.asm.amd64@workingSets=Graal,Assembler,AMD64\n\n# graal.asm.amd64.test\nproject@com.oracle.graal.asm.amd64.test@subDir=graal\nproject@com.oracle.graal.asm.amd64.test@sourceDirs=src\nproject@com.oracle.graal.asm.amd64.test@dependencies=com.oracle.graal.asm.test,com.oracle.graal.asm.amd64\nproject@com.oracle.graal.asm.amd64.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.asm.amd64.test@javaCompliance=1.8\nproject@com.oracle.graal.asm.amd64.test@workingSets=Graal,Assembler,AMD64,Test\n\n# graal.gpu\nproject@com.oracle.graal.gpu@subDir=graal\nproject@com.oracle.graal.gpu@sourceDirs=src\nproject@com.oracle.graal.gpu@dependencies=com.oracle.graal.nodes\nproject@com.oracle.graal.gpu@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.gpu@javaCompliance=1.8\n\n# graal.hsail\nproject@com.oracle.graal.hsail@subDir=graal\nproject@com.oracle.graal.hsail@sourceDirs=src\nproject@com.oracle.graal.hsail@dependencies=com.oracle.graal.api.code\nproject@com.oracle.graal.hsail@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.hsail@javaCompliance=1.8\n\n# graal.lir.hsail\nproject@com.oracle.graal.lir.hsail@subDir=graal\nproject@com.oracle.graal.lir.hsail@sourceDirs=src\nproject@com.oracle.graal.lir.hsail@dependencies=com.oracle.graal.lir,com.oracle.graal.asm.hsail\nproject@com.oracle.graal.lir.hsail@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.lir.hsail@javaCompliance=1.8\n\n# graal.compiler.hsail\nproject@com.oracle.graal.compiler.hsail@subDir=graal\nproject@com.oracle.graal.compiler.hsail@sourceDirs=src\nproject@com.oracle.graal.compiler.hsail@dependencies=com.oracle.graal.compiler,com.oracle.graal.lir.hsail\nproject@com.oracle.graal.compiler.hsail@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.compiler.hsail@javaCompliance=1.8\n\n# graal.compiler.hsail.test.infra - HSAIL compiler test infrastructure\nproject@com.oracle.graal.compiler.hsail.test.infra@subDir=graal\nproject@com.oracle.graal.compiler.hsail.test.infra@sourceDirs=src\nproject@com.oracle.graal.compiler.hsail.test.infra@dependencies=com.oracle.graal.test,com.oracle.graal.hotspot.hsail,OKRA_WITH_SIM\nproject@com.oracle.graal.compiler.hsail.test.infra@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.compiler.hsail.test.infra@javaCompliance=1.8\n\n# graal.compiler.hsail.test\nproject@com.oracle.graal.compiler.hsail.test@subDir=graal\nproject@com.oracle.graal.compiler.hsail.test@sourceDirs=src\nproject@com.oracle.graal.compiler.hsail.test@dependencies=com.oracle.graal.compiler.hsail.test.infra,com.oracle.graal.compiler.test,VECMATH\nproject@com.oracle.graal.compiler.hsail.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.compiler.hsail.test@javaCompliance=1.8\n\n# graal.asm.hsail\nproject@com.oracle.graal.asm.hsail@subDir=graal\nproject@com.oracle.graal.asm.hsail@sourceDirs=src\nproject@com.oracle.graal.asm.hsail@dependencies=com.oracle.graal.hsail,OKRA,com.oracle.graal.asm,com.oracle.graal.compiler.common\nproject@com.oracle.graal.asm.hsail@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.asm.hsail@javaCompliance=1.8\n\n# graal.asm.ptx\nproject@com.oracle.graal.asm.ptx@subDir=graal\nproject@com.oracle.graal.asm.ptx@sourceDirs=src\nproject@com.oracle.graal.asm.ptx@dependencies=com.oracle.graal.lir\nproject@com.oracle.graal.asm.ptx@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.asm.ptx@javaCompliance=1.8\nproject@com.oracle.graal.asm.ptx@workingSets=Graal,Assembler,PTX\n\n# graal.asm.sparc\nproject@com.oracle.graal.asm.sparc@subDir=graal\nproject@com.oracle.graal.asm.sparc@sourceDirs=src\nproject@com.oracle.graal.asm.sparc@dependencies=com.oracle.graal.hotspot,com.oracle.graal.sparc\nproject@com.oracle.graal.asm.sparc@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.asm.sparc@javaCompliance=1.8\nproject@com.oracle.graal.asm.sparc@workingSets=Graal,Assembler,SPARC\n\n# truffle.api\nproject@com.oracle.truffle.api@subDir=graal\nproject@com.oracle.truffle.api@sourceDirs=src\nproject@com.oracle.truffle.api@dependencies=\nproject@com.oracle.truffle.api@javaCompliance=1.7\nproject@com.oracle.truffle.api@workingSets=API,Truffle\n\n# truffle.api.test\nproject@com.oracle.truffle.api.test@subDir=graal\nproject@com.oracle.truffle.api.test@sourceDirs=src\nproject@com.oracle.truffle.api.test@dependencies=com.oracle.truffle.api,JUNIT\nproject@com.oracle.truffle.api.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.truffle.api.test@javaCompliance=1.7\nproject@com.oracle.truffle.api.test@workingSets=API,Truffle,Test\n\n# truffle.api.interop\nproject@com.oracle.truffle.api.interop@subDir=graal\nproject@com.oracle.truffle.api.interop@sourceDirs=src\nproject@com.oracle.truffle.api.interop@dependencies=com.oracle.truffle.api\nproject@com.oracle.truffle.api.interop@checkstyle=com.oracle.truffle.api\nproject@com.oracle.truffle.api.interop@javaCompliance=1.7\nproject@com.oracle.truffle.api.interop@workingSets=API,Truffle\n\n# truffle.api.dsl\nproject@com.oracle.truffle.api.dsl@subDir=graal\nproject@com.oracle.truffle.api.dsl@sourceDirs=src\nproject@com.oracle.truffle.api.dsl@dependencies=com.oracle.truffle.api\nproject@com.oracle.truffle.api.dsl@checkstyle=com.oracle.truffle.api\nproject@com.oracle.truffle.api.dsl@javaCompliance=1.7\nproject@com.oracle.truffle.api.dsl@workingSets=API,Truffle,Codegen\n\n# truffle.api.dsl.test\nproject@com.oracle.truffle.api.dsl.test@subDir=graal\nproject@com.oracle.truffle.api.dsl.test@sourceDirs=src\nproject@com.oracle.truffle.api.dsl.test@dependencies=com.oracle.truffle.api.dsl,JUNIT\nproject@com.oracle.truffle.api.dsl.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.truffle.api.dsl.test@javaCompliance=1.7\nproject@com.oracle.truffle.api.dsl.test@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.truffle.api.dsl.test@workingSets=API,Truffle,Codegen,Test\n\n# truffle.dsl.processor\nproject@com.oracle.truffle.dsl.processor@subDir=graal\nproject@com.oracle.truffle.dsl.processor@sourceDirs=src\nproject@com.oracle.truffle.dsl.processor@dependencies=com.oracle.truffle.api.dsl\nproject@com.oracle.truffle.dsl.processor@checkstyle=com.oracle.graal.graph\nproject@com.oracle.truffle.dsl.processor@javaCompliance=1.7\nproject@com.oracle.truffle.dsl.processor@workingSets=Truffle,Codegen\n\n# truffle.om\nproject@com.oracle.truffle.om@subDir=graal\nproject@com.oracle.truffle.om@sourceDirs=src\nproject@com.oracle.truffle.om@dependencies=com.oracle.truffle.api\nproject@com.oracle.truffle.om@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.om@javaCompliance=1.7\nproject@com.oracle.truffle.om@workingSets=API,Truffle\n\n# truffle.sl\nproject@com.oracle.truffle.sl@subDir=graal\nproject@com.oracle.truffle.sl@sourceDirs=src\nproject@com.oracle.truffle.sl@dependencies=com.oracle.truffle.api.dsl\nproject@com.oracle.truffle.sl@checkstyle=com.oracle.graal.graph\nproject@com.oracle.truffle.sl@javaCompliance=1.8\nproject@com.oracle.truffle.sl@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.truffle.sl@workingSets=Truffle,SimpleLanguage\n\n# truffle.sl.test\nproject@com.oracle.truffle.sl.test@subDir=graal\nproject@com.oracle.truffle.sl.test@sourceDirs=src\nproject@com.oracle.truffle.sl.test@dependencies=com.oracle.truffle.sl,JUNIT\nproject@com.oracle.truffle.sl.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.truffle.sl.test@javaCompliance=1.8\nproject@com.oracle.truffle.sl.test@workingSets=Truffle,SimpleLanguage,Test\n\n# graal.truffle\nproject@com.oracle.graal.truffle@subDir=graal\nproject@com.oracle.graal.truffle@sourceDirs=src\nproject@com.oracle.graal.truffle@dependencies=com.oracle.truffle.api,com.oracle.graal.replacements,com.oracle.graal.runtime,com.oracle.graal.printer\nproject@com.oracle.graal.truffle@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.truffle@javaCompliance=1.8\nproject@com.oracle.graal.truffle@workingSets=Graal,Truffle\n\n# graal.truffle.test\nproject@com.oracle.graal.truffle.test@subDir=graal\nproject@com.oracle.graal.truffle.test@sourceDirs=src\nproject@com.oracle.graal.truffle.test@dependencies=com.oracle.graal.truffle,com.oracle.graal.compiler.test\nproject@com.oracle.graal.truffle.test@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.truffle.test@javaCompliance=1.8\nproject@com.oracle.graal.truffle.test@workingSets=Graal,Truffle,Test\n\n# truffle.js.runtime\nproject@com.oracle.truffle.js.runtime@subDir=graal\nproject@com.oracle.truffle.js.runtime@sourceDirs=src\nproject@com.oracle.truffle.js.runtime@dependencies=com.oracle.truffle.om,com.oracle.truffle.regex,com.oracle.truffle.api.interop\nproject@com.oracle.truffle.js.runtime@javaCompliance=1.8\nproject@com.oracle.truffle.js.runtime@workingSets=Truffle,JavaScript\n\n# truffle.js.nodes\nproject@com.oracle.truffle.js.nodes@subDir=graal\nproject@com.oracle.truffle.js.nodes@sourceDirs=src\nproject@com.oracle.truffle.js.nodes@dependencies=com.oracle.truffle.js.runtime,com.oracle.truffle.api.dsl\nproject@com.oracle.truffle.js.nodes@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.js.nodes@javaCompliance=1.8\nproject@com.oracle.truffle.js.nodes@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.truffle.js.nodes@workingSets=Truffle,JavaScript\n\n# truffle.js.builtins\nproject@com.oracle.truffle.js.builtins@subDir=graal\nproject@com.oracle.truffle.js.builtins@sourceDirs=src\nproject@com.oracle.truffle.js.builtins@dependencies=com.oracle.truffle.js.nodes\nproject@com.oracle.truffle.js.builtins@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.js.builtins@javaCompliance=1.8\nproject@com.oracle.truffle.js.builtins@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.truffle.js.builtins@workingSets=Truffle,JavaScript\n\n# truffle.js.parser\nproject@com.oracle.truffle.js.parser@subDir=graal\nproject@com.oracle.truffle.js.parser@sourceDirs=src\nproject@com.oracle.truffle.js.parser@dependencies=com.oracle.truffle.js.builtins\nproject@com.oracle.truffle.js.parser@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.js.parser@javaCompliance=1.8\nproject@com.oracle.truffle.js.parser@workingSets=Truffle,JavaScript\n\n# truffle.js.shell\nproject@com.oracle.truffle.js.shell@subDir=graal\nproject@com.oracle.truffle.js.shell@sourceDirs=src\nproject@com.oracle.truffle.js.shell@dependencies=com.oracle.truffle.js.engine\nproject@com.oracle.truffle.js.shell@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.js.shell@javaCompliance=1.8\nproject@com.oracle.truffle.js.shell@workingSets=Truffle,JavaScript\n\n# truffle.js.repl\nproject@com.oracle.truffle.js.repl@subDir=graal\nproject@com.oracle.truffle.js.repl@sourceDirs=src\nproject@com.oracle.truffle.js.repl@dependencies=com.oracle.truffle.repl,com.oracle.truffle.js.engine\nproject@com.oracle.truffle.js.repl@checkstyle=com.oracle.truffle.repl\nproject@com.oracle.truffle.js.repl@javaCompliance=1.8\nproject@com.oracle.truffle.js.repl@workingSets=Truffle,JavaScript\n\n# truffle.js.test\nproject@com.oracle.truffle.js.test@subDir=graal\nproject@com.oracle.truffle.js.test@sourceDirs=src\nproject@com.oracle.truffle.js.test@dependencies=com.oracle.truffle.js.engine,com.oracle.graal.truffle.test,NASHORN_INTERNAL_TESTS\nproject@com.oracle.truffle.js.test@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.js.test@javaCompliance=1.8\nproject@com.oracle.truffle.js.test@workingSets=Truffle,JavaScript,Test\n\n# truffle.js.engine\nproject@com.oracle.truffle.js.engine@subDir=graal\nproject@com.oracle.truffle.js.engine@sourceDirs=src\nproject@com.oracle.truffle.js.engine@dependencies=JLINE,com.oracle.truffle.js.parser,com.oracle.truffle.multilang\nproject@com.oracle.truffle.js.engine@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.js.engine@annotationProcessors=com.oracle.truffle.multilang\nproject@com.oracle.truffle.js.engine@javaCompliance=1.8\nproject@com.oracle.truffle.js.engine@workingSets=Truffle,JavaScript\n\n# truffle.ruby.runtime\nproject@com.oracle.truffle.ruby.runtime@subDir=graal\nproject@com.oracle.truffle.ruby.runtime@sourceDirs=src\nproject@com.oracle.truffle.ruby.runtime@dependencies=JRUBYSTDLIB,JNR_POSIX,JNR_CONSTANTS,JNR_FFI,JFFI,JFFI_NATIVE,JNR_X86ASM,ASM,ASM_ANALYSIS,ASM_COMMONS,ASM_TREE,ASM_UTIL,com.oracle.truffle.api\nproject@com.oracle.truffle.ruby.runtime@javaCompliance=1.7\nproject@com.oracle.truffle.ruby.runtime@workingSets=Truffle,Ruby\n\n# truffle.ruby.nodes\nproject@com.oracle.truffle.ruby.nodes@subDir=graal\nproject@com.oracle.truffle.ruby.nodes@sourceDirs=src\nproject@com.oracle.truffle.ruby.nodes@dependencies=com.oracle.truffle.ruby.runtime,com.oracle.truffle.api.dsl\nproject@com.oracle.truffle.ruby.nodes@checkstyle=com.oracle.truffle.ruby.runtime\nproject@com.oracle.truffle.ruby.nodes@javaCompliance=1.7\nproject@com.oracle.truffle.ruby.nodes@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.truffle.ruby.nodes@workingSets=Truffle,Ruby\n\n# truffle.ruby.parser\nproject@com.oracle.truffle.ruby.parser@subDir=graal\nproject@com.oracle.truffle.ruby.parser@sourceDirs=src\nproject@com.oracle.truffle.ruby.parser@dependencies=JRUBYPARSER,com.oracle.truffle.ruby.nodes\nproject@com.oracle.truffle.ruby.parser@checkstyle=com.oracle.truffle.ruby.runtime\nproject@com.oracle.truffle.ruby.parser@javaCompliance=1.7\nproject@com.oracle.truffle.ruby.parser@workingSets=Truffle,Ruby\n\n# truffle.ruby.shell\nproject@com.oracle.truffle.ruby.shell@subDir=graal\nproject@com.oracle.truffle.ruby.shell@sourceDirs=src\nproject@com.oracle.truffle.ruby.shell@dependencies=JLINE,com.oracle.truffle.ruby.parser\nproject@com.oracle.truffle.ruby.shell@checkstyle=com.oracle.truffle.ruby.runtime\nproject@com.oracle.truffle.ruby.shell@javaCompliance=1.7\nproject@com.oracle.truffle.ruby.shell@workingSets=Truffle,Ruby\n\n# truffle.ruby.repl\nproject@com.oracle.truffle.ruby.repl@subDir=graal\nproject@com.oracle.truffle.ruby.repl@sourceDirs=src\nproject@com.oracle.truffle.ruby.repl@dependencies=com.oracle.truffle.repl,com.oracle.truffle.ruby.shell\nproject@com.oracle.truffle.ruby.repl@checkstyle=com.oracle.truffle.ruby.runtime\nproject@com.oracle.truffle.ruby.repl@javaCompliance=1.7\nproject@com.oracle.truffle.ruby.repl@workingSets=Truffle,Ruby\n\n# truffle.ruby.test\nproject@com.oracle.truffle.ruby.test@subDir=graal\nproject@com.oracle.truffle.ruby.test@sourceDirs=src\nproject@com.oracle.truffle.ruby.test@dependencies=com.oracle.truffle.ruby.shell,JUNIT\nproject@com.oracle.truffle.ruby.test@checkstyle=com.oracle.truffle.ruby.runtime\nproject@com.oracle.truffle.ruby.test@javaCompliance=1.7\nproject@com.oracle.truffle.ruby.test@workingSets=Truffle,Ruby,Test\n\n# truffle.nodejs.runtime\nproject@com.oracle.truffle.nodejs.runtime@subDir=graal\nproject@com.oracle.truffle.nodejs.runtime@sourceDirs=src\nproject@com.oracle.truffle.nodejs.runtime@dependencies=com.oracle.truffle.js.parser\nproject@com.oracle.truffle.nodejs.runtime@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.nodejs.runtime@javaCompliance=1.8\nproject@com.oracle.truffle.nodejs.runtime@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.truffle.nodejs.runtime@workingSets=Truffle,JavaScript\n\n# truffle.nodejs.test\nproject@com.oracle.truffle.nodejs.test@subDir=graal\nproject@com.oracle.truffle.nodejs.test@sourceDirs=src\nproject@com.oracle.truffle.nodejs.test@dependencies=com.oracle.truffle.nodejs.runtime,JUNIT\nproject@com.oracle.truffle.nodejs.test@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.nodejs.test@javaCompliance=1.8\nproject@com.oracle.truffle.nodejs.test@workingSets=Truffle,JavaScript,Test\n\n# truffle.js.px\nproject@com.oracle.truffle.js.px@subDir=graal\nproject@com.oracle.truffle.js.px@sourceDirs=src\nproject@com.oracle.truffle.js.px@dependencies=com.oracle.truffle.js.shell\nproject@com.oracle.truffle.js.px@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.js.px@javaCompliance=1.8\nproject@com.oracle.truffle.js.px@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.truffle.js.px@workingSets=Truffle,JavaScript\n\n# truffle.js.px.test\nproject@com.oracle.truffle.js.px.test@subDir=graal\nproject@com.oracle.truffle.js.px.test@sourceDirs=src\nproject@com.oracle.truffle.js.px.test@dependencies=com.oracle.truffle.js.px,JUNIT\nproject@com.oracle.truffle.js.px.test@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.js.px.test@javaCompliance=1.8\nproject@com.oracle.truffle.js.px.test@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.truffle.js.px.test@workingSets=Truffle,JavaScript\n\n# truffle.regex\nproject@com.oracle.truffle.regex@subDir=graal\nproject@com.oracle.truffle.regex@sourceDirs=src\nproject@com.oracle.truffle.regex@dependencies=com.oracle.truffle.api,NASHORN_JONI_REGEX\nproject@com.oracle.truffle.regex@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.regex@javaCompliance=1.8\nproject@com.oracle.truffle.regex@workingSets=Truffle,Regex\n\n# truffle.regex.test\nproject@com.oracle.truffle.regex.test@subDir=graal\nproject@com.oracle.truffle.regex.test@sourceDirs=src\nproject@com.oracle.truffle.regex.test@dependencies=com.oracle.truffle.regex,JUNIT\nproject@com.oracle.truffle.regex.test@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.regex.test@javaCompliance=1.8\nproject@com.oracle.truffle.regex.test@workingSets=Truffle,Regex\n\n# truffle.debug\nproject@com.oracle.truffle.debug@subDir=graal\nproject@com.oracle.truffle.debug@sourceDirs=src\nproject@com.oracle.truffle.debug@dependencies=com.oracle.truffle.api\nproject@com.oracle.truffle.debug@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.debug@javaCompliance=1.7\nproject@com.oracle.truffle.debug@workingSets=Truffle,REPL\n\n# truffle.repl\nproject@com.oracle.truffle.repl@subDir=graal\nproject@com.oracle.truffle.repl@sourceDirs=src\nproject@com.oracle.truffle.repl@dependencies=JLINE,com.oracle.truffle.debug\nproject@com.oracle.truffle.repl@checkstyle=com.oracle.truffle.repl\nproject@com.oracle.truffle.repl@javaCompliance=1.7\nproject@com.oracle.truffle.repl@workingSets=Truffle,REPL\n\n# graal.truffle.hotspot\nproject@com.oracle.graal.truffle.hotspot@subDir=graal\nproject@com.oracle.graal.truffle.hotspot@sourceDirs=src\nproject@com.oracle.graal.truffle.hotspot@dependencies=com.oracle.graal.truffle,com.oracle.graal.hotspot\nproject@com.oracle.graal.truffle.hotspot@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.truffle.hotspot@javaCompliance=1.8\nproject@com.oracle.graal.truffle.hotspot@annotationProcessors=com.oracle.graal.service.processor\nproject@com.oracle.graal.truffle.hotspot@workingSets=Graal,Truffle\n\n# graal.truffle.hotspot.amd64\nproject@com.oracle.graal.truffle.hotspot.amd64@subDir=graal\nproject@com.oracle.graal.truffle.hotspot.amd64@sourceDirs=src\nproject@com.oracle.graal.truffle.hotspot.amd64@dependencies=com.oracle.graal.truffle.hotspot,com.oracle.graal.asm.amd64\nproject@com.oracle.graal.truffle.hotspot.amd64@checkstyle=com.oracle.graal.graph\nproject@com.oracle.graal.truffle.hotspot.amd64@javaCompliance=1.8\nproject@com.oracle.graal.truffle.hotspot.amd64@annotationProcessors=com.oracle.graal.service.processor\nproject@com.oracle.graal.truffle.hotspot.amd64@workingSets=Graal,Truffle\n\n# truffle.avatar.js.runtime\nproject@com.oracle.truffle.avatar.js.runtime@subDir=graal\nproject@com.oracle.truffle.avatar.js.runtime@sourceDirs=src\nproject@com.oracle.truffle.avatar.js.runtime@dependencies=com.oracle.truffle.js.engine,AVATAR_JS\nproject@com.oracle.truffle.avatar.js.runtime@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.avatar.js.runtime@javaCompliance=1.8\nproject@com.oracle.truffle.avatar.js.runtime@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.truffle.avatar.js.runtime@workingSets=Truffle,Avatar,JavaScript\n\n# truffle.multilang\nproject@com.oracle.truffle.multilang@subDir=graal\nproject@com.oracle.truffle.multilang@sourceDirs=src\nproject@com.oracle.truffle.multilang@dependencies=com.oracle.truffle.api.interop\nproject@com.oracle.truffle.multilang@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.multilang@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.truffle.multilang@javaCompliance=1.8\nproject@com.oracle.truffle.multilang@workingSets=Truffle\n\n# truffle.jruby\nproject@com.oracle.truffle.jruby@subDir=graal\nproject@com.oracle.truffle.jruby@sourceDirs=src\nproject@com.oracle.truffle.jruby@dependencies=com.oracle.truffle.api,JRUBY\nproject@com.oracle.truffle.jruby@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.jruby@javaCompliance=1.7\nproject@com.oracle.truffle.jruby@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.truffle.jruby@workingSets=Truffle\n\n# truffle.walnut\nproject@com.oracle.truffle.walnut@subDir=graal\nproject@com.oracle.truffle.walnut@sourceDirs=src\nproject@com.oracle.truffle.walnut@dependencies=com.oracle.truffle.api.dsl,com.oracle.graal.word\nproject@com.oracle.truffle.walnut@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.walnut@javaCompliance=1.8\nproject@com.oracle.truffle.walnut@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.truffle.walnut@workingSets=Truffle,Walnut\n\n# truffle.walnut.test\nproject@com.oracle.truffle.walnut.test@subDir=graal\nproject@com.oracle.truffle.walnut.test@sourceDirs=src\nproject@com.oracle.truffle.walnut.test@dependencies=com.oracle.truffle.walnut,JUNIT\nproject@com.oracle.truffle.walnut.test@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.truffle.walnut.test@javaCompliance=1.8\nproject@com.oracle.truffle.walnut.test@workingSets=Truffle,Walnut,Test\n\n# svm.core\nproject@com.oracle.svm.core@subDir=graal\nproject@com.oracle.svm.core@sourceDirs=src\nproject@com.oracle.svm.core@dependencies=com.oracle.objectfile,com.oracle.svm.systemjava\nproject@com.oracle.svm.core@javaCompliance=1.8\nproject@com.oracle.svm.core@workingSets=SVM\n\n# svm.core.graal\nproject@com.oracle.svm.core.graal@subDir=graal\nproject@com.oracle.svm.core.graal@sourceDirs=src\nproject@com.oracle.svm.core.graal@dependencies=com.oracle.graal.compiler.amd64,com.oracle.svm.core.dis,com.oracle.graal.replacements.amd64,com.oracle.graal.printer\nproject@com.oracle.svm.core.graal@checkstyle=com.oracle.svm.core\nproject@com.oracle.svm.core.graal@javaCompliance=1.8\nproject@com.oracle.svm.core.graal@workingSets=SVM\n\n# svm.core.posix\nproject@com.oracle.svm.core.posix@subDir=graal\nproject@com.oracle.svm.core.posix@sourceDirs=src\nproject@com.oracle.svm.core.posix@dependencies=com.oracle.svm.core\nproject@com.oracle.svm.core.posix@checkstyle=com.oracle.svm.core\nproject@com.oracle.svm.core.posix@javaCompliance=1.8\nproject@com.oracle.svm.core.posix@workingSets=SVM\n\n# svm.hosted.analysis\nproject@com.oracle.svm.hosted.analysis@subDir=graal\nproject@com.oracle.svm.hosted.analysis@sourceDirs=src\nproject@com.oracle.svm.hosted.analysis@dependencies=com.oracle.svm.core.graal,com.oracle.svm.hosted.systemjava\nproject@com.oracle.svm.hosted.analysis@checkstyle=com.oracle.svm.hosted\nproject@com.oracle.svm.hosted.analysis@javaCompliance=1.8\nproject@com.oracle.svm.hosted.analysis@workingSets=SVM\n\n# svm.test.analysis\nproject@com.oracle.svm.test.analysis@subDir=graal\nproject@com.oracle.svm.test.analysis@sourceDirs=src\nproject@com.oracle.svm.test.analysis@dependencies=JUNIT,com.oracle.svm.hosted\nproject@com.oracle.svm.test.analysis@checkstyle=com.oracle.svm.hosted\nproject@com.oracle.svm.test.analysis@javaCompliance=1.8\nproject@com.oracle.svm.test.analysis@workingSets=SVM,Test\n\n# svm.hosted\nproject@com.oracle.svm.hosted@subDir=graal\nproject@com.oracle.svm.hosted@sourceDirs=src\nproject@com.oracle.svm.hosted@dependencies=com.oracle.svm.core.posix,com.oracle.svm.debug,com.oracle.svm.hosted.analysis,com.oracle.graal.runtime,GSON\nproject@com.oracle.svm.hosted@javaCompliance=1.8\nproject@com.oracle.svm.hosted@workingSets=SVM\n\n# svm.native\nproject@com.oracle.svm.native@subDir=graal\nproject@com.oracle.svm.native@sourceDirs=\nproject@com.oracle.svm.native@native=true\nproject@com.oracle.svm.native@workingSets=SVM\nproject@com.oracle.svm.native@javaCompliance=1.8\n\n# svm.jnr\nproject@com.oracle.svm.jnr@subDir=graal\nproject@com.oracle.svm.jnr@sourceDirs=src\nproject@com.oracle.svm.jnr@dependencies=com.oracle.svm.graal,JNR_INVOKE,JFFI,JFFI_NATIVE\nproject@com.oracle.svm.jnr@checkstyle=com.oracle.svm.core\nproject@com.oracle.svm.jnr@workingSets=SVM\nproject@com.oracle.svm.jnr@javaCompliance=1.8\n\n# svm.test\nproject@com.oracle.svm.test@subDir=graal\nproject@com.oracle.svm.test@sourceDirs=src\nproject@com.oracle.svm.test@dependencies=com.oracle.truffle.walnut.test,com.oracle.svm.jtt,com.oracle.svm.truffle.walnut,com.oracle.svm.truffle.sl,com.oracle.svm.truffle.js,com.oracle.svm.jnr\nproject@com.oracle.svm.test@checkstyle=com.oracle.svm.hosted\nproject@com.oracle.svm.test@javaCompliance=1.8\nproject@com.oracle.svm.test@workingSets=SVM,Test\n\n# svm.systemjava.demo\nproject@com.oracle.svm.systemjava.demo@subDir=graal\nproject@com.oracle.svm.systemjava.demo@sourceDirs=src\nproject@com.oracle.svm.systemjava.demo@dependencies=com.oracle.svm.core\nproject@com.oracle.svm.systemjava.demo@checkstyle=com.oracle.svm.core\nproject@com.oracle.svm.systemjava.demo@javaCompliance=1.8\nproject@com.oracle.svm.systemjava.demo@workingSets=SVM\n\n# svm.debug\nproject@com.oracle.svm.debug@subDir=graal\nproject@com.oracle.svm.debug@sourceDirs=src\nproject@com.oracle.svm.debug@dependencies=com.oracle.objectfile\nproject@com.oracle.svm.debug@checkstyle=com.oracle.svm.hosted\nproject@com.oracle.svm.debug@javaCompliance=1.8\nproject@com.oracle.svm.debug@workingSets=SVM\n\n# svm.debug.test\nproject@com.oracle.svm.debug.test@subDir=graal\nproject@com.oracle.svm.debug.test@sourceDirs=src\nproject@com.oracle.svm.debug.test@dependencies=com.oracle.svm.test\nproject@com.oracle.svm.debug.test@checkstyle=com.oracle.svm.hosted\nproject@com.oracle.svm.debug.test@javaCompliance=1.8\nproject@com.oracle.svm.debug.test@workingSets=SVM,Test\n\n# svm.jtt\nproject@com.oracle.svm.jtt@subDir=graal\nproject@com.oracle.svm.jtt@sourceDirs=src\nproject@com.oracle.svm.jtt@dependencies=JUNIT\nproject@com.oracle.svm.jtt@checkstyle=com.oracle.graal.graph\nproject@com.oracle.svm.jtt@javaCompliance=1.8\nproject@com.oracle.svm.jtt@workingSets=SVM,Test\n\n# com.oracle.objectfile\nproject@com.oracle.objectfile@subDir=graal\nproject@com.oracle.objectfile@sourceDirs=src\nproject@com.oracle.objectfile@dependencies=\nproject@com.oracle.objectfile@checkstyle=com.oracle.svm.hosted\nproject@com.oracle.objectfile@javaCompliance=1.8\nproject@com.oracle.objectfile@workingSets=SVM\n\n# com.oracle.objectfile.test\nproject@com.oracle.objectfile.test@subDir=graal\nproject@com.oracle.objectfile.test@sourceDirs=src\nproject@com.oracle.objectfile.test@dependencies=com.oracle.objectfile,JUNIT\nproject@com.oracle.objectfile.test@checkstyle=com.oracle.svm.hosted\nproject@com.oracle.objectfile.test@javaCompliance=1.8\nproject@com.oracle.objectfile.test@workingSets=SVM,Test\n\n# svm.graal\nproject@com.oracle.svm.graal@subDir=graal\nproject@com.oracle.svm.graal@sourceDirs=src\nproject@com.oracle.svm.graal@dependencies=com.oracle.svm.hosted,com.oracle.truffle.api\nproject@com.oracle.svm.graal@checkstyle=com.oracle.svm.hosted\nproject@com.oracle.svm.graal@javaCompliance=1.8\n\n# svm.truffle\nproject@com.oracle.svm.truffle@subDir=graal\nproject@com.oracle.svm.truffle@sourceDirs=src\nproject@com.oracle.svm.truffle@dependencies=com.oracle.svm.graal,com.oracle.graal.truffle\nproject@com.oracle.svm.truffle@checkstyle=com.oracle.svm.core\nproject@com.oracle.svm.truffle@javaCompliance=1.8\nproject@com.oracle.svm.truffle@workingSets=SVM\n\n# svm.truffle.sl\nproject@com.oracle.svm.truffle.sl@subDir=graal\nproject@com.oracle.svm.truffle.sl@sourceDirs=src\nproject@com.oracle.svm.truffle.sl@dependencies=com.oracle.truffle.sl.test,com.oracle.svm.truffle\nproject@com.oracle.svm.truffle.sl@checkstyle=com.oracle.svm.core\nproject@com.oracle.svm.truffle.sl@javaCompliance=1.8\nproject@com.oracle.svm.truffle.sl@workingSets=SVM\n\n# svm.truffle.jline\nproject@com.oracle.svm.truffle.jline@subDir=graal\nproject@com.oracle.svm.truffle.jline@sourceDirs=src\nproject@com.oracle.svm.truffle.jline@dependencies=com.oracle.svm.core,JLINE\nproject@com.oracle.svm.truffle.jline@checkstyle=com.oracle.svm.core\nproject@com.oracle.svm.truffle.jline@javaCompliance=1.8\nproject@com.oracle.svm.truffle.jline@workingSets=SVM\n\n# jnr.posix\nproject@jnr.posix@subDir=graal\nproject@jnr.posix@sourceDirs=src\nproject@jnr.posix@dependencies=JNR_POSIX,JNR_CONSTANTS,com.oracle.svm.core\nproject@jnr.posix@checkstyle=com.oracle.svm.core\nproject@jnr.posix@javaCompliance=1.8\nproject@jnr.posix@workingSets=SVM\n\nlibrary@YYDEBUG@path=lib/yydebug.jar\nlibrary@YYDEBUG@urls=http://lafo.ssw.uni-linz.ac.at/svm/yydebug.jar\nlibrary@YYDEBUG@sha1=7e7d8d64baf115fb1e4cce27e7a6a3a72f1e6ab0\n\n# svm.truffle.ruby\nproject@com.oracle.svm.truffle.ruby@subDir=graal\nproject@com.oracle.svm.truffle.ruby@sourceDirs=src\nproject@com.oracle.svm.truffle.ruby@dependencies=com.oracle.svm.truffle,com.oracle.svm.truffle.jline,com.oracle.truffle.ruby.shell,jnr.posix,YYDEBUG\nproject@com.oracle.svm.truffle.ruby@checkstyle=com.oracle.svm.core\nproject@com.oracle.svm.truffle.ruby@javaCompliance=1.8\nproject@com.oracle.svm.truffle.ruby@workingSets=SVM\n\n# svm.truffle.js\nproject@com.oracle.svm.truffle.js@subDir=graal\nproject@com.oracle.svm.truffle.js@sourceDirs=src\nproject@com.oracle.svm.truffle.js@dependencies=com.oracle.svm.truffle,com.oracle.svm.truffle.jline,com.oracle.truffle.js.shell,com.oracle.truffle.js.test\nproject@com.oracle.svm.truffle.js@checkstyle=com.oracle.svm.core\nproject@com.oracle.svm.truffle.js@javaCompliance=1.8\nproject@com.oracle.svm.truffle.js@workingSets=SVM\n\n# svm.truffle.walnut\nproject@com.oracle.svm.truffle.walnut@subDir=graal\nproject@com.oracle.svm.truffle.walnut@sourceDirs=src\nproject@com.oracle.svm.truffle.walnut@dependencies=com.oracle.svm.truffle,com.oracle.truffle.walnut\nproject@com.oracle.svm.truffle.walnut@checkstyle=com.oracle.svm.core\nproject@com.oracle.svm.truffle.walnut@javaCompliance=1.8\nproject@com.oracle.svm.truffle.walnut@workingSets=SVM\n\n# walnut.db\nproject@com.oracle.walnut.db@subDir=graal\nproject@com.oracle.walnut.db@sourceDirs=src\nproject@com.oracle.walnut.db@dependencies=com.oracle.walnut.db.hosted\nproject@com.oracle.walnut.db@checkstyle=com.oracle.svm.core\nproject@com.oracle.walnut.db@javaCompliance=1.8\nproject@com.oracle.walnut.db@workingSets=SVM\n\n\n# walnut.db.mockup\nproject@com.oracle.walnut.db.mockup@subDir=graal\nproject@com.oracle.walnut.db.mockup@sourceDirs=src\nproject@com.oracle.walnut.db.mockup@dependencies=com.oracle.walnut.db\nproject@com.oracle.walnut.db.mockup@checkstyle=com.oracle.svm.core\nproject@com.oracle.walnut.db.mockup@javaCompliance=1.8\nproject@com.oracle.walnut.db.mockup@workingSets=SVM\n\n# walnut.db.hosted\nproject@com.oracle.walnut.db.hosted@subDir=graal\nproject@com.oracle.walnut.db.hosted@sourceDirs=src\nproject@com.oracle.walnut.db.hosted@dependencies=com.oracle.svm.hosted\nproject@com.oracle.walnut.db.hosted@checkstyle=com.oracle.svm.hosted\nproject@com.oracle.walnut.db.hosted@javaCompliance=1.8\nproject@com.oracle.walnut.db.hosted@workingSets=SVM\n\n# walnut.db.codegen\nproject@com.oracle.walnut.db.codegen@subDir=graal\nproject@com.oracle.walnut.db.codegen@sourceDirs=src\nproject@com.oracle.walnut.db.codegen@dependencies=com.oracle.walnut.db,com.oracle.svm.truffle.walnut\nproject@com.oracle.walnut.db.codegen@checkstyle=com.oracle.svm.core\nproject@com.oracle.walnut.db.codegen@javaCompliance=1.8\nproject@com.oracle.walnut.db.codegen@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.walnut.db.codegen@workingSets=SVM\n\n# walnut.db.qshtest\nproject@com.oracle.walnut.db.qshtest@subDir=graal\nproject@com.oracle.walnut.db.qshtest@sourceDirs=\nproject@com.oracle.walnut.db.qshtest@native=true\nproject@com.oracle.walnut.db.qshtest@javaCompliance=1.8\nproject@com.oracle.walnut.db.qshtest@workingSets=SVM\n\n# walnut.db.servlet.walnut\nproject@com.oracle.walnut.db.servlet.walnut@subDir=graal\nproject@com.oracle.walnut.db.servlet.walnut@sourceDirs=src\nproject@com.oracle.walnut.db.servlet.walnut@dependencies=com.oracle.walnut.db.codegen\nproject@com.oracle.walnut.db.servlet.walnut@checkstyle=com.oracle.svm.core\nproject@com.oracle.walnut.db.servlet.walnut@javaCompliance=1.8\nproject@com.oracle.walnut.db.servlet.walnut@workingSets=SVM\n\n# svm.systemjava\nproject@com.oracle.svm.systemjava@subDir=graal\nproject@com.oracle.svm.systemjava@sourceDirs=src\nproject@com.oracle.svm.systemjava@dependencies=com.oracle.graal.word\nproject@com.oracle.svm.systemjava@checkstyle=com.oracle.svm.core\nproject@com.oracle.svm.systemjava@javaCompliance=1.8\nproject@com.oracle.svm.systemjava@workingSets=SVM\n\n# svm.hosted.systemjava\nproject@com.oracle.svm.hosted.systemjava@subDir=graal\nproject@com.oracle.svm.hosted.systemjava@sourceDirs=src\nproject@com.oracle.svm.hosted.systemjava@dependencies=com.oracle.svm.core\nproject@com.oracle.svm.hosted.systemjava@checkstyle=com.oracle.svm.hosted\nproject@com.oracle.svm.hosted.systemjava@javaCompliance=1.8\nproject@com.oracle.svm.hosted.systemjava@workingSets=SVM\n\n# svm.hosted.systemjava.test\nproject@com.oracle.svm.hosted.systemjava.test@subDir=graal\nproject@com.oracle.svm.hosted.systemjava.test@sourceDirs=src\nproject@com.oracle.svm.hosted.systemjava.test@dependencies=com.oracle.svm.hosted.systemjava,com.oracle.graal.runtime,JUNIT\nproject@com.oracle.svm.hosted.systemjava.test@checkstyle=com.oracle.svm.hosted\nproject@com.oracle.svm.hosted.systemjava.test@javaCompliance=1.8\nproject@com.oracle.svm.hosted.systemjava.test@workingSets=SVM,Test\n\nlibrary@APACHE_COMMONS_CLI@path=lib/dacapo/commons-cli-1.2.jar\nlibrary@APACHE_COMMONS_CLI@sha1=2bf96b7aa8b611c177d329452af1dc933e14501c\n\nlibrary@APACHE_COMMONS_CODEC@path=lib/dacapo/commons-codec-1.9.jar\nlibrary@APACHE_COMMONS_CODEC@sha1=9ce04e34240f674bc72680f8b843b1457383161a\n\nlibrary@DACAPO_ECLIPSE@path=lib/dacapo/eclipse.jar\nlibrary@DACAPO_ECLIPSE@sha1=2aa90c8ec7df6963cd8fe9db554b7387f769ee43\n\nlibrary@BATIK_JS@path=lib/dacapo/js.jar\nlibrary@BATIK_JS@sha1=fafe983596fa93f81392232fd25209e419cb5c43\nlibrary@BATIK_PDF_TRANSCODER@path=lib/dacapo/pdf-transcoder.jar\nlibrary@BATIK_PDF_TRANSCODER@sha1=a1ca304d9b6842bddbc160a45150590b82b762e7\n\nlibrary@XML_APIS_EXT@path=lib/dacapo/xml-apis-ext.jar\nlibrary@XML_APIS_EXT@sha1=41a8b86b358e87f3f13cf46069721719105aff66\nlibrary@XML_APIS@path=lib/dacapo/xml-apis.jar\nlibrary@XML_APIS@sha1=3845d5aabd62dc1954f2c0e84a799068c917ad2b\n\nlibrary@CRIMSON@path=lib/dacapo/crimson-1.1.3.jar\nlibrary@CRIMSON@sha1=31e3dac9777abfec809ad9315f8b5d283cd46c40\n\n# library@XERCES@path=lib/dacapo/xerces_2_5_0.jar\nlibrary@XERCES@path=lib/dacapo/xercesImpl-2.11.0.jar\nlibrary@XERCES@urls=http://repo1.maven.org/maven2/xerces/xercesImpl/2.11.0/xercesImpl-2.11.0.jar\nlibrary@XERCES@sha1=9bb329db1cfc4e22462c9d6b43a8432f5850e92c\n\n# library@XALAN@path=lib/dacapo/xalan-2.6.0.jar\nlibrary@XALAN@path=lib/dacapo/xalan-2.7.1-Java1.7.jar\nlibrary@XALAN@sha1=74b222785c72e165a777e99dac317350e76de918\nlibrary@XALAN@sourcePath=lib/dacapo/xalan-2.7.1-sources.jar\nlibrary@XALAN@sourceUrls=http://search.maven.org/remotecontent?filepath=xalan/xalan/2.7.1/xalan-2.7.1-sources.jar\nlibrary@XALAN@sourceSha1=b1f9b407f3593c99ae2b137bb0733761fcee6595\n\nlibrary@SERIALIZER@path=lib/dacapo/serializer-2.7.1-Java1.7.jar\nlibrary@SERIALIZER@sha1=747c62796500d0f2c050c198882a9b369c58c1c4\n\nlibrary@JANINO@path=lib/dacapo/janino-2.5.12.jar\nlibrary@JANINO@sha1=caac0fef033df417258a1ee0602aa7c7542a3745\n\nlibrary@LUCENE_DEMOS@path=lib/dacapo/lucene-demos-2.4.jar\nlibrary@LUCENE_DEMOS@sha1=369807e598f1cd6d4c269d1ebdee84dc9b9836a6\n\nlibrary@GANYMED_SSH2@path=lib/dacapo/ganymed-ssh2-261.jar\nlibrary@GANYMED_SSH2@sha1=b99f1ff40a31b0c7d74bf02648cfb437054f9518\n\n#Spec jars\nlibrary@SPEC_TIDY@path=lib/spec/Tidy.jar\nlibrary@SPEC_TIDY@sha1=90db10d857c642114d428675f3d324721b5fd636\n\nlibrary@SPEC_ANT@path=lib/spec/ant.jar\nlibrary@SPEC_ANT@sha1=19933481ba52bd7801aa83262c42b9468129522f\n\nlibrary@SPEC_DERBY@path=lib/spec/derby.jar\nlibrary@SPEC_DERBY@sha1=a272d77b70e0a06e80bde631bda4bbcaaad4e4ba\n\nlibrary@SPEC_JAVAC@path=lib/spec/javac.jar\nlibrary@SPEC_JAVAC@sha1=1ada7a6219d5644cabe7ac6914a40330e1c58f29\n\nlibrary@SPEC_JFREECHART@path=lib/spec/jfreechart-1.0.5.jar\nlibrary@SPEC_JFREECHART@sha1=2f242ae92d9f8896a04a69f368983dd2967d29b5\n\nlibrary@SPEC_SUNFLOW@path=lib/spec/sunflow.jar\nlibrary@SPEC_SUNFLOW@sha1=53679131b4715832a80810d0efe532ffa261cd4e\n\nlibrary@SPEC_ANT_LAUNCHER@path=lib/spec/ant-launcher.jar\nlibrary@SPEC_ANT_LAUNCHER@sha1=9c1f7dd6a21962e80ed7f720fc73e04454606e45\n\nlibrary@SPEC_CHECK@path=lib/spec/check.jar\nlibrary@SPEC_CHECK@sha1=c27f627651d94db50c711d000effc925f36c2e32\n\nlibrary@SPEC_JANINO@path=lib/spec/janino.jar\nlibrary@SPEC_JANINO@sha1=826179e63b2e0aea6c8fac07a00b08e82df2f778\n\nlibrary@SPEC_JCOMMON@path=lib/spec/jcommon-1.0.9.jar\nlibrary@SPEC_JCOMMON@sha1=f5371fb29f4c765fa4f8db43f373f99fb4da1cc9\n\nlibrary@SPEC_JL1@path=lib/spec/jl1.0.jar\nlibrary@SPEC_JL1@sha1=a6abafe8f0889abd269a53e2b131c1b9d987bc5d\n\nlibrary@SPEC_XOM@path=lib/spec/xom-1.1.jar\nlibrary@SPEC_XOM@sha1=ad9af4b7b397666effa5a8e64dd7e902cbdafc83\n\nlibrary@SPEC_JVM_2008@path=lib/spec/SPECjvm2008.jar\nlibrary@SPEC_JVM_2008@sha1=7f0faa2657f45d639c19fcf9c633a3b77085d52f\n\nlibrary@GSON@path=lib/gson-2.2.4.jar\nlibrary@GSON@urls=http://search.maven.org/remotecontent?filepath=com/google/code/gson/gson/2.2.4/gson-2.2.4.jar\nlibrary@GSON@sha1=a60a5e993c98c864010053cb901b7eab25306568\nlibrary@GSON@sourcePath=lib/dacapo/gson-2.2.4-sources.jar\nlibrary@GSON@sourceUrls=http://search.maven.org/remotecontent?filepath=com/google/code/gson/gson/2.2.4/gson-2.2.4-sources.jar\nlibrary@GSON@sourceSha1=a6dc5db8a12928e583bd3f23e72d3ab611ecd58f\n\n# org.dacapo\nproject@org.dacapo@subDir=dacapo\nproject@org.dacapo@sourceDirs=src,resources\nproject@org.dacapo@dependencies=com.oracle.svm.core,JUNIT,GANYMED_SSH2,APACHE_COMMONS_CLI,APACHE_COMMONS_CODEC\nproject@org.dacapo@javaCompliance=1.7\nproject@org.dacapo@workingSets=Dacapo,SVMBench\n\n# org.dacapo.avrora\nproject@org.dacapo.avrora@subDir=dacapo\nproject@org.dacapo.avrora@sourceDirs=src,resources\nproject@org.dacapo.avrora@dependencies=org.dacapo,avrora\nproject@org.dacapo.avrora@checkstyle=org.dacapo\nproject@org.dacapo.avrora@javaCompliance=1.7\nproject@org.dacapo.avrora@workingSets=Dacapo,SVMBench\n\n# avrora\nproject@avrora@subDir=dacapo\nproject@avrora@sourceDirs=src\nproject@avrora@dependencies=cck\nproject@avrora@checkstyle=org.dacapo\nproject@avrora@javaCompliance=1.7\nproject@avrora@workingSets=Dacapo,SVMBench\n\n# jintgen\nproject@jintgen@subDir=dacapo\nproject@jintgen@sourceDirs=src\nproject@jintgen@dependencies=cck\nproject@jintgen@checkstyle=org.dacapo\nproject@jintgen@javaCompliance=1.7\nproject@jintgen@workingSets=Dacapo,SVMBench\n\n# cck\nproject@cck@subDir=dacapo\nproject@cck@sourceDirs=src\nproject@cck@dependencies=\nproject@cck@checkstyle=org.dacapo\nproject@cck@javaCompliance=1.7\nproject@cck@workingSets=Dacapo,SVMBench\n\n# org.dacapo.batik\nproject@org.dacapo.batik@subDir=dacapo\nproject@org.dacapo.batik@sourceDirs=src,resources\nproject@org.dacapo.batik@dependencies=org.dacapo,org.apache.batik\nproject@org.dacapo.batik@checkstyle=org.dacapo\nproject@org.dacapo.batik@javaCompliance=1.7\nproject@org.dacapo.batik@workingSets=Dacapo,SVMBench\n\n# org.apache.batik\nproject@org.apache.batik@subDir=dacapo\nproject@org.apache.batik@sourceDirs=sources,soruces-1.3,sources-1.4,test-sources,resources,test-resources\nproject@org.apache.batik@dependencies=org.w3c.dom.events,XML_APIS_EXT,XML_APIS,CRIMSON,XERCES,XALAN,SERIALIZER,BATIK_PDF_TRANSCODER,BATIK_JS\nproject@org.apache.batik@checkstyle=org.dacapo\nproject@org.apache.batik@javaCompliance=1.7\nproject@org.apache.batik@workingSets=Dacapo,SVMBench\n\n# org.w3c.dom.events\nproject@org.w3c.dom.events@subDir=dacapo\nproject@org.w3c.dom.events@sourceDirs=src\nproject@org.w3c.dom.events@dependencies=\nproject@org.w3c.dom.events@checkstyle=org.dacapo\nproject@org.w3c.dom.events@javaCompliance=1.7\nproject@org.w3c.dom.events@workingSets=Dacapo,SVMBench\n\n# org.dacapo.sunflow\nproject@org.dacapo.sunflow@subDir=dacapo\nproject@org.dacapo.sunflow@sourceDirs=src,resources\nproject@org.dacapo.sunflow@dependencies=org.dacapo,org.sunflow\nproject@org.dacapo.sunflow@checkstyle=org.dacapo\nproject@org.dacapo.sunflow@javaCompliance=1.7\nproject@org.dacapo.sunflow@workingSets=Dacapo,SVMBench\n\n# org.sunflow\nproject@org.sunflow@subDir=dacapo\nproject@org.sunflow@sourceDirs=src,resources\nproject@org.sunflow@dependencies=JANINO\nproject@org.sunflow@checkstyle=org.dacapo\nproject@org.sunflow@javaCompliance=1.7\nproject@org.sunflow@workingSets=Dacapo,SVMBench\n\n# org.dacapo.lunidex\nproject@org.dacapo.luindex@subDir=dacapo\nproject@org.dacapo.luindex@sourceDirs=src,resources\nproject@org.dacapo.luindex@dependencies=org.dacapo,org.apache.lucene,LUCENE_DEMOS\nproject@org.dacapo.luindex@checkstyle=org.dacapo\nproject@org.dacapo.luindex@javaCompliance=1.7\nproject@org.dacapo.luindex@workingSets=Dacapo,SVMBench\n\n# org.dacapo.lusearch\nproject@org.dacapo.lusearch@subDir=dacapo\nproject@org.dacapo.lusearch@sourceDirs=src,resources\nproject@org.dacapo.lusearch@dependencies=org.dacapo,org.apache.lucene\nproject@org.dacapo.lusearch@checkstyle=org.dacapo\nproject@org.dacapo.lusearch@javaCompliance=1.7\nproject@org.dacapo.lusearch@workingSets=Dacapo,SVMBench\n\n# org.apache.lucene (org.apache.lucene.core)\nproject@org.apache.lucene@subDir=dacapo\nproject@org.apache.lucene@sourceDirs=src\nproject@org.apache.lucene@dependencies=\nproject@org.apache.lucene@checkstyle=org.dacapo\nproject@org.apache.lucene@javaCompliance=1.7\nproject@org.apache.lucene@workingSets=Dacapo,SVMBench\n\n# org.dacapo.eclipse\nproject@org.dacapo.eclipse@subDir=dacapo\nproject@org.dacapo.eclipse@sourceDirs=src,resources\nproject@org.dacapo.eclipse@dependencies=org.dacapo,DACAPO_ECLIPSE\nproject@org.dacapo.eclipse@checkstyle=org.dacapo\nproject@org.dacapo.eclipse@javaCompliance=1.7\nproject@org.dacapo.eclipse@workingSets=Dacapo,SVMBench\n\n# spec\nproject@spec@subDir=spec\nproject@spec@sourceDirs=src,resources\nproject@spec@dependencies=SPEC_TIDY,SPEC_ANT,SPEC_DERBY,SPEC_JAVAC,SPEC_JFREECHART,SPEC_SUNFLOW,SPEC_ANT_LAUNCHER,SPEC_CHECK,SPEC_JANINO,SPEC_JCOMMON,SPEC_JL1,SPEC_XOM\nproject@spec@checkstyle=org.dacapo\nproject@spec@javaCompliance=1.7\nproject@spec@workingSets=Spec,SVMBench\n\n# svm.bench.spec\nproject@com.oracle.svm.bench.spec@subDir=spec\nproject@com.oracle.svm.bench.spec@sourceDirs=src,resources\nproject@com.oracle.svm.bench.spec@dependencies=com.oracle.svm.core,spec\nproject@com.oracle.svm.bench.spec@checkstyle=org.dacapo\nproject@com.oracle.svm.bench.spec@javaCompliance=1.7\nproject@com.oracle.svm.bench.spec@workingSets=Spec,SVMBench\n\n# jolden\nproject@jolden@subDir=jolden\nproject@jolden@sourceDirs=src\nproject@jolden@dependencies=\nproject@jolden@checkstyle=org.dacapo\nproject@jolden@javaCompliance=1.7\nproject@jolden@workingSets=Jolden,SVMBench\n\n# svm.bench.jolden\nproject@com.oracle.svm.bench.jolden@subDir=jolden\nproject@com.oracle.svm.bench.jolden@sourceDirs=src\nproject@com.oracle.svm.bench.jolden@dependencies=com.oracle.svm.systemjava,jolden\nproject@com.oracle.svm.bench.jolden@checkstyle=org.dacapo\nproject@com.oracle.svm.bench.jolden@javaCompliance=1.7\nproject@com.oracle.svm.bench.jolden@workingSets=Jolden,SVMBench\n\n# svm.core.dis\n# use dependencies to DISTORM directly, instead of dependencies to com.oracle.svm.core.dis.native as the latter makes eclipse unhappy\nproject@com.oracle.svm.core.dis@subDir=graal\nproject@com.oracle.svm.core.dis@sourceDirs=src\nproject@com.oracle.svm.core.dis@dependencies=com.oracle.svm.core,DISTORM\nproject@com.oracle.svm.core.dis@javaCompliance=1.8\nproject@com.oracle.svm.core.dis@checkstyle=com.oracle.truffle.js.runtime\nproject@com.oracle.svm.core.dis@workingSets=SVM\n\n# Sources for distorm\nlibrary@DISTORM@path=lib/distorm3-3-sdist.zip\nlibrary@DISTORM@urls=http://distorm.googlecode.com/files/distorm3-3-sdist.zip\nlibrary@DISTORM@sha1=ddcadd68821f6f1b87e02bd26bd80f560872df6d\n\n# svm.core.dis.native\nproject@com.oracle.svm.core.dis.native@subDir=graal\nproject@com.oracle.svm.core.dis.native@sourceDirs=\nproject@com.oracle.svm.core.dis.native@dependencies=DISTORM\nproject@com.oracle.svm.core.dis.native@javaCompliance=1.8\nproject@com.oracle.svm.core.dis.native@workingSets=SVM\nproject@com.oracle.svm.core.dis.native@native=true\n","markers":{"markers":{"1":{"id":1,"range":[[1399,0],[1399,0]],"tailed":false,"reversed":true,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":804,"autoscroll":true,"goalBufferRange":null,"preserveFolds":true},"deserializer":"Marker"},"2":{"id":2,"range":[[1271,28],[1271,28]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":302,"autoscroll":true,"goalBufferRange":null,"preserveFolds":true},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/zwei/Workspace/oracle/fastr-svm-home/graal/mx/projects","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"ac492a2e3e091128ac7c98e4d65e0503e67b789f","deserializer":"TextBuffer"},{"text":"\n#\n# commands.py - the GraalVM specific commands\n#\n# ----------------------------------------------------------------------------------------------------\n#\n# Copyright (c) 2007, 2012, Oracle and/or its affiliates. All rights reserved.\n# DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n#\n# This code is free software; you can redistribute it and/or modify it\n# under the terms of the GNU General Public License version 2 only, as\n# published by the Free Software Foundation.\n#\n# This code is distributed in the hope that it will be useful, but WITHOUT\n# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n# version 2 for more details (a copy is included in the LICENSE file that\n# accompanied this code).\n#\n# You should have received a copy of the GNU General Public License version\n# 2 along with this work; if not, write to the Free Software Foundation,\n# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n#\n# Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n# or visit www.oracle.com if you need additional information or have any\n# questions.\n#\n# ----------------------------------------------------------------------------------------------------\n\nimport os, stat, errno, sys, shutil, zipfile, tarfile, tempfile, re, time, datetime, platform, subprocess, multiprocessing, StringIO, socket, difflib\nfrom os.path import join, exists, isdir, dirname, basename, getmtime\nfrom argparse import ArgumentParser, RawDescriptionHelpFormatter, REMAINDER\nfrom outputparser import OutputParser, ValuesMatcher\nimport mx\nimport xml.dom.minidom\nimport sanitycheck\nimport itertools\nimport json, textwrap\nimport fnmatch\n\n# This works because when mx loads this file, it makes sure __file__ gets an absolute path\n_graal_home = dirname(dirname(__file__))\n\n\"\"\" Used to distinguish an exported GraalVM (see 'mx export'). \"\"\"\n_vmSourcesAvailable = exists(join(_graal_home, 'make')) and exists(join(_graal_home, 'src'))\n\n\"\"\" The VMs that can be built and run along with an optional description. Only VMs with a\n    description are listed in the dialogue for setting the default VM (see _get_vm()). \"\"\"\n_vmChoices = {\n    'graal' : 'Normal compilation is performed with a tiered system (C1 + Graal), Truffle compilation is performed with Graal.',\n    'server' : 'Normal compilation is performed with a tiered system (C1 + C2), Truffle compilation is performed with Graal. Use this for optimal Truffle performance.',\n    'client' : None,  # normal compilation with client compiler, explicit compilation (e.g., by Truffle) with Graal\n    'server-nograal' : None,  # all compilation with tiered system (i.e., client + server), Graal omitted\n    'client-nograal' : None,  # all compilation with client compiler, Graal omitted\n    'original' : None,  # default VM copied from bootstrap JDK\n}\n\n\"\"\" The VM that will be run by the 'vm' command and built by default by the 'build' command.\n    This can be set via the global '--vm' option or the DEFAULT_VM environment variable.\n    It can also be temporarily set by using of a VM context manager object in a 'with' statement. \"\"\"\n_vm = 'server'\n\n\"\"\" The VM builds that will be run by the 'vm' command - default is first in list \"\"\"\n_vmbuildChoices = ['product', 'fastdebug', 'debug', 'optimized']\n\n\"\"\" The VM build that will be run by the 'vm' command.\n    This can be set via the global '--vmbuild' option.\n    It can also be temporarily set by using of a VM context manager object in a 'with' statement. \"\"\"\n_vmbuild = _vmbuildChoices[0]\n\n_jacoco = 'off'\n\n\"\"\" The current working directory to switch to before running the VM. \"\"\"\n_vm_cwd = None\n\n\"\"\" The base directory in which the JDKs cloned from $JAVA_HOME exist. \"\"\"\n_installed_jdks = None\n\n\"\"\" Prefix for running the VM. \"\"\"\n_vm_prefix = None\n\n_make_eclipse_launch = False\n\n_minVersion = mx.VersionSpec('1.8')\n\nJDK_UNIX_PERMISSIONS = 0755\n\ndef isVMSupported(vm):\n    if 'client' in vm and len(platform.mac_ver()[0]) != 0:\n        # Client VM not supported: java launcher on Mac OS X translates '-client' to '-server'\n        return False\n    return True\n\ndef _get_vm():\n    \"\"\"\n    Gets the configured VM, presenting a dialogue if there is no currently configured VM.\n    \"\"\"\n    global _vm\n    if _vm:\n        return _vm\n    vm = mx.get_env('DEFAULT_VM')\n    if vm is None:\n        if not sys.stdout.isatty():\n            mx.abort('Need to specify VM with --vm option or DEFAULT_VM environment variable')\n        envPath = join(_graal_home, 'mx', 'env')\n        mx.log('Please select the VM to be executed from the following: ')\n        items = [k for k in _vmChoices.keys() if _vmChoices[k] is not None]\n        descriptions = [_vmChoices[k] for k in _vmChoices.keys() if _vmChoices[k] is not None]\n        vm = mx.select_items(items, descriptions, allowMultiple=False)\n        if mx.ask_yes_no('Persist this choice by adding \"DEFAULT_VM=' + vm + '\" to ' + envPath, 'y'):\n            with open(envPath, 'a') as fp:\n                print >> fp, 'DEFAULT_VM=' + vm\n    _vm = vm\n    return vm\n\n\"\"\"\nA context manager that can be used with the 'with' statement to set the VM\nused by all VM executions within the scope of the 'with' statement. For example:\n\n    with VM('server'):\n        dacapo(['pmd'])\n\"\"\"\nclass VM:\n    def __init__(self, vm=None, build=None):\n        assert vm is None or vm in _vmChoices.keys()\n        assert build is None or build in _vmbuildChoices\n        self.vm = vm if vm else _vm\n        self.build = build if build else _vmbuild\n        self.previousVm = _vm\n        self.previousBuild = _vmbuild\n\n    def __enter__(self):\n        global _vm, _vmbuild\n        _vm = self.vm\n        _vmbuild = self.build\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        global _vm, _vmbuild\n        _vm = self.previousVm\n        _vmbuild = self.previousBuild\n\ndef _chmodDir(chmodFlags, dirname, fnames):\n    os.chmod(dirname, chmodFlags)\n    for name in fnames:\n        os.chmod(os.path.join(dirname, name), chmodFlags)\n\ndef chmodRecursive(dirname, chmodFlags):\n    os.path.walk(dirname, _chmodDir, chmodFlags)\n\ndef clean(args):\n    \"\"\"clean the GraalVM source tree\"\"\"\n    opts = mx.clean(args, parser=ArgumentParser(prog='mx clean'))\n\n    if opts.native:\n        def handleRemoveReadonly(func, path, exc):\n            excvalue = exc[1]\n            if mx.get_os() == 'windows' and func in (os.rmdir, os.remove) and excvalue.errno == errno.EACCES:\n                os.chmod(path, stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)  # 0777\n                func(path)\n            else:\n                raise\n\n        def rmIfExists(name):\n            if os.path.isdir(name):\n                shutil.rmtree(name, ignore_errors=False, onerror=handleRemoveReadonly)\n            elif os.path.isfile(name):\n                os.unlink(name)\n\n        rmIfExists(join(_graal_home, 'build'))\n        rmIfExists(join(_graal_home, 'build-nograal'))\n        rmIfExists(_jdksDir())\n\ndef export(args):\n    \"\"\"create archives of builds split by vmbuild and vm\"\"\"\n\n    parser = ArgumentParser(prog='mx export')\n    args = parser.parse_args(args)\n\n    # collect data about export\n    infos = dict()\n    infos['timestamp'] = time.time()\n\n    hgcfg = mx.HgConfig()\n    hgcfg.check()\n    infos['revision'] = hgcfg.tip('.') + ('+' if hgcfg.isDirty('.') else '')\n    # TODO: infos['repository']\n\n    infos['jdkversion'] = str(mx.java().version)\n\n    infos['architecture'] = _arch()\n    infos['platform'] = mx.get_os()\n\n    if mx.get_os != 'windows':\n        pass\n        # infos['ccompiler']\n        # infos['linker']\n\n    infos['hostname'] = socket.gethostname()\n\n    def _writeJson(suffix, properties):\n        d = infos.copy()\n        for k, v in properties.iteritems():\n            assert not d.has_key(k)\n            d[k] = v\n\n        jsonFileName = 'export-' + suffix + '.json'\n        with open(jsonFileName, 'w') as f:\n            print >> f, json.dumps(d)\n        return jsonFileName\n\n\n    def _genFileName(archivtype, middle):\n        idPrefix = infos['revision'] + '_'\n        idSuffix = '.tar.gz'\n        return join(_graal_home, \"graalvm_\" + archivtype + \"_\" + idPrefix + middle + idSuffix)\n\n    def _genFileArchPlatformName(archivtype, middle):\n        return _genFileName(archivtype, infos['platform'] + '_' + infos['architecture'] + '_' + middle)\n\n\n    # archive different build types of hotspot\n    for vmBuild in _vmbuildChoices:\n        jdkpath = join(_jdksDir(), vmBuild)\n        if not exists(jdkpath):\n            mx.logv(\"skipping \" + vmBuild)\n            continue\n\n        tarName = _genFileArchPlatformName('basejdk', vmBuild)\n        mx.logv(\"creating basejdk \" + tarName)\n        vmSet = set()\n        with tarfile.open(tarName, 'w:gz') as tar:\n            for root, _, files in os.walk(jdkpath):\n                if basename(root) in _vmChoices.keys():\n                    # TODO: add some assert to check path assumption\n                    vmSet.add(root)\n                    continue\n\n                for f in files:\n                    name = join(root, f)\n                    # print name\n                    tar.add(name, name)\n\n            n = _writeJson(\"basejdk-\" + vmBuild, {'vmbuild' : vmBuild})\n            tar.add(n, n)\n\n        # create a separate archive for each VM\n        for vm in vmSet:\n            bVm = basename(vm)\n            vmTarName = _genFileArchPlatformName('vm', vmBuild + '_' + bVm)\n            mx.logv(\"creating vm \" + vmTarName)\n\n            debugFiles = set()\n            with tarfile.open(vmTarName, 'w:gz') as tar:\n                for root, _, files in os.walk(vm):\n                    for f in files:\n                        # TODO: mac, windows, solaris?\n                        if any(map(f.endswith, [\".debuginfo\"])):\n                            debugFiles.add(f)\n                        else:\n                            name = join(root, f)\n                            # print name\n                            tar.add(name, name)\n\n                n = _writeJson(\"vm-\" + vmBuild + \"-\" + bVm, {'vmbuild' : vmBuild, 'vm' : bVm})\n                tar.add(n, n)\n\n            if len(debugFiles) > 0:\n                debugTarName = _genFileArchPlatformName('debugfilesvm', vmBuild + '_' + bVm)\n                mx.logv(\"creating debugfilesvm \" + debugTarName)\n                with tarfile.open(debugTarName, 'w:gz') as tar:\n                    for f in debugFiles:\n                        name = join(root, f)\n                        # print name\n                        tar.add(name, name)\n\n                    n = _writeJson(\"debugfilesvm-\" + vmBuild + \"-\" + bVm, {'vmbuild' : vmBuild, 'vm' : bVm})\n                    tar.add(n, n)\n\n    # graal directory\n    graalDirTarName = _genFileName('classfiles', 'javac')\n    mx.logv(\"creating graal \" + graalDirTarName)\n    with tarfile.open(graalDirTarName, 'w:gz') as tar:\n        for root, _, files in os.walk(\"graal\"):\n            for f in [f for f in files if not f.endswith('.java')]:\n                name = join(root, f)\n                # print name\n                tar.add(name, name)\n\n        n = _writeJson(\"graal\", {'javacompiler' : 'javac'})\n        tar.add(n, n)\n\n\ndef _run_benchmark(args, availableBenchmarks, runBenchmark):\n\n    vmOpts, benchmarksAndOptions = _extract_VM_args(args, useDoubleDash=availableBenchmarks is None)\n\n    if availableBenchmarks is None:\n        harnessArgs = benchmarksAndOptions\n        return runBenchmark(None, harnessArgs, vmOpts)\n\n    if len(benchmarksAndOptions) == 0:\n        mx.abort('at least one benchmark name or \"all\" must be specified')\n    benchmarks = list(itertools.takewhile(lambda x: not x.startswith('-'), benchmarksAndOptions))\n    harnessArgs = benchmarksAndOptions[len(benchmarks):]\n\n    if 'all' in benchmarks:\n        benchmarks = availableBenchmarks\n    else:\n        for bm in benchmarks:\n            if bm not in availableBenchmarks:\n                mx.abort('unknown benchmark: ' + bm + '\\nselect one of: ' + str(availableBenchmarks))\n\n    failed = []\n    for bm in benchmarks:\n        if not runBenchmark(bm, harnessArgs, vmOpts):\n            failed.append(bm)\n\n    if len(failed) != 0:\n        mx.abort('Benchmark failures: ' + str(failed))\n\ndef dacapo(args):\n    \"\"\"run one or more DaCapo benchmarks\"\"\"\n\n    def launcher(bm, harnessArgs, extraVmOpts):\n        return sanitycheck.getDacapo(bm, harnessArgs).test(_get_vm(), extraVmOpts=extraVmOpts)\n\n    _run_benchmark(args, sanitycheck.dacapoSanityWarmup.keys(), launcher)\n\ndef scaladacapo(args):\n    \"\"\"run one or more Scala DaCapo benchmarks\"\"\"\n\n    def launcher(bm, harnessArgs, extraVmOpts):\n        return sanitycheck.getScalaDacapo(bm, harnessArgs).test(_get_vm(), extraVmOpts=extraVmOpts)\n\n    _run_benchmark(args, sanitycheck.dacapoScalaSanityWarmup.keys(), launcher)\n\ndef _arch():\n    machine = platform.uname()[4]\n    if machine in ['amd64', 'AMD64', 'x86_64', 'i86pc']:\n        return 'amd64'\n    if machine in ['sun4v', 'sun4u']:\n        return 'sparcv9'\n    if machine == 'i386' and mx.get_os() == 'darwin':\n        try:\n            # Support for Snow Leopard and earlier version of MacOSX\n            if subprocess.check_output(['sysctl', '-n', 'hw.cpu64bit_capable']).strip() == '1':\n                return 'amd64'\n        except OSError:\n            # sysctl is not available\n            pass\n    mx.abort('unknown or unsupported architecture: os=' + mx.get_os() + ', machine=' + machine)\n\ndef _vmLibDirInJdk(jdk):\n    \"\"\"\n    Get the directory within a JDK where the server and client\n    subdirectories are located.\n    \"\"\"\n    if platform.system() == 'Darwin':\n        return join(jdk, 'jre', 'lib')\n    if platform.system() == 'Windows':\n        return join(jdk, 'jre', 'bin')\n    return join(jdk, 'jre', 'lib', _arch())\n\ndef _vmCfgInJdk(jdk):\n    \"\"\"\n    Get the jvm.cfg file.\n    \"\"\"\n    if platform.system() == 'Windows':\n        return join(jdk, 'jre', 'lib', _arch(), 'jvm.cfg')\n    return join(_vmLibDirInJdk(jdk), 'jvm.cfg')\n\ndef _jdksDir():\n    return os.path.abspath(join(_installed_jdks if _installed_jdks else _graal_home, 'jdk' + str(mx.java().version)))\n\ndef _handle_missing_VM(bld, vm):\n    mx.log('The ' + bld + ' ' + vm + ' VM has not been created')\n    if sys.stdout.isatty():\n        if mx.ask_yes_no('Build it now', 'y'):\n            with VM(vm, bld):\n                build([])\n            return\n    mx.abort('You need to run \"mx --vm ' + vm + ' --vmbuild ' + bld + ' build\" to build the selected VM')\n\ndef _jdk(build='product', vmToCheck=None, create=False, installGraalJar=True):\n    \"\"\"\n    Get the JDK into which Graal is installed, creating it first if necessary.\n    \"\"\"\n    jdk = join(_jdksDir(), build)\n    if create:\n        srcJdk = mx.java().jdk\n        if not exists(jdk):\n            mx.log('Creating ' + jdk + ' from ' + srcJdk)\n            shutil.copytree(srcJdk, jdk)\n\n            # Make a copy of the default VM so that this JDK can be\n            # reliably used as the bootstrap for a HotSpot build.\n            jvmCfg = _vmCfgInJdk(jdk)\n            if not exists(jvmCfg):\n                mx.abort(jvmCfg + ' does not exist')\n\n            defaultVM = None\n            jvmCfgLines = []\n            with open(jvmCfg) as f:\n                for line in f:\n                    if line.startswith('-') and defaultVM is None:\n                        parts = line.split()\n                        if len(parts) == 2:\n                            assert parts[1] == 'KNOWN', parts[1]\n                            defaultVM = parts[0][1:]\n                            jvmCfgLines += ['# default VM is a copy of the unmodified ' + defaultVM + ' VM\\n']\n                            jvmCfgLines += ['-original KNOWN\\n']\n                        else:\n                            # skip lines which we cannot parse (e.g. '-hotspot ALIASED_TO -client')\n                            mx.log(\"WARNING: skipping not parsable line \\\"\" + line + \"\\\"\")\n                    else:\n                        jvmCfgLines += [line]\n\n            assert defaultVM is not None, 'Could not find default VM in ' + jvmCfg\n            if mx.get_os() != 'windows':\n                chmodRecursive(jdk, JDK_UNIX_PERMISSIONS)\n            shutil.move(join(_vmLibDirInJdk(jdk), defaultVM), join(_vmLibDirInJdk(jdk), 'original'))\n\n\n            with open(jvmCfg, 'w') as fp:\n                for line in jvmCfgLines:\n                    fp.write(line)\n\n            # patch 'release' file (append graalvm revision)\n            releaseFile = join(jdk, 'release')\n            if exists(releaseFile):\n                releaseFileLines = []\n                with open(releaseFile) as f:\n                    for line in f:\n                        releaseFileLines.append(line)\n\n                with open(releaseFile, 'w') as fp:\n                    for line in releaseFileLines:\n                        if line.startswith(\"SOURCE=\"):\n                            try:\n                                sourceLine = line[0:-2]  # remove last char\n                                hgcfg = mx.HgConfig()\n                                hgcfg.check()\n                                revision = hgcfg.tip('.')[:12]  # take first 12 chars\n                                fp.write(sourceLine + ' graal:' + revision + '\\\"\\n')\n                            except:\n                                fp.write(line)\n                        else:\n                            fp.write(line)\n\n            # Install a copy of the disassembler library\n            try:\n                hsdis([], copyToDir=_vmLibDirInJdk(jdk))\n            except SystemExit:\n                pass\n    else:\n        if not exists(jdk):\n            if _installed_jdks:\n                mx.log(\"The selected JDK directory does not (yet) exist: \" + jdk)\n            _handle_missing_VM(build, vmToCheck if vmToCheck else 'graal')\n\n    if installGraalJar:\n        _installGraalJarInJdks(mx.distribution('GRAAL'))\n        _installGraalJarInJdks(mx.distribution('GRAAL_LOADER'))\n\n    if vmToCheck is not None:\n        jvmCfg = _vmCfgInJdk(jdk)\n        found = False\n        with open(jvmCfg) as f:\n            for line in f:\n                if line.strip() == '-' + vmToCheck + ' KNOWN':\n                    found = True\n                    break\n        if not found:\n            _handle_missing_VM(build, vmToCheck)\n\n    return jdk\n\ndef _updateInstalledGraalOptionsFile(jdk):\n    graalOptions = join(_graal_home, 'graal.options')\n    jreLibDir = join(jdk, 'jre', 'lib')\n    if exists(graalOptions):\n        shutil.copy(graalOptions, join(jreLibDir, 'graal.options'))\n    else:\n        toDelete = join(jreLibDir, 'graal.options')\n        if exists(toDelete):\n            os.unlink(toDelete)\n\ndef _update_graalRuntime_inline_hpp(graalJar):\n    p = mx.project('com.oracle.graal.hotspot.sourcegen')\n    mainClass = 'com.oracle.graal.hotspot.sourcegen.GenGraalRuntimeInlineHpp'\n    if exists(join(p.output_dir(), mainClass.replace('.', os.sep) + '.class')):\n        hsSrcGenDir = join(mx.project('com.oracle.graal.hotspot').source_gen_dir(), 'hotspot')\n        if not exists(hsSrcGenDir):\n            os.makedirs(hsSrcGenDir)\n\n        tmp = StringIO.StringIO()\n        mx.run_java(['-cp', '{}{}{}'.format(graalJar, os.pathsep, p.output_dir()), mainClass], out=tmp.write)\n        mx.update_file(join(hsSrcGenDir, 'graalRuntime.inline.hpp'), tmp.getvalue())\n\ndef _installGraalJarInJdks(graalDist):\n    graalJar = graalDist.path\n    if graalJar.endswith('graal.jar'):\n        _update_graalRuntime_inline_hpp(graalJar)\n    jdks = _jdksDir()\n\n    if exists(jdks):\n        for e in os.listdir(jdks):\n            jreLibDir = join(jdks, e, 'jre', 'lib')\n            if exists(jreLibDir):\n                def install(srcJar, dstDir):\n                    name = os.path.basename(srcJar)\n                    dstJar = join(dstDir, name)\n                    if mx.get_env('SYMLINK_GRAAL_JAR', None) == 'true':\n                        # Using symlinks is much faster than copying but may\n                        # cause issues if graal.jar is being updated while\n                        # the VM is running.\n                        if not os.path.islink(dstJar) or not os.path.realpath(dstJar) == srcJar:\n                            if exists(dstJar):\n                                os.remove(dstJar)\n                            os.symlink(srcJar, dstJar)\n                    else:\n                        # do a copy and then a move to get atomic updating (on Unix)\n                        fd, tmp = tempfile.mkstemp(suffix='', prefix=name, dir=dstDir)\n                        shutil.copyfile(srcJar, tmp)\n                        os.close(fd)\n                        shutil.move(tmp, dstJar)\n                        os.chmod(dstJar, JDK_UNIX_PERMISSIONS)\n\n                install(graalJar, jreLibDir)\n                if graalDist.sourcesPath:\n                    install(graalDist.sourcesPath, join(jdks, e))\n\n# run a command in the windows SDK Debug Shell\ndef _runInDebugShell(cmd, workingDir, logFile=None, findInOutput=None, respondTo=None):\n    if respondTo is None:\n        respondTo = {}\n    newLine = os.linesep\n    startToken = 'RUNINDEBUGSHELL_STARTSEQUENCE'\n    endToken = 'RUNINDEBUGSHELL_ENDSEQUENCE'\n\n    winSDK = mx.get_env('WIN_SDK', 'C:\\\\Program Files\\\\Microsoft SDKs\\\\Windows\\\\v7.1\\\\')\n\n    if not exists(winSDK):\n        mx.abort(\"Could not find Windows SDK : '\" + winSDK + \"' does not exist\")\n\n    if not exists(join(winSDK, 'Bin', 'SetEnv.cmd')):\n        mx.abort(\"Invalid Windows SDK path (\" + winSDK + \") : could not find Bin/SetEnv.cmd (you can use the WIN_SDK environment variable to specify an other path)\")\n\n    p = subprocess.Popen('cmd.exe /E:ON /V:ON /K \"\"' + winSDK + '/Bin/SetEnv.cmd\" & echo ' + startToken + '\"', \\\n            shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, creationflags=subprocess.CREATE_NEW_PROCESS_GROUP)\n    stdout = p.stdout\n    stdin = p.stdin\n    if logFile:\n        log = open(logFile, 'w')\n    ret = False\n    while True:\n\n        # encoding may be None on windows plattforms\n        if sys.stdout.encoding is None:\n            encoding = 'utf-8'\n        else:\n            encoding = sys.stdout.encoding\n\n        line = stdout.readline().decode(encoding)\n        if logFile:\n            log.write(line.encode('utf-8'))\n        line = line.strip()\n        mx.log(line)\n        if line == startToken:\n            stdin.write('cd /D ' + workingDir + ' & ' + cmd + ' & echo ' + endToken + newLine)\n        for regex in respondTo.keys():\n            match = regex.search(line)\n            if match:\n                stdin.write(respondTo[regex] + newLine)\n        if findInOutput:\n            match = findInOutput.search(line)\n            if match:\n                ret = True\n        if line == endToken:\n            if not findInOutput:\n                stdin.write('echo ERRXXX%errorlevel%' + newLine)\n            else:\n                break\n        if line.startswith('ERRXXX'):\n            if line == 'ERRXXX0':\n                ret = True\n            break\n    stdin.write('exit' + newLine)\n    if logFile:\n        log.close()\n    return ret\n\ndef jdkhome(vm=None):\n    \"\"\"return the JDK directory selected for the 'vm' command\"\"\"\n    build = _vmbuild if _vmSourcesAvailable else 'product'\n    return _jdk(build, installGraalJar=False)\n\ndef print_jdkhome(args, vm=None):\n    \"\"\"print the JDK directory selected for the 'vm' command\"\"\"\n    print jdkhome(vm)\n\ndef buildvars(args):\n    \"\"\"describe the variables that can be set by the -D option to the 'mx build' commmand\"\"\"\n\n    buildVars = {\n        'ALT_BOOTDIR' : 'The location of the bootstrap JDK installation (default: ' + mx.java().jdk + ')',\n        'ALT_OUTPUTDIR' : 'Build directory',\n        'HOTSPOT_BUILD_JOBS' : 'Number of CPUs used by make (default: ' + str(multiprocessing.cpu_count()) + ')',\n        'INSTALL' : 'Install the built VM into the JDK? (default: y)',\n        'ZIP_DEBUGINFO_FILES' : 'Install zipped debug symbols file? (default: 0)',\n    }\n\n    mx.log('HotSpot build variables that can be set by the -D option to \"mx build\":')\n    mx.log('')\n    for n in sorted(buildVars.iterkeys()):\n        mx.log(n)\n        mx.log(textwrap.fill(buildVars[n], initial_indent='    ', subsequent_indent='    ', width=200))\n\n    mx.log('')\n    mx.log('Note that these variables can be given persistent values in the file ' + join(_graal_home, 'mx', 'env') + ' (see \\'mx about\\').')\n\ndef build(args, vm=None):\n    \"\"\"build the VM binary\n\n    The global '--vm' and '--vmbuild' options select which VM type and build target to build.\"\"\"\n\n    # Override to fail quickly if extra arguments are given\n    # at the end of the command line. This allows for a more\n    # helpful error message.\n    class AP(ArgumentParser):\n        def __init__(self):\n            ArgumentParser.__init__(self, prog='mx build')\n        def parse_args(self, args):\n            result = ArgumentParser.parse_args(self, args)\n            if len(result.remainder) != 0:\n                firstBuildTarget = result.remainder[0]\n                mx.abort('To specify the ' + firstBuildTarget + ' VM build target, you need to use the global \"--vmbuild\" option. For example:\\n' +\n                         '    mx --vmbuild ' + firstBuildTarget + ' build')\n            return result\n\n    # Call mx.build to compile the Java sources\n    parser = AP()\n    parser.add_argument('--export-dir', help='directory to which graal.jar and graal.options will be copied', metavar='<path>')\n    parser.add_argument('-D', action='append', help='set a HotSpot build variable (run \\'mx buildvars\\' to list variables)', metavar='name=value')\n    opts2 = mx.build(['--source', '1.7'] + args, parser=parser)\n    assert len(opts2.remainder) == 0\n\n    if opts2.export_dir is not None:\n        if not exists(opts2.export_dir):\n            os.makedirs(opts2.export_dir)\n        else:\n            assert os.path.isdir(opts2.export_dir), '{} is not a directory'.format(opts2.export_dir)\n\n        shutil.copy(mx.distribution('GRAAL').path, opts2.export_dir)\n        shutil.copy(mx.distribution('GRAAL_LOADER').path, opts2.export_dir)\n        graalOptions = join(_graal_home, 'graal.options')\n        if exists(graalOptions):\n            shutil.copy(graalOptions, opts2.export_dir)\n\n    if not _vmSourcesAvailable or not opts2.native:\n        return\n\n    builds = [_vmbuild]\n\n    if vm is None:\n        vm = _get_vm()\n\n    if vm == 'original':\n        pass\n    elif vm.startswith('server'):\n        buildSuffix = ''\n    elif vm.startswith('client'):\n        buildSuffix = '1'\n    else:\n        assert vm == 'graal', vm\n        buildSuffix = 'graal'\n\n    if _installed_jdks and _installed_jdks != _graal_home:\n        if not mx.ask_yes_no(\"Warning: building while --installed-jdks is set (\" + _installed_jdks + \") is not recommanded - are you sure you want to continue\", 'n'):\n            mx.abort(1)\n\n    for build in builds:\n        if build == 'ide-build-target':\n            build = os.environ.get('IDE_BUILD_TARGET', None)\n            if build is None or len(build) == 0:\n                continue\n\n        jdk = _jdk(build, create=True)\n\n        if vm == 'original':\n            if build != 'product':\n                mx.log('only product build of original VM exists')\n            continue\n\n        if not isVMSupported(vm):\n            mx.log('The ' + vm + ' VM is not supported on this platform - skipping')\n            continue\n\n        vmDir = join(_vmLibDirInJdk(jdk), vm)\n        if not exists(vmDir):\n            if mx.get_os() != 'windows':\n                chmodRecursive(jdk, JDK_UNIX_PERMISSIONS)\n            mx.log('Creating VM directory in JDK: ' + vmDir)\n            os.makedirs(vmDir)\n\n        def filterXusage(line):\n            if not 'Xusage.txt' in line:\n                sys.stderr.write(line + os.linesep)\n\n        # Check if a build really needs to be done\n        timestampFile = join(vmDir, '.build-timestamp')\n        if opts2.force or not exists(timestampFile):\n            mustBuild = True\n        else:\n            mustBuild = False\n            timestamp = os.path.getmtime(timestampFile)\n            sources = []\n            for d in ['src', 'make', join('graal', 'com.oracle.graal.hotspot', 'src_gen', 'hotspot')]:\n                for root, dirnames, files in os.walk(join(_graal_home, d)):\n                    # ignore <graal>/src/share/tools\n                    if root == join(_graal_home, 'src', 'share'):\n                        dirnames.remove('tools')\n                    sources += [join(root, name) for name in files]\n            for f in sources:\n                if len(f) != 0 and os.path.getmtime(f) > timestamp:\n                    mustBuild = True\n                    break\n\n        if not mustBuild:\n            mx.logv('[all files in src and make directories are older than ' + timestampFile[len(_graal_home) + 1:] + ' - skipping native build]')\n            continue\n\n        if platform.system() == 'Windows':\n            compilelogfile = _graal_home + '/graalCompile.log'\n            mksHome = mx.get_env('MKS_HOME', 'C:\\\\cygwin\\\\bin')\n\n            variant = {'client': 'compiler1', 'server': 'compiler2'}.get(vm, vm)\n            project_config = variant + '_' + build\n            _runInDebugShell('msbuild ' + _graal_home + r'\\build\\vs-amd64\\jvm.vcproj /p:Configuration=' + project_config + ' /target:clean', _graal_home)\n            winCompileCmd = r'set HotSpotMksHome=' + mksHome + r'& set OUT_DIR=' + jdk + r'& set JAVA_HOME=' + jdk + r'& set path=%JAVA_HOME%\\bin;%path%;%HotSpotMksHome%& cd /D \"' + _graal_home + r'\\make\\windows\"& call create.bat ' + _graal_home\n            print winCompileCmd\n            winCompileSuccess = re.compile(r\"^Writing \\.vcxproj file:\")\n            if not _runInDebugShell(winCompileCmd, _graal_home, compilelogfile, winCompileSuccess):\n                mx.log('Error executing create command')\n                return\n            winBuildCmd = 'msbuild ' + _graal_home + r'\\build\\vs-amd64\\jvm.vcxproj /p:Configuration=' + project_config + ' /p:Platform=x64'\n            if not _runInDebugShell(winBuildCmd, _graal_home, compilelogfile):\n                mx.log('Error building project')\n                return\n        else:\n            cpus = multiprocessing.cpu_count()\n            makeDir = join(_graal_home, 'make')\n            runCmd = [mx.gmake_cmd(), '-C', makeDir]\n\n            env = os.environ.copy()\n\n            # These must be passed as environment variables\n            env.setdefault('LANG', 'C')\n            env['JAVA_HOME'] = jdk\n\n            def setMakeVar(name, default, env=None):\n                \"\"\"Sets a make variable on the command line to the value\n                   of the variable in 'env' with the same name if defined\n                   and 'env' is not None otherwise to 'default'\n                \"\"\"\n                runCmd.append(name + '=' + (env.get(name, default) if env else default))\n\n            if opts2.D:\n                for nv in opts2.D:\n                    name, value = nv.split('=', 1)\n                    setMakeVar(name.strip(), value)\n\n            setMakeVar('ARCH_DATA_MODEL', '64', env=env)\n            setMakeVar('HOTSPOT_BUILD_JOBS', str(cpus), env=env)\n            setMakeVar('ALT_BOOTDIR', mx.java().jdk, env=env)\n\n            setMakeVar('MAKE_VERBOSE', 'y' if mx._opts.verbose else '')\n            if vm.endswith('nograal'):\n                setMakeVar('INCLUDE_GRAAL', 'false')\n                setMakeVar('ALT_OUTPUTDIR', join(_graal_home, 'build-nograal', mx.get_os()), env=env)\n            else:\n                # extract latest release tag for graal\n                try:\n                    tags = [x.split(' ')[0] for x in subprocess.check_output(['hg', '-R', _graal_home, 'tags']).split('\\n') if x.startswith(\"graal-\")]\n                except:\n                    # not a mercurial repository or hg commands are not available.\n                    tags = None\n\n                if tags:\n                    # extract the most recent tag\n                    tag = sorted(tags, key=lambda e: [int(x) for x in e[len(\"graal-\"):].split('.')], reverse=True)[0]\n                    setMakeVar('USER_RELEASE_SUFFIX', tag)\n                    setMakeVar('GRAAL_VERSION', tag[len(\"graal-\"):])\n                else:\n                    version = 'unknown-{}-{}'.format(platform.node(), time.strftime('%Y-%m-%d_%H-%M-%S_%Z'))\n                    setMakeVar('USER_RELEASE_SUFFIX', 'graal-' + version)\n                    setMakeVar('GRAAL_VERSION', version)\n                setMakeVar('INCLUDE_GRAAL', 'true')\n            setMakeVar('INSTALL', 'y', env=env)\n            if mx.get_os() == 'solaris':\n                # If using sparcWorks, setup flags to avoid make complaining about CC version\n                cCompilerVersion = subprocess.Popen('CC -V', stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True).stderr.readlines()[0]\n                if cCompilerVersion.startswith('CC: Sun C++'):\n                    compilerRev = cCompilerVersion.split(' ')[3]\n                    setMakeVar('ENFORCE_COMPILER_REV', compilerRev, env=env)\n                    setMakeVar('ENFORCE_CC_COMPILER_REV', compilerRev, env=env)\n                    if build == 'jvmg':\n                        # We want ALL the symbols when debugging on Solaris\n                        setMakeVar('STRIP_POLICY', 'no_strip')\n            # This removes the need to unzip the *.diz files before debugging in gdb\n            setMakeVar('ZIP_DEBUGINFO_FILES', '0', env=env)\n\n            # Clear these 2 variables as having them set can cause very confusing build problems\n            env.pop('LD_LIBRARY_PATH', None)\n            env.pop('CLASSPATH', None)\n\n            # Issue an env prefix that can be used to run the make on the command line\n            if not mx._opts.verbose:\n                mx.log('--------------- make command line ----------------------')\n\n            envPrefix = ' '.join([key + '=' + env[key] for key in env.iterkeys() if not os.environ.has_key(key) or env[key] != os.environ[key]])\n            if len(envPrefix):\n                mx.log('env ' + envPrefix + ' \\\\')\n\n            runCmd.append(build + buildSuffix)\n\n            if not mx._opts.verbose:\n                mx.log(' '.join(runCmd))\n                mx.log('--------------------------------------------------------')\n            mx.run(runCmd, err=filterXusage, env=env)\n\n        jvmCfg = _vmCfgInJdk(jdk)\n        if not exists(jvmCfg):\n            mx.abort(jvmCfg + ' does not exist')\n\n        prefix = '-' + vm + ' '\n        vmKnown = prefix + 'KNOWN\\n'\n        lines = []\n        found = False\n        with open(jvmCfg) as f:\n            for line in f:\n                if line.strip() == vmKnown.strip():\n                    found = True\n                lines.append(line)\n\n        if not found:\n            mx.log('Appending \"' + prefix + 'KNOWN\" to ' + jvmCfg)\n            if mx.get_os() != 'windows':\n                os.chmod(jvmCfg, JDK_UNIX_PERMISSIONS)\n            with open(jvmCfg, 'w') as f:\n                for line in lines:\n                    if line.startswith(prefix):\n                        line = vmKnown\n                        found = True\n                    f.write(line)\n                if not found:\n                    f.write(vmKnown)\n\n        if exists(timestampFile):\n            os.utime(timestampFile, None)\n        else:\n            file(timestampFile, 'a')\n\ndef vmg(args):\n    \"\"\"run the debug build of VM selected by the '--vm' option\"\"\"\n    return vm(args, vmbuild='debug')\n\ndef vmfg(args):\n    \"\"\"run the fastdebug build of VM selected by the '--vm' option\"\"\"\n    return vm(args, vmbuild='fastdebug')\n\ndef _parseVmArgs(args, vm=None, cwd=None, vmbuild=None):\n    \"\"\"run the VM selected by the '--vm' option\"\"\"\n\n    if vm is None:\n        vm = _get_vm()\n\n    if not isVMSupported(vm):\n        mx.abort('The ' + vm + ' is not supported on this platform')\n\n    if cwd is None:\n        cwd = _vm_cwd\n    elif _vm_cwd is not None and _vm_cwd != cwd:\n        mx.abort(\"conflicting working directories: do not set --vmcwd for this command\")\n\n    build = vmbuild if vmbuild is not None else _vmbuild if _vmSourcesAvailable else 'product'\n    jdk = _jdk(build, vmToCheck=vm, installGraalJar=False)\n    _updateInstalledGraalOptionsFile(jdk)\n    mx.expand_project_in_args(args)\n    if _make_eclipse_launch:\n        mx.make_eclipse_launch(args, 'graal-' + build, name=None, deps=mx.project('com.oracle.graal.hotspot').all_deps([], True))\n    if _jacoco == 'on' or _jacoco == 'append':\n        jacocoagent = mx.library(\"JACOCOAGENT\", True)\n        # Exclude all compiler tests and snippets\n        excludes = ['com.oracle.graal.compiler.tests.*', 'com.oracle.graal.jtt.*']\n        for p in mx.projects():\n            excludes += _find_classes_with_annotations(p, None, ['@Snippet', '@ClassSubstitution', '@Test'], includeInnerClasses=True).keys()\n            excludes += p.find_classes_with_matching_source_line(None, lambda line: 'JaCoCo Exclude' in line, includeInnerClasses=True).keys()\n\n        includes = ['com.oracle.graal.*']\n        agentOptions = {\n                        'append' : 'true' if _jacoco == 'append' else 'false',\n                        'bootclasspath' : 'true',\n                        'includes' : ':'.join(includes),\n                        'excludes' : ':'.join(excludes),\n                        'destfile' : 'jacoco.exec'\n        }\n        args = ['-javaagent:' + jacocoagent.get_path(True) + '=' + ','.join([k + '=' + v for k, v in agentOptions.items()])] + args\n    exe = join(jdk, 'bin', mx.exe_suffix('java'))\n    pfx = _vm_prefix.split() if _vm_prefix is not None else []\n\n    if '-version' in args:\n        ignoredArgs = args[args.index('-version') + 1:]\n        if  len(ignoredArgs) > 0:\n            mx.log(\"Warning: The following options will be ignored by the vm because they come after the '-version' argument: \" + ' '.join(ignoredArgs))\n\n    args = mx.java().processArgs(args)\n    return (pfx, exe, vm, args, cwd)\n\ndef vm(args, vm=None, nonZeroIsFatal=True, out=None, err=None, cwd=None, timeout=None, vmbuild=None):\n    (pfx_, exe_, vm_, args_, cwd) = _parseVmArgs(args, vm, cwd, vmbuild)\n    return mx.run(pfx_ + [exe_, '-' + vm_] + args_, nonZeroIsFatal=nonZeroIsFatal, out=out, err=err, cwd=cwd, timeout=timeout)\n\ndef _find_classes_with_annotations(p, pkgRoot, annotations, includeInnerClasses=False):\n    \"\"\"\n    Scan the sources of project 'p' for Java source files containing a line starting with 'annotation'\n    (ignoring preceding whitespace) and return the fully qualified class name for each Java\n    source file matched in a list.\n    \"\"\"\n\n    matches = lambda line: len([a for a in annotations if line == a or line.startswith(a + '(')]) != 0\n    return p.find_classes_with_matching_source_line(pkgRoot, matches, includeInnerClasses)\n\ndef _extract_VM_args(args, allowClasspath=False, useDoubleDash=False, defaultAllVMArgs=True):\n    \"\"\"\n    Partitions a command line into a leading sequence of HotSpot VM options and the rest.\n    \"\"\"\n    for i in range(0, len(args)):\n        if useDoubleDash:\n            if args[i] == '--':\n                vmArgs = args[:i]\n                remainder = args[i + 1:]\n                return vmArgs, remainder\n        else:\n            if not args[i].startswith('-'):\n                if i != 0 and (args[i - 1] == '-cp' or args[i - 1] == '-classpath'):\n                    if not allowClasspath:\n                        mx.abort('Cannot supply explicit class path option')\n                    else:\n                        continue\n                vmArgs = args[:i]\n                remainder = args[i:]\n                return vmArgs, remainder\n\n    if defaultAllVMArgs:\n        return args, []\n    else:\n        return [], args\n\ndef _run_tests(args, harness, annotations, testfile, whitelist, regex):\n\n\n    vmArgs, tests = _extract_VM_args(args)\n    for t in tests:\n        if t.startswith('-'):\n            mx.abort('VM option ' + t + ' must precede ' + tests[0])\n\n    candidates = {}\n    for p in mx.projects_opt_limit_to_suites():\n        if mx.java().javaCompliance < p.javaCompliance:\n            continue\n        for c in _find_classes_with_annotations(p, None, annotations).keys():\n            candidates[c] = p\n\n    classes = []\n    if len(tests) == 0:\n        classes = candidates.keys()\n        projectsCp = mx.classpath([pcp.name for pcp in mx.projects_opt_limit_to_suites() if pcp.javaCompliance <= mx.java().javaCompliance])\n    else:\n        projs = set()\n        if len(tests) == 1 and '#' in tests[0]:\n            words = tests[0].split('#')\n            if len(words) != 2:\n                mx.abort(\"Method specification is class#method: \" + tests[0])\n            t, method = words\n            for c, p in candidates.iteritems():\n                if t in c:\n                    found = True\n                    classes.append(c + '#' + method)\n                    projs.add(p.name)\n            if not found:\n                mx.log('warning: no tests matched by substring \"' + t)\n        else:\n            for t in tests:\n                if '#' in t:\n                    mx.abort('Method specifications can only be used in a single test: ' + t)\n                found = False\n                for c, p in candidates.iteritems():\n                    if t in c:\n                        found = True\n                        classes.append(c)\n                        projs.add(p.name)\n                if not found:\n                    mx.log('warning: no tests matched by substring \"' + t)\n        projectsCp = mx.classpath(projs)\n\n    if whitelist:\n        classes = [c for c in classes if any((glob.match(c) for glob in whitelist))]\n\n    if regex:\n        classes = [c for c in classes if re.search(regex, c)]\n\n    if len(classes) != 0:\n        f_testfile = open(testfile, 'w')\n        for c in classes:\n            f_testfile.write(c + '\\n')\n        f_testfile.close()\n        harness(projectsCp, vmArgs)\n\ndef _unittest(args, annotations, prefixCp=\"\", whitelist=None, verbose=False, enable_timing=False, regex=None, color=False, eager_stacktrace=False, gc_after_test=False):\n    testfile = os.environ.get('MX_TESTFILE', None)\n    if testfile is None:\n        (_, testfile) = tempfile.mkstemp(\".testclasses\", \"graal\")\n        os.close(_)\n    coreCp = mx.classpath(['com.oracle.graal.test'])\n\n    coreArgs = []\n    if verbose:\n        coreArgs.append('-JUnitVerbose')\n    if enable_timing:\n        coreArgs.append('-JUnitEnableTiming')\n    if color:\n        coreArgs.append('-JUnitColor')\n    if eager_stacktrace:\n        coreArgs.append('-JUnitEagerStackTrace')\n    if gc_after_test:\n        coreArgs.append('-JUnitGCAfterTest')\n\n\n    def harness(projectsCp, vmArgs):\n        if _get_vm() != 'graal':\n            prefixArgs = ['-esa', '-ea']\n        else:\n            prefixArgs = ['-XX:-BootstrapGraal', '-esa', '-ea']\n        if gc_after_test:\n            prefixArgs.append('-XX:-DisableExplicitGC')\n        with open(testfile) as fp:\n            testclasses = [l.rstrip() for l in fp.readlines()]\n\n        # Remove entries from class path that are in graal.jar and\n        # run the VM in a mode where application/test classes can\n        # access core Graal classes.\n        cp = prefixCp + coreCp + os.pathsep + projectsCp\n        if isGraalEnabled(_get_vm()):\n            graalDist = mx.distribution('GRAAL')\n            graalJarCp = set([d.output_dir() for d in graalDist.sorted_deps()])\n            cp = os.pathsep.join([e for e in cp.split(os.pathsep) if e not in graalJarCp])\n            vmArgs = vmArgs + ['-XX:-UseGraalClassLoader']\n\n        if len(testclasses) == 1:\n            # Execute Junit directly when one test is being run. This simplifies\n            # replaying the VM execution in a native debugger (e.g., gdb).\n            vm(prefixArgs + vmArgs + ['-cp', cp, 'com.oracle.graal.test.GraalJUnitCore'] + coreArgs + testclasses)\n        else:\n            vm(prefixArgs + vmArgs + ['-cp', cp, 'com.oracle.graal.test.GraalJUnitCore'] + coreArgs + ['@' + testfile])\n\n    try:\n        _run_tests(args, harness, annotations, testfile, whitelist, regex)\n    finally:\n        if os.environ.get('MX_TESTFILE') is None:\n            os.remove(testfile)\n\n# enterprise-truffle\ndef test262gate():\n    \"\"\"run the ECMAScript test262 test suite in gate mode\"\"\"\n\n    fetchTest262()\n    vm(['-ea', '-esa', '-cp', mx.classpath(\"com.oracle.truffle.js.test\"), \"com.oracle.truffle.js.test.test262.Test262\", \"gate\"], \"original\")\n\ndef testNashornGate():\n    \"\"\"run the Nashorn test suite in gate mode\"\"\"\n\n    testdir = join(_graal_home, 'lib', 'testnashorn-18edd7a1b166')\n    fetchTestNashorn()\n    vm(['-ea', '-esa', '-cp', mx.classpath(\"com.oracle.truffle.js.test\"), \"com.oracle.truffle.js.test.nashorn.TestNashorn\", \"gate\"], \"original\", cwd=testdir)\n\ndef testNodeTruffleGate():\n    testNodeTruffle([])\n\ndef testNodeTruffle(args):\n    \"\"\"run Node.Truffle tests\"\"\"\n    vmArgs, nodeArgs = _extract_VM_args(args)\n    nodejsPath = '-Dnodejs.path=' + os.path.join(_graal_home, 'graal', 'com.oracle.truffle.nodejs.runtime')\n    nodejsTestPath = '-Dnodejs.test.path=' + os.path.join(_graal_home, 'graal', 'com.oracle.truffle.nodejs.test', 'tests')\n    vm(vmArgs + ['-ea', '-esa', '-cp', mx.classpath('com.oracle.truffle.nodejs.test'), nodejsPath, nodejsTestPath, 'com.oracle.truffle.nodejs.test.TestHarness'] + nodeArgs)\n# enterprise-truffle\n\n_unittestHelpSuffix = \"\"\"\n    Unittest options:\n\n      --whitelist <file>     run only testcases which are included\n                             in the given whitelist\n      --verbose              enable verbose JUnit output\n      --enable-timing        enable JUnit test timing\n      --regex <regex>        run only testcases matching a regular expression\n      --color                enable colors output\n      --eager-stacktrace     print stacktrace eagerly\n      --gc-after-test        force a GC after each test\n\n    To avoid conflicts with VM options '--' can be used as delimiter.\n\n    If filters are supplied, only tests whose fully qualified name\n    includes a filter as a substring are run.\n\n    For example, this command line:\n\n       mx unittest -G:Dump= -G:MethodFilter=BC_aload.* -G:+PrintCFG BC_aload\n\n    will run all JUnit test classes that contain 'BC_aload' in their\n    fully qualified name and will pass these options to the VM:\n\n        -G:Dump= -G:MethodFilter=BC_aload.* -G:+PrintCFG\n\n    To get around command line length limitations on some OSes, the\n    JUnit class names to be executed are written to a file that a\n    custom JUnit wrapper reads and passes onto JUnit proper. The\n    MX_TESTFILE environment variable can be set to specify a\n    file which will not be deleted once the unittests are done\n    (unlike the temporary file otherwise used).\n\n    As with all other commands, using the global '-v' before 'unittest'\n    command will cause mx to show the complete command line\n    it uses to run the VM.\n\"\"\"\n\ndef unittest(args):\n    \"\"\"run the JUnit tests (all testcases){0}\"\"\"\n\n    parser = ArgumentParser(prog='mx unittest',\n          description='run the JUnit tests',\n          add_help=False,\n          formatter_class=RawDescriptionHelpFormatter,\n          epilog=_unittestHelpSuffix,\n        )\n    parser.add_argument('--whitelist', help='run testcases specified in whitelist only', metavar='<path>')\n    parser.add_argument('--verbose', help='enable verbose JUnit output', action='store_true')\n    parser.add_argument('--enable-timing', help='enable JUnit test timing', action='store_true')\n    parser.add_argument('--regex', help='run only testcases matching a regular expression', metavar='<regex>')\n    parser.add_argument('--color', help='enable color output', action='store_true')\n    parser.add_argument('--eager-stacktrace', help='print stacktrace eagerly', action='store_true')\n    parser.add_argument('--gc-after-test', help='force a GC after each test', action='store_true')\n\n    ut_args = []\n    delimiter = False\n    # check for delimiter\n    while len(args) > 0:\n        arg = args.pop(0)\n        if arg == '--':\n            delimiter = True\n            break\n        ut_args.append(arg)\n\n    if delimiter:\n        # all arguments before '--' must be recognized\n        parsed_args = parser.parse_args(ut_args)\n    else:\n        # parse all know arguments\n        parsed_args, args = parser.parse_known_args(ut_args)\n\n    if parsed_args.whitelist:\n        try:\n            with open(join(_graal_home, parsed_args.whitelist)) as fp:\n                parsed_args.whitelist = [re.compile(fnmatch.translate(l.rstrip())) for l in fp.readlines() if not l.startswith('#')]\n        except IOError:\n            mx.log('warning: could not read whitelist: ' + parsed_args.whitelist)\n\n    _unittest(args, ['@Test', '@Parameters'], **parsed_args.__dict__)\n\ndef shortunittest(args):\n    \"\"\"alias for 'unittest --whitelist test/whitelist_shortunittest.txt'{0}\"\"\"\n\n    args = ['--whitelist', 'test/whitelist_shortunittest.txt'] + args\n    unittest(args)\n\ndef buildvms(args):\n    \"\"\"build one or more VMs in various configurations\"\"\"\n\n    vmsDefault = ','.join(_vmChoices.keys())\n    vmbuildsDefault = ','.join(_vmbuildChoices)\n\n    parser = ArgumentParser(prog='mx buildvms')\n    parser.add_argument('--vms', help='a comma separated list of VMs to build (default: ' + vmsDefault + ')', metavar='<args>', default=vmsDefault)\n    parser.add_argument('--builds', help='a comma separated list of build types (default: ' + vmbuildsDefault + ')', metavar='<args>', default=vmbuildsDefault)\n    parser.add_argument('-n', '--no-check', action='store_true', help='omit running \"java -version\" after each build')\n    parser.add_argument('-c', '--console', action='store_true', help='send build output to console instead of log file')\n\n    args = parser.parse_args(args)\n    vms = args.vms.split(',')\n    builds = args.builds.split(',')\n\n    allStart = time.time()\n    for v in vms:\n        if not isVMSupported(v):\n            mx.log('The ' + v + ' VM is not supported on this platform - skipping')\n            continue\n\n        for vmbuild in builds:\n            if v == 'original' and vmbuild != 'product':\n                continue\n            if not args.console:\n                logFile = join(v + '-' + vmbuild + '.log')\n                log = open(join(_graal_home, logFile), 'wb')\n                start = time.time()\n                mx.log('BEGIN: ' + v + '-' + vmbuild + '\\t(see: ' + logFile + ')')\n                # Run as subprocess so that output can be directed to a file\n                subprocess.check_call([sys.executable, '-u', join('mxtool', 'mx.py'), '--vm', v, '--vmbuild',\n                                       vmbuild, 'build'], cwd=_graal_home, stdout=log, stderr=subprocess.STDOUT)\n                duration = datetime.timedelta(seconds=time.time() - start)\n                mx.log('END:   ' + v + '-' + vmbuild + '\\t[' + str(duration) + ']')\n            else:\n                with VM(v, vmbuild):\n                    build([])\n            if not args.no_check:\n                vmargs = ['-version']\n                if v == 'graal':\n                    vmargs.insert(0, '-XX:-BootstrapGraal')\n                vm(vmargs, vm=v, vmbuild=vmbuild)\n    allDuration = datetime.timedelta(seconds=time.time() - allStart)\n    mx.log('TOTAL TIME:   ' + '[' + str(allDuration) + ']')\n\nclass Task:\n    def __init__(self, title):\n        self.start = time.time()\n        self.title = title\n        self.end = None\n        self.duration = None\n        mx.log(time.strftime('gate: %d %b %Y %H:%M:%S: BEGIN: ') + title)\n    def stop(self):\n        self.end = time.time()\n        self.duration = datetime.timedelta(seconds=self.end - self.start)\n        mx.log(time.strftime('gate: %d %b %Y %H:%M:%S: END:   ') + self.title + ' [' + str(self.duration) + ']')\n        return self\n    def abort(self, codeOrMessage):\n        self.end = time.time()\n        self.duration = datetime.timedelta(seconds=self.end - self.start)\n        mx.log(time.strftime('gate: %d %b %Y %H:%M:%S: ABORT: ') + self.title + ' [' + str(self.duration) + ']')\n        mx.abort(codeOrMessage)\n        return self\n\ndef _basic_gate_body(args, tasks):\n    t = Task('BuildHotSpotGraal: fastdebug,product')\n    buildvms(['--vms', 'graal,server', '--builds', 'fastdebug,product'])\n    tasks.append(t.stop())\n\n    with VM('graal', 'fastdebug'):\n        t = Task('BootstrapWithSystemAssertions:fastdebug')\n        vm(['-esa', '-XX:-TieredCompilation', '-version'])\n        tasks.append(t.stop())\n\n    with VM('graal', 'fastdebug'):\n        t = Task('BootstrapWithSystemAssertionsNoCoop:fastdebug')\n        vm(['-esa', '-XX:-TieredCompilation', '-XX:-UseCompressedOops', '-version'])\n        tasks.append(t.stop())\n\n    with VM('graal', 'product'):\n        t = Task('BootstrapWithGCVerification:product')\n        out = mx.DuplicateSuppressingStream(['VerifyAfterGC:', 'VerifyBeforeGC:']).write\n        vm(['-XX:-TieredCompilation', '-XX:+UnlockDiagnosticVMOptions', '-XX:+VerifyBeforeGC', '-XX:+VerifyAfterGC', '-version'], out=out)\n        tasks.append(t.stop())\n\n    with VM('graal', 'product'):\n        t = Task('BootstrapWithG1GCVerification:product')\n        out = mx.DuplicateSuppressingStream(['VerifyAfterGC:', 'VerifyBeforeGC:']).write\n        vm(['-XX:-TieredCompilation', '-XX:+UnlockDiagnosticVMOptions', '-XX:-UseSerialGC', '-XX:+UseG1GC', '-XX:+VerifyBeforeGC', '-XX:+VerifyAfterGC', '-version'], out=out)\n        tasks.append(t.stop())\n\n    with VM('graal', 'product'):\n        t = Task('BootstrapWithRegisterPressure:product')\n        vm(['-XX:-TieredCompilation', '-G:RegisterPressure=rbx,r11,r10,r14,xmm3,xmm11,xmm14', '-esa', '-version'])\n        tasks.append(t.stop())\n\n    with VM('graal', 'product'):\n        t = Task('BootstrapWithImmutableCode:product')\n        vm(['-XX:-TieredCompilation', '-G:+ImmutableCode', '-G:+VerifyPhases', '-esa', '-version'])\n        tasks.append(t.stop())\n\n    with VM('server', 'product'):  # hosted mode\n        t = Task('UnitTests:hosted-product')\n        unittest(['--enable-timing', '--verbose'])\n        tasks.append(t.stop())\n\n    with VM('server', 'product'):  # hosted mode\n        t = Task('UnitTests-BaselineCompiler:hosted-product')\n        unittest(['--enable-timing', '--verbose', '--whitelist', 'test/whitelist_baseline.txt', '-G:+UseBaselineCompiler'])\n        tasks.append(t.stop())\n\n    for vmbuild in ['fastdebug', 'product']:\n        for test in sanitycheck.getDacapos(level=sanitycheck.SanityCheckLevel.Gate, gateBuildLevel=vmbuild) + sanitycheck.getScalaDacapos(level=sanitycheck.SanityCheckLevel.Gate, gateBuildLevel=vmbuild):\n            t = Task(str(test) + ':' + vmbuild)\n            if not test.test('graal'):\n                t.abort(test.name + ' Failed')\n            tasks.append(t.stop())\n\n    # ensure -Xbatch still works\n    with VM('graal', 'product'):\n        t = Task('DaCapo_pmd:BatchMode:product')\n        dacapo(['-Xbatch', 'pmd'])\n        tasks.append(t.stop())\n\n    # ensure -Xcomp still works\n    with VM('graal', 'product'):\n        t = Task('XCompMode:product')\n        vm(['-Xcomp', '-version'])\n        tasks.append(t.stop())\n\n    if args.jacocout is not None:\n        jacocoreport([args.jacocout])\n\n    global _jacoco\n    _jacoco = 'off'\n\n    t = Task('CleanAndBuildIdealGraphVisualizer')\n    mx.run(['ant', '-f', join(_graal_home, 'src', 'share', 'tools', 'IdealGraphVisualizer', 'build.xml'), '-q', 'clean', 'build'])\n    tasks.append(t.stop())\n\n    # Prevent Graal modifications from breaking the standard builds\n    if args.buildNonGraal:\n        t = Task('BuildHotSpotVarieties')\n        buildvms(['--vms', 'client,server', '--builds', 'fastdebug,product'])\n        buildvms(['--vms', 'server-nograal', '--builds', 'product'])\n        buildvms(['--vms', 'server-nograal', '--builds', 'optimized'])\n        tasks.append(t.stop())\n\n        for vmbuild in ['product', 'fastdebug']:\n            for theVm in ['client', 'server']:\n                if not isVMSupported(theVm):\n                    mx.log('The' + theVm + ' VM is not supported on this platform')\n                    continue\n                with VM(theVm, vmbuild):\n                    t = Task('DaCapo_pmd:' + theVm + ':' + vmbuild)\n                    dacapo(['pmd'])\n                    tasks.append(t.stop())\n\n                    t = Task('UnitTests:' + theVm + ':' + vmbuild)\n                    unittest(['-XX:CompileCommand=exclude,*::run*', 'graal.api'])\n                    tasks.append(t.stop())\n\n# enterprise-truffle\ndef _enterprise_truffle_gate_body(args, tasks):\n    t = Task('BuildHotSpotGraalServer: product')\n    buildvms(['--vms', 'server', '--builds', 'product'])\n    tasks.append(t.stop())\n\n    with VM('original', 'product'):\n        pulljsbenchmarks()\n        t = Task('UnitTests:original')\n        unittest(['js.test.tests', 'js.test.engine', 'js.test.benchmark.octane', 'ruby.test.runtime', 'ruby.test.language', 'ruby.test.core'])\n        tasks.append(t.stop())\n\n        t = Task('Test262:original')\n        test262gate()\n        tasks.append(t.stop())\n\n        t = Task('TestNashorn:original')\n        testNashornGate()\n        tasks.append(t.stop())\n\n        t = Task('TestNodeTruffle:original')\n        testNodeTruffleGate()\n        tasks.append(t.stop())\n\n        t = Task('TestAvatarJS:original')\n        testAvatarJSGate()\n        tasks.append(t.stop())\n\n        t = Task('TruffleThreadSafe:original')\n        testParallelJS(['ts'])\n        tasks.append(t.stop())\n\n        t = Task('TruffleRiverTrail:original')\n        testParallelJS(['pjs'])\n        tasks.append(t.stop())\n\n        t = Task('TruffleTL2STM:original')\n        testParallelJS(['stm'])\n        tasks.append(t.stop())\n\n    if args.jacocout is not None:\n        jacocoreport([args.jacocout])\n\n    global _jacoco\n    _jacoco = 'off'\n\n# Substrate VM\ndef _svm_gate_body(args, tasks):\n    t = Task('BuildHotSpotGraalServer: product')\n    buildvms(['--vms', 'server', '--builds', 'product'])\n    tasks.append(t.stop())\n\n    # This ensures that all JUnit tests pass on the HotSpot VM. If they fail\n    # here, obviously they would not pass when making a Substrate VM image.\n    # Note that Substrate-VM only tests, annotated with @SVMTest, are not\n    # executed here because they cannot run on regluar Java VM.\n    t = Task('Run SVM unit tests on HotSpot VM')\n    unittest([\"svm\"])\n    tasks.append(t.stop())\n\n    t = Task('svmtest debug')\n    svmtest(['helloworld', 'svm_test_deoptimization', 'svm_test_graal_BasicCompileTest_testall', 'svm_test_graal_RuntimeCompileDeopt', 'svm_test_graal_RuntimeCompileJtt', 'systemjava_UnsignedTests'])\n    tasks.append(t.stop())\n\n    t = Task('svmtest product')\n    svmtest(['-da', '-dsa', '--', '-g=false', 'helloworld', 'svm_test_deoptimization', 'svm_test_graal_BasicCompileTest_testall', 'svm_test_graal_RuntimeCompileDeopt'])\n    tasks.append(t.stop())\n\n    t = Task('deopt stress')\n    svmtest(['-B:+Inline', '-B:+RuntimeAssertions', '-B:-CheckStaticAnalysisResults', '-B:-SourceLevelDebug', '-B:+DeoptimizeAll', 'svm_test_graal_BasicCompileTest_testmin'])\n    tasks.append(t.stop())\n\n    t = Task('Simple Language')\n    image(['-class=com.oracle.svm.truffle.sl.Main', '-name=sl'])\n    tasks.append(t.stop())\n\n    t = Task('SL testsuite, compiled')\n    svmtest(['-G:-VerifyGraalGraphs', '-G:-TraceTruffleCompilation', '-G:-TruffleSplitting', '--', '-B:+UseTruffleCompiler', '-B:+TruffleCompileImmediately', '-B:+StoreMethodNames', 'SubstrateSLTestSuite'])\n    tasks.append(t.stop())\n\n    t = Task('JavaScript')\n    image(['-class=com.oracle.svm.truffle.js.Main', '-name=js'])\n    tasks.append(t.stop())\n\n    t = Task('JavaScript, compiled')\n    svmtest(['-G:-VerifyGraalGraphs', '-G:-TraceTruffleCompilation', '-G:-TruffleSplitting', '--', '-B:+UseTruffleCompiler', '-B:+TruffleCompileImmediately', '-B:+StoreMethodNames', 'JSCompileTest'])\n    tasks.append(t.stop())\n\n    t = Task('JavaScript benchmarks')\n    image(['-G:-VerifyGraalGraphs', '-G:-TraceTruffleCompilation', '--', '-B:+UseTruffleCompiler', '-B:+RuntimeAssertions', '-B:+RuntimeAssertionsAreFatal', '-class=com.oracle.svm.truffle.js.Main', '-path=svmbuild', '-name=jscomp'])\n\n    benchmarkDir = \"lib/js-benchmarks/\"\n    if not exists(benchmarkDir):\n        pulljsbenchmarks()\n\n    def jsbench(name):\n        output_ok = [True]\n        def parse_output(line):\n            print(line)\n            if not re.match(r'^\\S+: *\\d+(\\.\\d+)?\\s*$', line):\n                output_ok[0] = False\n\n        mx.run(['svmbuild/jscomp', 'lib/js-benchmarks/harness.js', '--', 'lib/js-benchmarks/' + name + '.js'], True, parse_output)\n        if not output_ok[0]:\n            mx.abort('JS benchmark ' + name + ' failed')\n\n    # Execute only a subset of the benchmarks to avoid long runtime.\n    jsbench('octane-richards')\n    jsbench('octane-crypto')\n    jsbench('octane-raytrace')\n    jsbench('octane-code-load')\n    jsbench('fannkuch')\n    jsbench('nbody')\n\n    tasks.append(t.stop())\n\n    t = Task('Run walnut unit test')\n    unittest([\"walnut.test\"])\n    tasks.append(t.stop())\n\n    t = Task('Build walnut db servlet')\n    dbs([\"-servlet=walnut\"])\n    tasks.append(t.stop())\n\n    t = Task('Run walnut qsh test')\n    qshtest()\n    tasks.append(t.stop())\n\ndef gate(args, gate_body=_svm_gate_body):\n    \"\"\"run the tests used to validate a push\n\n    If this command exits with a 0 exit code, then the source code is in\n    a state that would be accepted for integration into the main repository.\"\"\"\n\n    parser = ArgumentParser(prog='mx gate')\n    parser.add_argument('-j', '--omit-java-clean', action='store_false', dest='cleanJava', help='omit cleaning Java native code')\n    parser.add_argument('-n', '--omit-native-clean', action='store_false', dest='cleanNative', help='omit cleaning and building native code')\n    parser.add_argument('-g', '--only-build-graalvm', action='store_false', dest='buildNonGraal', help='only build the Graal VM')\n    parser.add_argument('--jacocout', help='specify the output directory for jacoco report')\n\n    args = parser.parse_args(args)\n\n    global _jacoco\n\n    tasks = []\n    total = Task('Gate')\n    try:\n\n        # t = Task('Pylint')\n        # mx.pylint([])\n        # tasks.append(t.stop())\n\n        def _clean(name='Clean'):\n            t = Task(name)\n            cleanArgs = []\n            if not args.cleanNative:\n                cleanArgs.append('--no-native')\n            if not args.cleanJava:\n                cleanArgs.append('--no-java')\n            clean(cleanArgs)\n            tasks.append(t.stop())\n        _clean()\n\n        t = Task('IDEConfigCheck')\n        mx.ideclean([])\n        mx.ideinit([])\n        tasks.append(t.stop())\n\n        eclipse_exe = mx.get_env('ECLIPSE_EXE')\n        if eclipse_exe is not None:\n            t = Task('CodeFormatCheck')\n            if mx.eclipseformat(['-e', eclipse_exe]) != 0:\n                t.abort('Formatter modified files - run \"mx eclipseformat\", check in changes and repush')\n            tasks.append(t.stop())\n\n        t = Task('Canonicalization Check')\n        mx.log(time.strftime('%d %b %Y %H:%M:%S - Ensuring mx/projects files are canonicalized...'))\n        if mx.canonicalizeprojects([]) != 0:\n            t.abort('Rerun \"mx canonicalizeprojects\" and check-in the modified mx/projects files.')\n        tasks.append(t.stop())\n\n        if mx.get_env('JDT'):\n            t = Task('BuildJavaWithEcj')\n            build(['-p', '--no-native', '--jdt-warning-as-error'])\n            tasks.append(t.stop())\n\n            _clean('CleanAfterEcjBuild')\n\n        t = Task('BuildJavaWithJavac')\n        build(['-p', '--no-native', '--force-javac'])\n        tasks.append(t.stop())\n\n        t = Task('Checkheaders')\n        if checkheaders([]) != 0:\n            t.abort('Checkheaders warnings were found')\n        tasks.append(t.stop())\n\n        #t = Task('FindBugs')\n        #if findbugs([]) != 0:\n        #    # TODO activate FindBugs again once we have solved most issues\n        #    #t.abort('FindBugs warnings were found')\n        #    mx.log('FindBugs FAILED, enterprise-truffle is ignoring that for the moment')\n        #tasks.append(t.stop())\n\n        if exists('jacoco.exec'):\n            os.unlink('jacoco.exec')\n\n        if args.jacocout is not None:\n            _jacoco = 'append'\n        else:\n            _jacoco = 'off'\n\n        gate_body(args, tasks)\n\n    except KeyboardInterrupt:\n        total.abort(1)\n\n    except BaseException as e:\n        import traceback\n        traceback.print_exc()\n        total.abort(str(e))\n\n    total.stop()\n\n    mx.log('Gate task times:')\n    for t in tasks:\n        mx.log('  ' + str(t.duration) + '\\t' + t.title)\n    mx.log('  =======')\n    mx.log('  ' + str(total.duration))\n\ndef deoptalot(args):\n    \"\"\"bootstrap a fastdebug Graal VM with DeoptimizeALot and VerifyOops on\n\n    If the first argument is a number, the process will be repeated\n    this number of times. All other arguments are passed to the VM.\"\"\"\n    count = 1\n    if len(args) > 0 and args[0].isdigit():\n        count = int(args[0])\n        del args[0]\n\n    for _ in range(count):\n        if not vm(['-XX:+DeoptimizeALot', '-XX:+VerifyOops'] + args + ['-version'], vmbuild='fastdebug') == 0:\n            mx.abort(\"Failed\")\n\ndef longtests(args):\n\n    deoptalot(['15', '-Xmx48m'])\n\n    dacapo(['100', 'eclipse', '-esa'])\n\ndef igv(args):\n    \"\"\"run the Ideal Graph Visualizer\"\"\"\n    with open(join(_graal_home, '.ideal_graph_visualizer.log'), 'w') as fp:\n        # When the http_proxy environment variable is set, convert it to the proxy settings that ant needs\n        env = os.environ\n        proxy = os.environ.get('http_proxy')\n        if not (proxy is None) and len(proxy) > 0:\n            if '://' in proxy:\n                # Remove the http:// prefix (or any other protocol prefix)\n                proxy = proxy.split('://', 1)[1]\n            # Separate proxy server name and port number\n            proxyName, proxyPort = proxy.split(':', 1)\n            proxyEnv = '-DproxyHost=\"' + proxyName + '\" -DproxyPort=' + proxyPort\n            env['ANT_OPTS'] = proxyEnv\n\n        mx.logv('[Ideal Graph Visualizer log is in ' + fp.name + ']')\n        nbplatform = join(_graal_home, 'src', 'share', 'tools', 'IdealGraphVisualizer', 'nbplatform')\n\n        # Remove NetBeans platform if it is earlier than the current supported version\n        if exists(nbplatform):\n            dom = xml.dom.minidom.parse(join(nbplatform, 'platform', 'update_tracking', 'org-netbeans-core.xml'))\n            currentVersion = mx.VersionSpec(dom.getElementsByTagName('module_version')[0].getAttribute('specification_version'))\n            supportedVersion = mx.VersionSpec('3.43.1')\n            if currentVersion < supportedVersion:\n                mx.log('Replacing NetBeans platform version ' + str(currentVersion) + ' with version ' + str(supportedVersion))\n                shutil.rmtree(nbplatform)\n            elif supportedVersion < currentVersion:\n                mx.log('Supported NetBeans version in igv command should be updated to ' + str(currentVersion))\n\n        if not exists(nbplatform):\n            mx.logv('[This execution may take a while as the NetBeans platform needs to be downloaded]')\n        mx.run(['ant', '-f', join(_graal_home, 'src', 'share', 'tools', 'IdealGraphVisualizer', 'build.xml'), '-l', fp.name, 'run'], env=env)\n\ndef c1visualizer(args):\n    \"\"\"run the Cl Compiler Visualizer\"\"\"\n    libpath = join(_graal_home, 'lib')\n    if mx.get_os() == 'windows':\n        executable = join(libpath, 'c1visualizer', 'bin', 'c1visualizer.exe')\n    else:\n        executable = join(libpath, 'c1visualizer', 'bin', 'c1visualizer')\n\n    archive = join(libpath, 'c1visualizer_2014-04-22.zip')\n    if not exists(executable) or not exists(archive):\n        if not exists(archive):\n            mx.download(archive, ['https://java.net/downloads/c1visualizer/c1visualizer_2014-04-22.zip'])\n        zf = zipfile.ZipFile(archive, 'r')\n        zf.extractall(libpath)\n\n    if not exists(executable):\n        mx.abort('C1Visualizer binary does not exist: ' + executable)\n\n    if mx.get_os() != 'windows':\n        # Make sure that execution is allowed. The zip file does not always specfiy that correctly\n        os.chmod(executable, 0777)\n\n    mx.run([executable])\n\ndef bench(args):\n    \"\"\"run benchmarks and parse their output for results\n\n    Results are JSON formated : {group : {benchmark : score}}.\"\"\"\n    resultFile = None\n    if '-resultfile' in args:\n        index = args.index('-resultfile')\n        if index + 1 < len(args):\n            resultFile = args[index + 1]\n            del args[index]\n            del args[index]\n        else:\n            mx.abort('-resultfile must be followed by a file name')\n    # enterprise-truffle\n    resultFileCSV = None\n    if '-resultfilecsv' in args:\n        index = args.index('-resultfilecsv')\n        if index + 1 < len(args):\n            resultFileCSV = args[index + 1]\n            del args[index]\n            del args[index]\n        else:\n            mx.abort('-resultfilecsv must be followed by a file name')\n    # enterprise-truffle\n    vm = _get_vm()\n    if len(args) is 0:\n        args = ['all']\n\n    vmArgs = [arg for arg in args if arg.startswith('-')]\n\n    def benchmarks_in_group(group):\n        prefix = group + ':'\n        return [a[len(prefix):] for a in args if a.startswith(prefix)]\n\n    results = {}\n    benchmarks = []\n    # DaCapo\n    if 'dacapo' in args or 'all' in args:\n        benchmarks += sanitycheck.getDacapos(level=sanitycheck.SanityCheckLevel.Benchmark)\n    else:\n        dacapos = benchmarks_in_group('dacapo')\n        for dacapo in dacapos:\n            if dacapo not in sanitycheck.dacapoSanityWarmup.keys():\n                mx.abort('Unknown DaCapo : ' + dacapo)\n            iterations = sanitycheck.dacapoSanityWarmup[dacapo][sanitycheck.SanityCheckLevel.Benchmark]\n            if iterations > 0:\n                benchmarks += [sanitycheck.getDacapo(dacapo, iterations)]\n\n    if 'scaladacapo' in args or 'all' in args:\n        benchmarks += sanitycheck.getScalaDacapos(level=sanitycheck.SanityCheckLevel.Benchmark)\n    else:\n        scaladacapos = benchmarks_in_group('scaladacapo')\n        for scaladacapo in scaladacapos:\n            if scaladacapo not in sanitycheck.dacapoScalaSanityWarmup.keys():\n                mx.abort('Unknown Scala DaCapo : ' + scaladacapo)\n            iterations = sanitycheck.dacapoScalaSanityWarmup[scaladacapo][sanitycheck.SanityCheckLevel.Benchmark]\n            if iterations > 0:\n                benchmarks += [sanitycheck.getScalaDacapo(scaladacapo, ['-n', str(iterations)])]\n\n    # Bootstrap\n    if 'bootstrap' in args or 'all' in args:\n        benchmarks += sanitycheck.getBootstraps()\n    # SPECjvm2008\n    if 'specjvm2008' in args or 'all' in args:\n        benchmarks += [sanitycheck.getSPECjvm2008(['-ikv', '-wt', '120', '-it', '120'])]\n    else:\n        specjvms = benchmarks_in_group('specjvm2008')\n        for specjvm in specjvms:\n            benchmarks += [sanitycheck.getSPECjvm2008(['-ikv', '-wt', '120', '-it', '120', specjvm])]\n\n    if 'specjbb2005' in args or 'all' in args:\n        benchmarks += [sanitycheck.getSPECjbb2005()]\n\n    if 'specjbb2013' in args:  # or 'all' in args //currently not in default set\n        benchmarks += [sanitycheck.getSPECjbb2013()]\n\n    if 'ctw-full' in args:\n        benchmarks.append(sanitycheck.getCTW(vm, sanitycheck.CTWMode.Full))\n    if 'ctw-noinline' in args:\n        benchmarks.append(sanitycheck.getCTW(vm, sanitycheck.CTWMode.NoInline))\n    if 'ctw-nocomplex' in args:\n        benchmarks.append(sanitycheck.getCTW(vm, sanitycheck.CTWMode.NoComplex))\n\n    # enterprise-truffle\n    #JavaScript\n    engine = next((x for x in args if x in [\"trufflejs\", \"truffle\", \"nashorn\", \"v8\", \"v8-nocrankshaft\"]), None)\n    if engine:\n        benchmarks += sanitycheck.getTruffleJSBenchmarks(vm, engine=('truffle' if engine == \"trufflejs\" else engine))\n\n    #Ruby\n    if 'ruby' in args or 'truffle' in args:\n        benchmarks += sanitycheck.getRubyBenchmarks(vm)\n    # enterprise-truffle\n\n    for test in benchmarks:\n        for (groupName, res) in test.bench(vm, extraVmOpts=vmArgs).items():\n            group = results.setdefault(groupName, {})\n            group.update(res)\n    mx.log(json.dumps(results))\n    if resultFile:\n        with open(resultFile, 'w') as f:\n            f.write(json.dumps(results))\n    # enterprise-truffle\n    if resultFileCSV:\n        with open(resultFileCSV, 'w') as f:\n            for key1, value1 in results.iteritems():\n                f.write('%s;\\n' % (str(key1)))\n                for key2, value2 in sorted(value1.iteritems()):\n                    f.write('%s; %s;\\n' % (str(key2), str(value2)))\n    # enterprise-truffle\n\ndef _get_jmh_path():\n    path = mx.get_env('JMH_BENCHMARKS', None)\n    if not path:\n        probe = join(dirname(_graal_home), 'java-benchmarks')\n        if exists(probe):\n            path = probe\n\n    if not path:\n        mx.abort(\"Please set the JMH_BENCHMARKS environment variable to point to the java-benchmarks workspace\")\n    if not exists(path):\n        mx.abort(\"The directory denoted by the JMH_BENCHMARKS environment variable does not exist: \" + path)\n    return path\n\ndef makejmhdeps(args):\n    \"\"\"creates and installs Maven dependencies required by the JMH benchmarks\n\n    The dependencies are specified by files named pom.mxdeps in the\n    JMH directory tree. Each such file contains a list of dependencies\n    defined in JSON format. For example:\n\n    '[{\"artifactId\" : \"compiler.test\", \"groupId\" : \"com.oracle.graal\", \"deps\" : [\"com.oracle.graal.compiler.test\"]}]'\n\n    will result in a dependency being installed in the local Maven repository\n    that can be referenced in a pom.xml file as follows:\n\n          <dependency>\n            <groupId>com.oracle.graal</groupId>\n            <artifactId>compiler.test</artifactId>\n            <version>1.0-SNAPSHOT</version>\n          </dependency>\"\"\"\n\n    parser = ArgumentParser(prog='mx makejmhdeps')\n    parser.add_argument('-s', '--settings', help='alternative path for Maven user settings file', metavar='<path>')\n    parser.add_argument('-p', '--permissive', action='store_true', help='issue note instead of error if a Maven dependency cannot be built due to missing projects/libraries')\n    args = parser.parse_args(args)\n\n    def makejmhdep(artifactId, groupId, deps):\n        graalSuite = mx.suite(\"graal\")\n        path = artifactId + '.jar'\n        if args.permissive:\n            for name in deps:\n                if not mx.project(name, fatalIfMissing=False):\n                    if not mx.library(name, fatalIfMissing=False):\n                        mx.log('Skipping ' + groupId + '.' + artifactId + '.jar as ' + name + ' cannot be resolved')\n                        return\n        d = mx.Distribution(graalSuite, name=artifactId, path=path, sourcesPath=path, deps=deps, mainClass=None, excludedDependencies=[], distDependencies=[])\n        d.make_archive()\n        cmd = ['mvn', 'install:install-file', '-DgroupId=' + groupId, '-DartifactId=' + artifactId,\n               '-Dversion=1.0-SNAPSHOT', '-Dpackaging=jar', '-Dfile=' + d.path]\n        if not mx._opts.verbose:\n            cmd.append('-q')\n        if args.settings:\n            cmd = cmd + ['-s', args.settings]\n        mx.run(cmd)\n        os.unlink(d.path)\n\n    jmhPath = _get_jmh_path()\n    for root, _, filenames in os.walk(jmhPath):\n        for f in [join(root, n) for n in filenames if n == 'pom.mxdeps']:\n            mx.logv('[processing ' + f + ']')\n            try:\n                with open(f) as fp:\n                    for d in json.load(fp):\n                        artifactId = d['artifactId']\n                        groupId = d['groupId']\n                        deps = d['deps']\n                        makejmhdep(artifactId, groupId, deps)\n            except ValueError as e:\n                mx.abort('Error parsing {}:\\n{}'.format(f, e))\n\ndef buildjmh(args):\n    \"\"\"build the JMH benchmarks\"\"\"\n\n    parser = ArgumentParser(prog='mx buildjmh')\n    parser.add_argument('-s', '--settings', help='alternative path for Maven user settings file', metavar='<path>')\n    parser.add_argument('-c', action='store_true', dest='clean', help='clean before building')\n    args = parser.parse_args(args)\n\n    jmhPath = _get_jmh_path()\n    mx.log('JMH benchmarks: ' + jmhPath)\n\n    # Ensure the mx injected dependencies are up to date\n    makejmhdeps(['-p'] + (['-s', args.settings] if args.settings else []))\n\n    timestamp = mx.TimeStampFile(join(_graal_home, 'mx', 'jmh', jmhPath.replace(os.sep, '_') + '.timestamp'))\n    mustBuild = args.clean\n    if not mustBuild:\n        try:\n            hgfiles = [join(jmhPath, f) for f in subprocess.check_output(['hg', '-R', jmhPath, 'locate']).split('\\n')]\n            mustBuild = timestamp.isOlderThan(hgfiles)\n        except:\n            # not a Mercurial repository or hg commands are not available.\n            mustBuild = True\n\n    if mustBuild:\n        buildOutput = []\n        def _redirect(x):\n            if mx._opts.verbose:\n                mx.log(x[:-1])\n            else:\n                buildOutput.append(x)\n        env = os.environ.copy()\n        env['JAVA_HOME'] = _jdk(vmToCheck='server')\n        env['MAVEN_OPTS'] = '-server'\n        mx.log(\"Building benchmarks...\")\n        cmd = ['mvn']\n        if args.settings:\n            cmd = cmd + ['-s', args.settings]\n        if args.clean:\n            cmd.append('clean')\n        cmd.append('package')\n        retcode = mx.run(cmd, cwd=jmhPath, out=_redirect, env=env, nonZeroIsFatal=False)\n        if retcode != 0:\n            mx.log(''.join(buildOutput))\n            mx.abort(retcode)\n        timestamp.touch()\n    else:\n        mx.logv('[all Mercurial controlled files in ' + jmhPath + ' are older than ' + timestamp.path + ' - skipping build]')\n\ndef jmh(args):\n    \"\"\"run the JMH benchmarks\n\n    This command respects the standard --vm and --vmbuild options\n    for choosing which VM to run the benchmarks with.\"\"\"\n    if '-h' in args:\n        mx.help_(['jmh'])\n        mx.abort(1)\n\n    vmArgs, benchmarksAndJsons = _extract_VM_args(args)\n\n    benchmarks = [b for b in benchmarksAndJsons if not b.startswith('{')]\n    jmhArgJsons = [b for b in benchmarksAndJsons if b.startswith('{')]\n    jmhOutDir = join(_graal_home, 'mx', 'jmh')\n    if not exists(jmhOutDir):\n        os.makedirs(jmhOutDir)\n    jmhOut = join(jmhOutDir, 'jmh.out')\n    jmhArgs = {'-rff' : jmhOut, '-v' : 'EXTRA' if mx._opts.verbose else 'NORMAL'}\n\n    # e.g. '{\"-wi\" : 20}'\n    for j in jmhArgJsons:\n        try:\n            for n, v in json.loads(j).iteritems():\n                if v is None:\n                    del jmhArgs[n]\n                else:\n                    jmhArgs[n] = v\n        except ValueError as e:\n            mx.abort('error parsing JSON input: {}\\n{}'.format(j, e))\n\n    jmhPath = _get_jmh_path()\n    mx.log('Using benchmarks in ' + jmhPath)\n\n    matchedSuites = set()\n    numBench = [0]\n    for micros in os.listdir(jmhPath):\n        absoluteMicro = os.path.join(jmhPath, micros)\n        if not os.path.isdir(absoluteMicro):\n            continue\n        if not micros.startswith(\"micros-\"):\n            mx.logv('JMH: ignored ' + absoluteMicro + \" because it doesn't start with 'micros-'\")\n            continue\n\n        microJar = os.path.join(absoluteMicro, \"target\", \"microbenchmarks.jar\")\n        if not exists(microJar):\n            mx.log('Missing ' + microJar + ' - please run \"mx buildjmh\"')\n            continue\n        if benchmarks:\n            def _addBenchmark(x):\n                if x.startswith(\"Benchmark:\"):\n                    return\n                match = False\n                for b in benchmarks:\n                    match = match or (b in x)\n\n                if match:\n                    numBench[0] += 1\n                    matchedSuites.add(micros)\n\n            mx.run_java(['-jar', microJar, \"-l\"], cwd=jmhPath, out=_addBenchmark, addDefaultArgs=False)\n        else:\n            matchedSuites.add(micros)\n\n    mx.logv(\"matchedSuites: \" + str(matchedSuites))\n    plural = 's' if not benchmarks or numBench[0] > 1 else ''\n    number = str(numBench[0]) if benchmarks else \"all\"\n    mx.log(\"Running \" + number + \" benchmark\" + plural + '...')\n\n    regex = []\n    if benchmarks:\n        regex.append(r\".*(\" + \"|\".join(benchmarks) + \").*\")\n\n    for suite in matchedSuites:\n        absoluteMicro = os.path.join(jmhPath, suite)\n        (pfx, exe, vm, forkedVmArgs, _) = _parseVmArgs(vmArgs)\n        if pfx:\n            mx.warn(\"JMH ignores prefix: \\\"\" + pfx + \"\\\"\")\n        javaArgs = ['-jar', os.path.join(absoluteMicro, \"target\", \"microbenchmarks.jar\"),\n                    '--jvm', exe,\n                    '--jvmArgs', ' '.join([\"-\" + vm] + forkedVmArgs)]\n        for k, v in jmhArgs.iteritems():\n            javaArgs.append(k)\n            if len(str(v)):\n                javaArgs.append(str(v))\n        mx.run_java(javaArgs + regex, addDefaultArgs=False, cwd=jmhPath)\n\ndef specjvm2008(args):\n    \"\"\"run one or more SPECjvm2008 benchmarks\"\"\"\n\n    def launcher(bm, harnessArgs, extraVmOpts):\n        return sanitycheck.getSPECjvm2008(harnessArgs + [bm]).bench(_get_vm(), extraVmOpts=extraVmOpts)\n\n    availableBenchmarks = set(sanitycheck.specjvm2008Names)\n    for name in sanitycheck.specjvm2008Names:\n        parts = name.rsplit('.', 1)\n        if len(parts) > 1:\n            assert len(parts) == 2\n            group = parts[0]\n            availableBenchmarks.add(group)\n\n    _run_benchmark(args, sorted(availableBenchmarks), launcher)\n\ndef specjbb2013(args):\n    \"\"\"run the composite SPECjbb2013 benchmark\"\"\"\n\n    def launcher(bm, harnessArgs, extraVmOpts):\n        assert bm is None\n        return sanitycheck.getSPECjbb2013(harnessArgs).bench(_get_vm(), extraVmOpts=extraVmOpts)\n\n    _run_benchmark(args, None, launcher)\n\ndef specjbb2005(args):\n    \"\"\"run the composite SPECjbb2005 benchmark\"\"\"\n\n    def launcher(bm, harnessArgs, extraVmOpts):\n        assert bm is None\n        return sanitycheck.getSPECjbb2005(harnessArgs).bench(_get_vm(), extraVmOpts=extraVmOpts)\n\n    _run_benchmark(args, None, launcher)\n\ndef hsdis(args, copyToDir=None):\n    \"\"\"download the hsdis library\n\n    This is needed to support HotSpot's assembly dumping features.\n    By default it downloads the Intel syntax version, use the 'att' argument to install AT&T syntax.\"\"\"\n    flavor = 'intel'\n    if 'att' in args:\n        flavor = 'att'\n    lib = mx.add_lib_suffix('hsdis-' + _arch())\n    path = join(_graal_home, 'lib', lib)\n    if not exists(path):\n        mx.download(path, ['http://lafo.ssw.uni-linz.ac.at/hsdis/' + flavor + \"/\" + lib])\n    if copyToDir is not None and exists(copyToDir):\n        shutil.copy(path, copyToDir)\n\ndef hcfdis(args):\n    \"\"\"disassemble HexCodeFiles embedded in text files\n\n    Run a tool over the input files to convert all embedded HexCodeFiles\n    to a disassembled format.\"\"\"\n\n    parser = ArgumentParser(prog='mx hcfdis')\n    parser.add_argument('-m', '--map', help='address to symbol map applied to disassembler output')\n    parser.add_argument('files', nargs=REMAINDER, metavar='files...')\n\n    args = parser.parse_args(args)\n\n    path = join(_graal_home, 'lib', 'hcfdis-1.jar')\n    if not exists(path):\n        mx.download(path, ['http://lafo.ssw.uni-linz.ac.at/hcfdis-2.jar'])\n    mx.run_java(['-jar', path] + args.files)\n\n    if args.map is not None:\n        addressRE = re.compile(r'0[xX]([A-Fa-f0-9]+)')\n        with open(args.map) as fp:\n            lines = fp.read().splitlines()\n        symbols = dict()\n        for l in lines:\n            addressAndSymbol = l.split(' ', 1)\n            if len(addressAndSymbol) == 2:\n                address, symbol = addressAndSymbol\n                if address.startswith('0x'):\n                    address = long(address, 16)\n                    symbols[address] = symbol\n        for f in args.files:\n            with open(f) as fp:\n                lines = fp.read().splitlines()\n            updated = False\n            for i in range(0, len(lines)):\n                l = lines[i]\n                for m in addressRE.finditer(l):\n                    sval = m.group(0)\n                    val = long(sval, 16)\n                    sym = symbols.get(val)\n                    if sym:\n                        l = l.replace(sval, sym)\n                        updated = True\n                        lines[i] = l\n            if updated:\n                mx.log('updating ' + f)\n                with open('new_' + f, \"w\") as fp:\n                    for l in lines:\n                        print >> fp, l\n\ndef jacocoreport(args):\n    \"\"\"create a JaCoCo coverage report\n\n    Creates the report from the 'jacoco.exec' file in the current directory.\n    Default output directory is 'coverage', but an alternative can be provided as an argument.\"\"\"\n    jacocoreport = mx.library(\"JACOCOREPORT\", True)\n    out = 'coverage'\n    if len(args) == 1:\n        out = args[0]\n    elif len(args) > 1:\n        mx.abort('jacocoreport takes only one argument : an output directory')\n    mx.run_java(['-jar', jacocoreport.get_path(True), '--in', 'jacoco.exec', '--out', out] + [p.dir for p in mx.projects()])\n\ndef sl(args):\n    \"\"\"run an SL program\"\"\"\n    vmArgs, slArgs = _extract_VM_args(args)\n    vm(vmArgs + ['-cp', mx.classpath([\"TRUFFLE\", \"com.oracle.truffle.sl\"]), \"com.oracle.truffle.sl.SLMain\"] + slArgs)\n\ndef isGraalEnabled(vm):\n    return vm != 'original' and not vm.endswith('nograal')\n\ndef jol(args):\n    \"\"\"Java Object Layout\"\"\"\n    jolurl = \"http://lafo.ssw.uni-linz.ac.at/truffle/jol/jol-internals.jar\"\n    joljar = \"lib/jol-internals.jar\"\n    if not exists(joljar):\n        mx.download(joljar, [jolurl])\n\n    candidates = mx.findclass(args, logToConsole=False, matcher=lambda s, classname: s == classname or classname.endswith('.' + s) or classname.endswith('$' + s))\n    if len(candidates) > 10:\n        print \"Found %d candidates. Please be more precise.\" % (len(candidates))\n        return\n\n    vm(['-javaagent:' + joljar, '-cp', os.pathsep.join([mx.classpath(), joljar]), \"org.openjdk.jol.MainObjectInternals\"] + candidates)\n\n# enterprise-truffle\n\ndef jsShellCp():\n    return mx.classpath(\"com.oracle.truffle.js.shell\")\n\ndef jsShellClass():\n    return \"com.oracle.truffle.js.shell.Shell\"\n\ndef jsRunScriptCp():\n    return mx.classpath(\"com.oracle.truffle.js.shell\")\n\ndef jsRunScriptClass():\n    return \"com.oracle.truffle.js.shell.RunScript\"\n\ndef jsREPLCp():\n    return mx.classpath(\"com.oracle.truffle.js.repl\")\n\ndef jsREPLClass():\n    return \"com.oracle.truffle.js.repl.JSREPLServer\"\n\ndef rubyShellCp():\n    return mx.classpath(\"com.oracle.truffle.ruby.shell\")\n\ndef rubyShellClass():\n    return \"com.oracle.truffle.ruby.shell.Shell\"\n\ndef ruby(args):\n    \"\"\"run a Ruby program or shell\"\"\"\n    vmArgs, rubyArgs = _extract_VM_args(args, useDoubleDash=True)\n    vm(vmArgs + ['-cp', rubyShellCp(), rubyShellClass()] + rubyArgs)\n\ndef rubyREPLCp():\n    return mx.classpath(\"com.oracle.truffle.ruby.repl\")\n\ndef rubyREPLClass():\n    return \"com.oracle.truffle.ruby.repl.RubyREPLServer\"\n\ndef jrubyShellCp():\n    return mx.classpath(\"com.oracle.truffle.jruby\")\n\ndef jrubyShellClass():\n    return \"com.oracle.truffle.jruby.shell.Shell\"\n\ndef jruby(args):\n    \"\"\"run a JRuby program or shell\"\"\"\n    vmArgs, jrubyArgs = _extract_VM_args(args, useDoubleDash=True)\n    vm(vmArgs + ['-cp', jrubyShellCp(), jrubyShellClass()] + jrubyArgs)\n\ndef nodeTruffleShellCp():\n    return mx.classpath(\"com.oracle.truffle.nodejs.runtime\")\n\ndef nodeTruffleShellClass():\n    return \"com.oracle.truffle.nodejs.runtime.NodeTruffle\"\n\ndef avatarJSShellCp():\n    return mx.classpath(\"com.oracle.truffle.avatar.js.runtime\")\n\ndef avatarJSShellClass():\n    return \"com.oracle.truffle.avatar.js.runtime.AvatarTruffle\"\n\ndef pxJSShellCp():\n    return mx.classpath(\"com.oracle.truffle.js.px\")\n\ndef pxJSShellClass():\n    return \"com.oracle.truffle.js.px.RunParallelScript\"\n\ndef processorjars(args):\n    return mx.processorjars()\n\ndef truffle_extract_VM_args(args, doubleDash=False):\n    vmArgs, remainder = [], []\n    for (i, arg) in enumerate(args):\n        if any(arg.startswith(prefix) for prefix in ['-X', '-G:', '-D']) or arg in ['-ea', '-esa']:\n            vmArgs += [arg]\n        elif doubleDash and arg == '--':\n            remainder += args[i:]\n            break\n        else:\n            remainder += [arg]\n    return vmArgs, remainder\n\ndef jsshell(args, main):\n    vmArgs, jsArgs = truffle_extract_VM_args(args)\n\n    # after extracting standard vm args, also extract @-prefixed ones\n    vmArgs += [a[1:] for a in jsArgs if a[0] == '@']\n    jsArgs = [a for a in jsArgs if a[0] != '@']\n\n    vm(vmArgs + main + jsArgs)\n\ndef js(args):\n    \"\"\"run a JavaScript program or shell\"\"\"\n    jsshell(args, ['-cp', jsShellCp(), jsShellClass()])\n\ndef jsnashorn(args):\n    \"\"\"run Nashorn JavaScript shell\"\"\"\n    jsshell(args, ['-cp', jsShellCp(), \"jdk.nashorn.tools.Shell\"])\n\ndef jsmozilla(args):\n    \"\"\"run a JavaScript program or shell (for Mozilla test suite)\"\"\"\n    jsshell(args, ['-cp', jsRunScriptCp(), jsRunScriptClass()])\n\ndef jsrepl(args):\n    \"\"\"run a Javascript REPL server\"\"\"\n    vmArgs, jsArgs = _extract_VM_args(args, useDoubleDash=True)\n    vm(vmArgs + ['-cp', jsREPLCp(), jsREPLClass()] + jsArgs)\n\ndef rubyrepl(args):\n    \"\"\"run a Ruby REPL server\"\"\"\n    vmArgs, rubyArgs = _extract_VM_args(args, useDoubleDash=True)\n    vm(vmArgs + ['-cp', rubyREPLCp(), rubyREPLClass()] + rubyArgs)\n\ndef nodeTruffle(args):\n    \"\"\"run a Node.Truffle program\"\"\"\n    jsshell(args, ['-Dnodejs.path=' + os.path.join(_graal_home, 'graal', 'com.oracle.truffle.nodejs.runtime')] + ['-cp', nodeTruffleShellCp(), nodeTruffleShellClass()])\n\ndef jsBenchmarks():\n    import glob\n    benchmarkDir = \"lib/js-benchmarks/\"\n    benchmarks = [os.path.splitext(x)[0] for x in (os.path.relpath(x, benchmarkDir).replace('\\\\', '/') for x in glob.glob(benchmarkDir + \"*.js\") + glob.glob(benchmarkDir + \"*/*.js\")) if x != \"harness.js\" and not x.startswith(\"octane/\") and not x.startswith(\"lib/\")]\n\n    # keep order\n    desired_order = ['octane-richards', 'octane-deltablue', 'octane-crypto', 'octane-raytrace', 'octane-navier-stokes', 'octane-splay', 'octane-earley-boyer', 'octane-regexp',\n                     'octane-box2d', 'octane-gbemu', 'octane-mandreel', 'octane-pdfjs', 'octane-typescript', 'octane-zlib', 'octane-code-load', 'fannkuch', 'nbody']\n    benchmarks = [x[1] for x in sorted([(x in desired_order and 1 + desired_order.index(x) or len(desired_order) + (2 if x.startswith(\"micro-\") else 1), x) for x in benchmarks])]\n    return benchmarks\n\ndef trufflebench(args):\n    \"\"\"run truffle benchmarks\n\n    Usage: mx trufflebench [-XX:...] [benchmarks...] [engines...] -- [jsArgs]\n           mx trufflebench --help\n\n    Harness arguments (after double dash):\n      --iterations=# --warmup-iterations=# .. minimum number of (warmup) iterations\n      --time=# --warmup-time=#             .. minimum (warmup) time in milliseconds\n      --show-warmup --show-each-run        .. show start and end of warmup run; show time after each run\n      --deterministic                      .. run only the minimum number of iterations or amount of time\n\n    Examples:\n      mx trufflebench original octane -XX:+PrintGC\n      mx trufflebench server richards deltablue -- --warmup-iterations=200 --iterations=200\n\n    To update the benchmarks, run mx pulljsbenchmarks\"\"\"\n    benchmarkDir = \"lib/js-benchmarks/\"\n    if not exists(benchmarkDir):\n        pulljsbenchmarks()\n\n    benchmarks_default = jsBenchmarks()\n    benchmarks_available = benchmarks_default + ['octane', 'octane-v0', 'micro']\n    engines_available = ['truffle', 'truffle-server', 'truffle-original', 'truffle-graal', 'truffle-client', 'v8', 'v8-nocrankshaft', 'spidermonkey', 'nashorn', 'nashorn-original', 'nashorn-graal', 'nashorn-server', 'nashorn-client', 'jsc', 'svm']\n    engines_default = ['truffle']\n    benchmarks, engines = [], []\n\n    vmArgs, args = truffle_extract_VM_args(args)\n    vmArgs = vmArgs + [a[1:] for a in args if a[0] == '@']\n    if not any((x.startswith('-Xm') for x in vmArgs)):\n        vmArgs += ['-Xms2g', '-Xmx2g', '-Xss6m']\n    args = [a for a in args if a[0] != '@']\n\n    if \"--help\" in args:\n        for benchmark in benchmarks_available:\n            print benchmark\n        return\n\n    def findneedle(needles, haystack):\n        def takefirst(lamb, seq):\n            for i in seq:\n                found = lamb(i)\n                if found:\n                    return found\n        def warn_approx(needle, found):\n            if found:\n                print \"warning: approximate matches for\", needle, found\n            return found\n        return takefirst(lambda needle: [x for x in haystack if needle.upper() == x.upper()], needles) or \\\n               takefirst(lambda needle: [x for x in haystack if needle.upper() == os.path.basename(x.upper())], needles) or \\\n               takefirst(lambda needle: warn_approx(needle, [x for x in haystack if needle.upper() in x.upper()]), needles)\n\n    engineArgs = []\n    scriptArgs = []\n    onevm = False\n    for arg in args:\n        if arg.endswith(\".js\"):\n            arg = arg[:arg.rindex(\".js\")]\n\n        if arg in engines_available:\n            engines += [arg]\n        elif arg == \"--\":\n            scriptArgs += args[args.index(arg)+1:]\n            break\n        elif arg.startswith(\"--\") or arg.startswith(\"-\"):\n            if arg == '--onevm':\n                onevm = True\n                continue\n            engineArgs += [arg]\n        elif arg in _vmChoices:\n            engines += ['truffle-' + arg]\n        else:\n            found = findneedle([arg, \"octane-\" + arg, \"micro-\" + arg], benchmarks_available)\n            if found:\n                benchmarks += found\n            else:\n                print \"warning: ignored argument:\", arg\n\n    if len(benchmarks) == 0:\n        benchmarks = benchmarks_default\n    if len(engines) == 0:\n        engines = engines_default\n    for benchmark in benchmarks:\n        if benchmark in [\"octane\", \"micro\"]:\n            benchmarks.remove(benchmark)\n            benchmarks += [b for b in benchmarks_available if b.startswith(benchmark + \"-\")]\n        if benchmark == \"octane-v0\":\n            benchmarks.remove(benchmark)\n            benchmarks += ['octane-richards', 'octane-deltablue', 'octane-crypto', 'octane-raytrace', 'octane-navier-stokes', 'octane-splay', 'octane-earley-boyer', 'octane-regexp']\n    engines = [x + '-' + _get_vm() if x in ['truffle', 'nashorn'] else x for x in engines]\n\n    class Timer(object):\n        def __enter__(self):\n            self.start = time.time()\n        def __exit__(self, exc_type, exc_value, traceback):\n            self.finish = time.time()\n        def duration_in_seconds(self):\n            return self.finish - self.start\n    timer = Timer()\n\n    def runbench(benchmarks, engine):\n        print engine, ' '.join(benchmarks) + ':'\n        result = -1\n        benchmarkArgs = [benchmarkDir + \"harness.js\", \"--\"] + scriptArgs + [benchmarkDir + benchmark + \".js\" for benchmark in benchmarks]\n        with timer:\n            if engine.startswith('truffle-'):\n                vmoption = engine.split('-', 1)[1]\n                vmargs = [x for x in vmArgs if isGraalEnabled(vmoption) or not x.startswith('-G:')]\n                if not isGraalEnabled(vmoption) and len(scriptArgs) == 0:\n                    insertindex = benchmarkArgs.index('--') + 1\n                    benchmarkArgs[insertindex:insertindex] = ['--iterations=1', '--warmup-iterations=1', '--time=3000', '--warmup-time=3000']\n                elif isGraalEnabled(vmoption) and not '-G:-TraceTruffleCompilation' in vmArgs:\n                    vmargs += ['-G:+TraceTruffleCompilation']\n                result = vm(vmargs + ['-cp', jsShellCp(), jsShellClass()] + engineArgs + benchmarkArgs, vm=vmoption)\n            elif engine == 'v8' or engine.startswith('v8-'):\n                result = mx.run(['lib/d8'] + ['--' + x for x in engine.split('-', 1)[1:]] + engineArgs + benchmarkArgs)\n            elif engine.startswith('nashorn-'):\n                vmoption = engine.split('-', 1)[1]\n                vmargs = [x for x in vmArgs if isGraalEnabled(vmoption) or not x.startswith('-G:')]\n                result = vm(vmargs + [\"jdk.nashorn.tools.Shell\"] + engineArgs + benchmarkArgs, vm=vmoption)\n            elif engine == 'spidermonkey':\n                result = mx.run(['lib/spidermonkey/js'] + engineArgs + benchmarkArgs)\n            elif engine == 'jsc':\n                result = mx.run(['lib/jsc/jsc'] + engineArgs + benchmarkArgs)\n            elif engine == 'svm':\n                result = mx.run(['svmbuild/jscomp'] + engineArgs + benchmarkArgs)\n        if result == 0:\n            print \"(%.3fs)\" % timer.duration_in_seconds()\n\n    if onevm:\n        for engine in engines:\n            runbench(benchmarks, engine)\n    else:\n        for benchmark in benchmarks:\n            for engine in engines:\n                runbench([benchmark], engine)\n\ndef pulljsbenchmarks(args=None):\n    benchmarkDir = \"lib/js-benchmarks\"\n    url = \"https://lafo.ssw.uni-linz.ac.at/hg/js-benchmarks/\"\n    pullbench(benchmarkDir, url)\n\ndef pullavatarjsbench(args=None):\n    benchmarkDir = \"lib/avatar/bench\"\n    url = \"https://lafo.ssw.uni-linz.ac.at/hg/nodejs-benchmarks/\"\n    pullbench(benchmarkDir, url)\n\ndef pullbench(benchmarkDir, url):\n    if not exists(benchmarkDir):\n        print benchmarkDir, \"does not exist, cloning from\", url\n        mx.run([\"hg\", \"clone\", url, benchmarkDir])\n    else:\n        mx.run([\"hg\", \"pull\", \"-u\", \"-R\", benchmarkDir])\n\ndef jsjar(args=None):\n    \"\"\"make trufflejs.jar\"\"\"\n    mx.archive([\"@TRUFFLEJS\"])\n    mx.run([mx.exe_suffix(join(mx.java().jdk, 'bin', 'pack200')), '-r', '-G', 'trufflejs.jar'])\n\ndef avatarjsjar(args=None):\n    \"\"\"make truffleavatarjs.jar\"\"\"\n    getAvatarJS()\n    mx.archive([\"@AVATARTRUFFLEJS\"])\n    mx.run([mx.exe_suffix(join(mx.java().jdk, 'bin', 'pack200')), '-r', '-G', 'avatartrufflejs.jar'])\n\ndef alienshell(args, title, dstdir, exename, url=None):\n    exefile = dstdir + exename\n    isupdate = args == ['update']\n\n    if isupdate or not exists(exefile) and url:\n        srcname = os.path.basename(url)\n        dstname = srcname if srcname.endswith('.zip') else exename\n        dstfile = os.path.join(dstdir, dstname)\n\n        def geturldate(url):\n            from urllib2 import urlopen\n            f = urlopen(url)\n            f.close()\n            return datetime.datetime(*f.info().getdate('last-modified')[0:6])\n\n        def isoutdated(filename):\n            return datetime.datetime.fromtimestamp(os.path.getmtime(filename)) < geturldate(url)\n\n        if not exists(exefile) or isoutdated(exefile):\n            print \"downloading %s from %s to %s...\" % (title, url, dstfile)\n            mx.download(dstfile, [url])\n            if srcname.endswith('.zip'):\n                with zipfile.ZipFile(dstfile, 'r') as zf:\n                    zf.extractall(dstdir)\n            if mx.get_os() != 'windows':\n                os.chmod(exefile, 0755)\n        elif isupdate:\n            print \"up to date (%s)\" % (datetime.date.fromtimestamp(os.path.getmtime(dstfile)))\n\n    if not isupdate:\n        mx.run([exefile] + args)\n\ndef spidermonkey(args=None):\n    baseurl = \"http://ftp.mozilla.org/pub/mozilla.org/firefox/nightly/latest-trunk/\"\n    zipname = {'linux': 'jsshell-linux-x86_64.zip', 'windows': 'jsshell-win64-x86_64.zip', 'darwin': 'jsshell-mac.zip'}[mx.get_os()]\n    destdir = \"lib/spidermonkey/\"\n    exename = mx.exe_suffix(\"js\")\n    alienshell(args, \"spidermonkey nightly\", destdir, exename, baseurl + zipname)\n\ndef v8(args=None):\n    url = \"http://lafo.ssw.uni-linz.ac.at/truffle/bench/\" + {\"windows\": \"d8.exe\", \"darwin\": \"d8.mac\"}.get(mx.get_os(), \"d8\")\n    exename = mx.exe_suffix(\"d8\")\n    alienshell(args, \"V8\", \"lib/\", exename, url)\n\ndef javascriptcore(args=None):\n    alienshell(args, \"JavaScriptCore\", \"lib/jsc/\", \"jsc\")\n\ndef fetchTest262():\n    libdir = join(_graal_home, 'lib')\n    version = \"9b669da\"\n\n    test262dir = join(libdir, 'test262-' + version)\n    test262runner = join(test262dir, 'tools', 'packaging', 'test262.py')\n    test262tar = test262dir + '.tar.bz2'\n    if not exists(test262runner):\n        if not exists(test262tar):\n            mx.download(test262tar, ['http://lafo.ssw.uni-linz.ac.at/truffle/js/test262-' + version + '.tar.bz2'])\n        mx.run(['tar', '-jxf', 'test262-' + version + '.tar.bz2'], cwd=libdir)\n    return test262runner\n\ndef test262(args):\n    \"\"\"run the test262 conformance suite\"\"\"\n    fetchTest262()\n    if not mx.java().debug_port is None and not any(arg.startswith(\"timeout=\") for arg in args):\n        args += [\"timeout=0\"]\n    vm(['-ea', '-esa', '-cp', mx.classpath(\"com.oracle.truffle.js.test\"), \"com.oracle.truffle.js.test.test262.Test262\"] + args, \"original\")\n\ndef fetchTestNashorn():\n    libdir = join(_graal_home, 'lib')\n    version = \"18edd7a1b166\"\n\n    testNashorndir = join(libdir, 'testnashorn-' + version)\n    testNashornChecker = join(testNashorndir, 'test', 'script', 'basic', 'NASHORN-11.js')\n    testNashorntar = testNashorndir + '.tar.bz2'\n    if not exists(testNashornChecker):\n        if not exists(testNashorntar):\n            mx.download(testNashorntar, ['http://lafo.ssw.uni-linz.ac.at/truffle/js/testnashorn-' + version + '.tar.bz2'])\n        mx.run(['tar', '-jxf', 'testnashorn-' + version + '.tar.bz2'], cwd=libdir)\n\n    externalDir = join(testNashorndir, 'test', 'script', 'external')\n\n    externalYui = join(externalDir, 'yui')\n    if not exists(externalYui):\n        mx.download(join(externalYui, 'yui.js'), ['http://yui.yahooapis.com/3.5.1/build/yui/yui.js'])\n        mx.download(join(externalYui, 'yui-min.js'), ['http://yui.yahooapis.com/3.5.1/build/yui/yui-min.js'])\n\n    externalJQuery = join(externalDir, 'jquery')\n    if not exists(externalJQuery):\n        mx.download(join(externalJQuery, 'jquery-1.7.2.js'), ['http://code.jquery.com/jquery-1.7.2.js'])\n        mx.download(join(externalJQuery, 'jquery-1.7.2.min.js'), ['http://code.jquery.com/jquery-1.7.2.min.js'])\n\n    externalPrototype = join(externalDir, 'prototype')\n    if not exists(externalPrototype):\n        mx.download(join(externalPrototype, 'prototype.js'), ['http://ajax.googleapis.com/ajax/libs/prototype/1.7.0/prototype.js'])\n\n    externalUnderscore = join(externalDir, 'underscore')\n    if not exists(externalUnderscore):\n        mx.download(join(externalUnderscore, 'underscore.js'), ['http://underscorejs.org/underscore.js'])\n        mx.download(join(externalUnderscore, 'underscore-min.js'), ['http://underscorejs.org/underscore-min.js'])\n\n    externalOctane = join(externalDir, 'octane')\n    if not exists(externalOctane):\n        externalOctaneTar = testNashorndir + '-octane.tar.bz2'\n        externalOctaneTarName = 'testnashorn-' + version + '-octane.tar.bz2'\n        if not exists(externalOctaneTar):\n            mx.download(externalOctaneTar, ['http://lafo.ssw.uni-linz.ac.at/truffle/js/' + externalOctaneTarName])\n        mx.run(['tar', '-jxf', externalOctaneTarName], cwd=libdir)\n\n    externalSunspider = join(externalDir, 'sunspider')\n    if not exists(externalSunspider):\n        externalSunspiderTar = testNashorndir + '-sunspider.tar.bz2'\n        externalSunspiderTarName = 'testnashorn-' + version + '-sunspider.tar.bz2'\n        if not exists(externalSunspiderTar):\n            mx.download(externalSunspiderTar, ['http://lafo.ssw.uni-linz.ac.at/truffle/js/' + externalSunspiderTarName])\n        mx.run(['tar', '-jxf', externalSunspiderTarName], cwd=libdir)\n\n    return testNashornChecker\n\ndef testnashorn(args):\n    \"\"\"run the testNashorn conformance suite\"\"\"\n    testdir = join(_graal_home, 'lib', 'testnashorn-18edd7a1b166')\n    fetchTestNashorn()\n    if not mx.java().debug_port is None and not any(arg.startswith(\"timeout=\") for arg in args):\n        args += [\"timeout=0\"]\n    vm(['-ea', '-esa', '-cp', mx.classpath(\"com.oracle.truffle.js.test\"), \"com.oracle.truffle.js.test.nashorn.TestNashorn\"] + args, \"original\", cwd=testdir)\n\ndef parallelJS(args):\n    \"\"\"run a JS program using the JS parallel extensions (Px)\"\"\"\n    vmArgs, pxArgs = truffle_extract_VM_args(args)\n    numArgs = len(pxArgs)\n    if numArgs == 0:\n        print 'usage: mx px [px or mx js options] filename'\n    vmArgs += ['-server', '-Xmx6G'] + ['-cp', pxJSShellCp(), pxJSShellClass()] + pxArgs\n    vm(vmArgs)\n\ndef testParallelJS(args):\n    \"\"\"run the Px JUnit tests\"\"\"\n    def isValidEngine(engine):\n        if engine == 'stm' or engine == 'pev' or engine == 'ts' or engine == 'pjs':\n            return True\n        return False\n\n    vmArgs, pxArgs = truffle_extract_VM_args(args)\n    if len(pxArgs) == 0:\n        unittest(vmArgs + ['-Dtruffle.js.px=pjs', '-Dtruffle.js.px.profile=true', 'js.px.test.pjs'])\n        unittest(vmArgs + ['-Dtruffle.js.px=stm', '-Dtruffle.js.px.profile=true', 'js.px.test.tm.tl2'])\n        unittest(vmArgs + ['-Dtruffle.js.px=ts', '-Dtruffle.js.px.profile=true', 'js.px.test.ts'])\n    elif isValidEngine(pxArgs[0]):\n        if pxArgs[0] == 'stm':\n            unittest(vmArgs + ['-Dtruffle.js.px=stm', '-Dtruffle.js.px.profile=true', 'js.px.test.tm.tl2'])\n        elif pxArgs[0] == 'pjs':\n            unittest(vmArgs + ['-Dtruffle.js.px=pjs', '-Dtruffle.js.px.profile=true', 'js.px.test.pjs'])\n        elif pxArgs[0] == 'pev':\n            unittest(vmArgs + ['-Dtruffle.js.px=pev', '-Dtruffle.js.px.profile=true', 'js.px.test.tm.tl2'])\n        elif pxArgs[0] == 'ts':\n            unittest(vmArgs + ['-Dtruffle.js.px=ts', '-Dtruffle.js.px.profile=true', 'js.px.test.ts'])\n        else:\n            print 'usage: mx pxtest [engine]'\n\ndef runAvatarJS(args, vmOption=None):\n    vmArgs, avatarJSArgs = truffle_extract_VM_args(args)\n    vmArgs += [a[1:] for a in avatarJSArgs if a[0] == '@']\n    avatarJSArgs = [a for a in avatarJSArgs if a[0] != '@']\n    # Thread stack size increased to 2m (required by long regexp)\n    vmArgs += avatarJSArgs\n    if vmOption == None:\n#        vm(vmArgs, cwd=_graal_home)\n        vm(vmArgs)\n    else:\n#        vm(vmArgs, cwd=_graal_home, vm=vmOption)\n        vm(vmArgs, vm=vmOption)\n\ndef avatarJS(args, vmOption=None):\n    \"\"\"run an Avatar.JS program on top of Truffle\"\"\"\n    getAvatarJS()\n    args = ['-Xss2m', '-Davatar.scriptEngine=Truffle.JS', '-Dtruffle.js.functionLookup=com.oracle.truffle.avatar.js.runtime.builtins.AvatarBuiltinLookup', '-Djava.library.path=' + _avatarJSLibPath] + ['-cp', avatarJSShellCp(), avatarJSShellClass()] + args\n    runAvatarJS(args, vmOption)\n\ndef avatarJSOrig(args):\n    \"\"\"run an Avatar.JS program on the current VM [orig mode]\"\"\"\n    getAvatarJSOrig()\n    args = ['-Djava.library.path=' + _avatarJSOrigPath] + ['-jar', join(_avatarJSOrigPath, _avatarJSOrigJar)] + args\n    runAvatarJS(args, 'original')\n\ndef testAvatarJS(args):\n    \"\"\"run Avatar.JS tests [simple]\"\"\"\n    getAvatarJS()\n\n    if args:\n        avatarArgList = [join(_avatarJSTestPath, _avatarJSTestRunner)] + args\n    else:\n        avatarArgList = [join(_avatarJSTestPath, _avatarJSTestRunner), join(_avatarJSTestPath, 'simple')]\n\n    avatarJS(avatarArgList)\n\ndef testAvatarJSGate(args=None):\n    testAvatarJS([join(_avatarJSTestPath, 'simple', 'test-assert.js'), join(_avatarJSTestPath, 'simple', 'test-buffer.js')])\n\ndef getAvatarJS(args=None):\n    _getAvatarZip(_avatarJSLibPath, _avatarJSZip, \"http://lafo.ssw.uni-linz.ac.at/truffle/avatar/\")\n\ndef getAvatarJSOrig(args=None):\n    _getAvatarZip(_avatarJSOrigPath, _avatarJSOrigZip, \"http://lafo.ssw.uni-linz.ac.at/truffle/avatar/orig/\")\n\ndef _getAvatarZip(libPath, zipName, url):\n    zipPath = join(libPath, zipName)\n    if not exists(zipPath):\n        completeUrl = url + zipName\n        print (zipPath, \"does not exist, downloading from\", completeUrl)\n        mx.download(zipPath, [completeUrl])\n        mx.run(['bash', '-c', 'yes | unzip ' + zipName], cwd=libPath,)\n\n_avatarJSLibPath = join(_graal_home, 'lib', 'avatar')\n\n_avatarJSTestPath = join(_avatarJSLibPath, 'test')\n\n_avatarJSOrigPath = join(_avatarJSLibPath, 'orig')\n\n_avatarJSTestRunner = 'test-runner.js'\n\n_avatarJSZip = 'avatarjs-0.12.zip'\n\n_avatarJSOrigZip = 'avatarjs-orig-14_06_26.zip'\n\n_avatarJSOrigJar = 'avatar-js.jar'\n\ndef avatarJSBench(args):\n    \"\"\"Run Avatar.js benchmarks\n\n    Usage: mx avatarjsbench [@-XX:...] [engines...] [benchmarks...] [harness opts...]\n           mx avatarjsbench --help\n\n    Engines:\n      truffle-server\n      truffle-original\n      nashorn\n\n    Benchmarks:\n      mx avatarjsbench -l\n\n    Examples:\n      *) print harness opts: mx avatarjsbench --help\n      *) run with truffle with graal (hosted mode): mx avatarjsbench\n      *) run with truffle with graal (hosted mode): mx avatarjsbench truffle-server\n      *) run with truffle without graal: mx --vm original avatarjsbench\n      *) run with truffle without graal: mx avatarjsbench truffle-original\n      *) run with nashorn: mx avatarjsbench nashorn\n\n    To update the benchmarks, run mx pullavatarjsbench\"\"\"\n\n    benchmarks, engines = [], []\n    benchArgs, engineArgs = [], []\n    engines_available = ['truffle-server', 'truffle-original', 'nashorn']\n    engines_default = ['default']\n    for arg in args:\n        if arg in engines_available:\n            engines += [arg]\n        elif arg[0] == '@':\n            engineArgs += [arg]\n        elif arg == '-h' or arg == '--help' or arg == '-l':\n            benchArgs += [arg]\n        elif arg[0] == '-':\n            print 'Warning! Ignored argument: ' + arg\n        else:\n            benchmarks += [arg]\n\n    if len(engines) == 0:\n        engines = engines_default\n\n    parsedArgs = engineArgs + [join('lib', 'avatar', 'bench', 'harness.js')] + benchArgs + benchmarks\n\n    for engine in engines:\n        if engine == engines_default[0]:\n            avatarJS(parsedArgs)\n        elif engine == engines_available[0]:\n            avatarJS(parsedArgs, 'server')\n        elif engine == engines_available[1]:\n            avatarJS(parsedArgs, 'original')\n        elif engine == engines_available[2]:\n            avatarJSOrig(parsedArgs)\n        else:\n            print 'Warning! Ignored engine: ' + engine\n\n# enterprise-truffle\n\ndef site(args):\n    \"\"\"create a website containing javadoc and the project dependency graph\"\"\"\n\n    return mx.site(['--name', 'Graal',\n                    '--jd', '@-tag', '--jd', '@test:X',\n                    '--jd', '@-tag', '--jd', '@run:X',\n                    '--jd', '@-tag', '--jd', '@bug:X',\n                    '--jd', '@-tag', '--jd', '@summary:X',\n                    '--jd', '@-tag', '--jd', '@vmoption:X',\n                    '--overview', join(_graal_home, 'graal', 'overview.html'),\n                    '--title', 'Graal OpenJDK Project Documentation',\n                    '--dot-output-base', 'projects'] + args)\n\ndef generateZshCompletion(args):\n    \"\"\"generate zsh completion for mx\"\"\"\n    try:\n        from genzshcomp import CompletionGenerator\n    except ImportError:\n        mx.abort(\"install genzshcomp (pip install genzshcomp)\")\n\n    # need to fake module for the custom mx arg parser, otherwise a check in genzshcomp fails\n    originalModule = mx._argParser.__module__\n    mx._argParser.__module__ = \"argparse\"\n    generator = CompletionGenerator(\"mx\", mx._argParser)\n    mx._argParser.__module__ = originalModule\n\n    # strip last line and define local variable \"ret\"\n    complt = \"\\n\".join(generator.get().split('\\n')[0:-1]).replace('context state line', 'context state line ret=1')\n\n    # add array of possible subcommands (as they are not part of the argument parser)\n    complt += '\\n  \": :->command\" \\\\\\n'\n    complt += '  \"*::args:->args\" && ret=0\\n'\n    complt += '\\n'\n    complt += 'case $state in\\n'\n    complt += '\\t(command)\\n'\n    complt += '\\t\\tlocal -a main_commands\\n'\n    complt += '\\t\\tmain_commands=(\\n'\n    for cmd in sorted(mx._commands.iterkeys()):\n        c, _ = mx._commands[cmd][:2]\n        doc = c.__doc__\n        complt += '\\t\\t\\t\"{0}'.format(cmd)\n        if doc:\n            complt += ':{0}'.format(_fixQuotes(doc.split('\\n', 1)[0]))\n        complt += '\"\\n'\n    complt += '\\t\\t)\\n'\n    complt += '\\t\\t_describe -t main_commands command main_commands && ret=0\\n'\n    complt += '\\t\\t;;\\n'\n\n    complt += '\\t(args)\\n'\n    # TODO: improve matcher: if mx args are given, this doesn't work\n    complt += '\\t\\tcase $line[1] in\\n'\n    complt += '\\t\\t\\t(vm)\\n'\n    complt += '\\t\\t\\t\\tnoglob \\\\\\n'\n    complt += '\\t\\t\\t\\t\\t_arguments -s -S \\\\\\n'\n    complt += _appendOptions(\"graal\", r\"G\\:\")\n    # TODO: fix -XX:{-,+}Use* flags\n    complt += _appendOptions(\"hotspot\", r\"XX\\:\")\n    complt += '\\t\\t\\t\\t\\t\"-version\" && ret=0 \\n'\n    complt += '\\t\\t\\t\\t;;\\n'\n    complt += '\\t\\tesac\\n'\n    complt += '\\t\\t;;\\n'\n    complt += 'esac\\n'\n    complt += '\\n'\n    complt += 'return $ret'\n    print complt\n\ndef _fixQuotes(arg):\n    return arg.replace('\\\"', '').replace('\\'', '').replace('`', '').replace('{', '\\\\{').replace('}', '\\\\}').replace('[', '\\\\[').replace(']', '\\\\]')\n\ndef _appendOptions(optionType, optionPrefix):\n    def isBoolean(vmap, field):\n        return vmap[field] == \"Boolean\" or vmap[field] == \"bool\"\n\n    def hasDescription(vmap):\n        return vmap['optDefault'] or vmap['optDoc']\n\n    complt = \"\"\n    for vmap in _parseVMOptions(optionType):\n        complt += '\\t\\t\\t\\t\\t-\"'\n        complt += optionPrefix\n        if isBoolean(vmap, 'optType'):\n            complt += '\"{-,+}\"'\n        complt += vmap['optName']\n        if not isBoolean(vmap, 'optType'):\n            complt += '='\n        if hasDescription(vmap):\n            complt += \"[\"\n        if vmap['optDefault']:\n            complt += r\"(default\\: \" + vmap['optDefault'] + \")\"\n        if vmap['optDoc']:\n            complt += _fixQuotes(vmap['optDoc'])\n        if hasDescription(vmap):\n            complt += \"]\"\n        complt += '\" \\\\\\n'\n    return complt\n\ndef _parseVMOptions(optionType):\n    parser = OutputParser()\n    # TODO: the optDoc part can wrapped accross multiple lines, currently only the first line will be captured\n    # TODO: fix matching for float literals\n    jvmOptions = re.compile(\n        r\"^[ \\t]*\"\n        r\"(?P<optType>(Boolean|Integer|Float|Double|String|bool|intx|uintx|ccstr|double)) \"\n        r\"(?P<optName>[a-zA-Z0-9]+)\"\n        r\"[ \\t]+=[ \\t]*\"\n        r\"(?P<optDefault>([\\-0-9]+(\\.[0-9]+(\\.[0-9]+\\.[0-9]+))?|false|true|null|Name|sun\\.boot\\.class\\.path))?\"\n        r\"[ \\t]*\"\n        r\"(?P<optDoc>.+)?\",\n        re.MULTILINE)\n    parser.addMatcher(ValuesMatcher(jvmOptions, {\n        'optType' : '<optType>',\n        'optName' : '<optName>',\n        'optDefault' : '<optDefault>',\n        'optDoc' : '<optDoc>',\n        }))\n\n    # gather graal options\n    output = StringIO.StringIO()\n    vm(['-XX:-BootstrapGraal', '-G:+PrintFlags' if optionType == \"graal\" else '-XX:+PrintFlagsWithComments'],\n       vm=\"graal\",\n       vmbuild=\"optimized\",\n       nonZeroIsFatal=False,\n       out=output.write,\n       err=subprocess.STDOUT)\n\n    valueMap = parser.parse(output.getvalue())\n    return valueMap\n\ndef findbugs(args):\n    '''run FindBugs against non-test Java projects'''\n    findBugsHome = mx.get_env('FINDBUGS_HOME', None)\n    if findBugsHome:\n        findbugsJar = join(findBugsHome, 'lib', 'findbugs.jar')\n    else:\n        findbugsLib = join(_graal_home, 'lib', 'findbugs-3.0.0')\n        if not exists(findbugsLib):\n            tmp = tempfile.mkdtemp(prefix='findbugs-download-tmp', dir=_graal_home)\n            try:\n                findbugsDist = join(tmp, 'findbugs.zip')\n                mx.download(findbugsDist, ['http://lafo.ssw.uni-linz.ac.at/graal-external-deps/findbugs-3.0.0.zip', 'http://sourceforge.net/projects/findbugs/files/findbugs/3.0.0/findbugs-3.0.0.zip'])\n                with zipfile.ZipFile(findbugsDist) as zf:\n                    candidates = [e for e in zf.namelist() if e.endswith('/lib/findbugs.jar')]\n                    assert len(candidates) == 1, candidates\n                    libDirInZip = os.path.dirname(candidates[0])\n                    zf.extractall(tmp)\n                shutil.copytree(join(tmp, libDirInZip), findbugsLib)\n            finally:\n                shutil.rmtree(tmp)\n        findbugsJar = join(findbugsLib, 'findbugs.jar')\n    assert exists(findbugsJar)\n    nonTestProjects = [p for p in mx.projects() if not p.name.endswith('.test') and not p.name.endswith('.jtt')]\n    outputDirs = [p.output_dir() for p in nonTestProjects]\n    findbugsResults = join(_graal_home, 'findbugs.results')\n\n    cmd = ['-jar', findbugsJar, '-textui', '-low', '-maxRank', '15']\n    if sys.stdout.isatty():\n        cmd.append('-progress')\n    cmd = cmd + ['-auxclasspath', mx.classpath(['GRAAL'] + [p.name for p in nonTestProjects]), '-output', findbugsResults, '-exitcode'] + args + outputDirs\n    exitcode = mx.run_java(cmd, nonZeroIsFatal=False)\n    if exitcode != 0:\n        with open(findbugsResults) as fp:\n            mx.log(fp.read())\n    os.unlink(findbugsResults)\n    return exitcode\n\ndef checkheaders(args):\n    \"\"\"check Java source headers against any required pattern\"\"\"\n    failures = {}\n    for p in mx.projects():\n        if p.native:\n            continue\n\n        csConfig = join(mx.project(p.checkstyleProj).dir, '.checkstyle_checks.xml.disabled')\n        dom = xml.dom.minidom.parse(csConfig)\n        for module in dom.getElementsByTagName('module'):\n            if module.getAttribute('name') == 'RegexpHeader':\n                for prop in module.getElementsByTagName('property'):\n                    if prop.getAttribute('name') == 'header':\n                        value = prop.getAttribute('value')\n                        matcher = re.compile(value, re.MULTILINE)\n                        for sourceDir in p.source_dirs():\n                            for root, _, files in os.walk(sourceDir):\n                                for name in files:\n                                    if name.endswith('.java') and name != 'package-info.java':\n                                        f = join(root, name)\n                                        with open(f) as fp:\n                                            content = fp.read()\n                                        if not matcher.match(content):\n                                            failures[f] = csConfig\n    for n, v in failures.iteritems():\n        mx.log('{}: header does not match RegexpHeader defined in {}'.format(n, v))\n    return len(failures)\n\n# Substrate VM\n\ndef _get_universal_image_sourcepath():\n    \"\"\" Gets a source path for use with the BootImageGenerator -sourcepath option\n        that includes available sources for all project and libraries.\"\"\"\n    sp = []\n    for dep in mx.sorted_deps(None, includeLibs=True):\n        if dep.isLibrary():\n            p = dep.get_source_path(resolve=True)\n            if p:\n                sp.append(p)\n        elif dep.isProject():\n            for p in dep.source_dirs():\n                sp.append(p)\n    jdkSrc = join(mx.java().jdk, 'src.zip')\n    if exists(jdkSrc):\n        sp.append(jdkSrc)\n    return os.pathsep.join(sp)\n\ndef image(args):\n    \"\"\"Generate a SubstrateVM image\n       Options:\n           -project=<project dir>   project to search for classes with entry points\n           -asserts                 generate image with asserts enabled\n       For other options, please run `mx image -help'\"\"\"\n\n    project = ''\n    clazz = ''\n\n    debugArgs = ['-da', '-dsa']\n\n    if len(args) > 0:\n        i = 0\n        while i < len(args):\n            if args[i].startswith('-project='):\n                project = args.pop(i)[9:]\n            elif args[i].startswith('-class='):\n                clazz = args[i][7:]\n                i = i + 1\n            elif args[i] == '-asserts':\n                debugArgs = ['-ea', '-esa']\n                args.pop(i)\n            else:\n                i = i + 1\n\n    classpath = mx.classpath('com.oracle.svm.hosted')\n\n    # infer project from main class name if no project is specified explicitly\n    if project == '' and clazz != '':\n        prefix = clazz\n        p = mx.project(prefix, False)\n        while p is None:\n            idx = prefix.rfind('.')\n            if idx == -1:\n                mx.abort('no project prefix found in class name ' + clazz)\n            prefix = prefix[0:idx]\n            p = mx.project(prefix, False)\n        project = prefix\n\n    # if a project is given the classpath of which needs to be added, elide all duplicate class path entries\n    if project != '':\n        cpis = (classpath + ':' + mx.classpath(project)).split(':')\n        cpis = list(set(cpis))\n        classpath = ':'.join(cpis)\n    vmArgs, normalArgs = _extract_VM_args(args, useDoubleDash=True, defaultAllVMArgs=False)\n    vm(['-Xms2G', '-Xmx4G'] + debugArgs + vmArgs + ['-cp', classpath, 'com.oracle.svm.hosted.BootImageGenerator'] + normalArgs)\n\ndef mockupdb(args=None):\n    \"\"\"Mockup DB setup tool (check/install, clean)\n       Always perform check and install if no present. Use -clean if the default mockup db home needs to be cleaned before hand.\n       Options:\n           -clean\n    \"\"\"\n    mdbhome = join(mx.project('com.oracle.walnut.db.qshtest').dir, 'mdb')\n    if args:\n        if len(args) != 1 or args[0] != '-clean':\n            mx.abort('mockupdb: invalid argument')\n        # force clean before anything else\n        try:\n            if isdir(mdbhome):\n                shutil.rmtree(mdbhome)\n            else:\n                os.remove(mdbhome)\n        except OSError:\n            pass\n\n    mdbArchive = join(mx.project('com.oracle.walnut.db.qshtest').dir, 'mockup_db.zip')\n    if not os.path.isdir(mdbhome):\n        if exists(mdbhome):\n            mx.abort('mockupdb: corrupted setup => ' + mdbhome + ' not a directory. Manually verify/remove before trying setting up again')\n        else:\n            os.makedirs(mdbhome)\n            with zipfile.ZipFile(mdbArchive) as z:\n                z.extractall(mdbhome)\n\n    missingFiles = False\n    with zipfile.ZipFile(mdbArchive) as z:\n        for f in z.namelist():\n            if not exists(join(mdbhome, f)):\n                print \"*** Mockup DB file \" + f + \" is missing\"\n                missingFiles = True\n\n    if missingFiles:\n        mx.abort('mockupdb: some files are missing => clean mockup db install (mx mockupdb -clean) before re-running')\n\ndef qshtestCompare(testResult, expectedResult, diffLog, testName=None):\n    \"\"\" Compare result of a test against expected result, print the difference to the diff log.\n    Return True if difference where found.\n    \"\"\"\n    with open(testResult) as f:\n        resultLines = f.readlines()\n    with open(expectedResult) as f:\n        expectedLines = f.readlines()\n\n    diff = list(difflib.unified_diff(resultLines, expectedLines, 'test output', 'expected output', n=1))\n    if len(diff) > 0:\n        if testName:\n            diffLog.write('*** FAILED! ' + testName + '\\n')\n        diffLog.writelines(diff)\n        return True\n    diffLog.write('*** SUCCESS ' + testName + '\\n')\n    return False\n\ndef qshtest(args=None):\n    \"\"\"Walnut unit tests\n    Run qsh requests registered in testlist against mockup DB and compare the results to pre-generated results\n    Also used to regenerate test results. This will cause changes to the svm repository that'll need to be committed if\n    they're destined to become the new test results.\n    \"\"\"\n    # make sure mockup db is setup\n    mockupdb()\n    mdbhome = join(mx.project('com.oracle.walnut.db.qshtest').dir, 'mdb')\n    validResultDir = join(mx.project('com.oracle.walnut.db.qshtest').dir, 'tests')\n    generate = False\n    suffix = ''\n    if args:\n        if len(args) > 1 or args[0] != '-generate-results':\n            print 'qshtest: invalid argument'\n            return\n        generate = True\n        outDir = validResultDir\n        suffix = '.expected'\n        print 'generating results from testlist in ' + validResultDir\n    else:\n        outDir = tempfile.mkdtemp(suffix='', prefix='qshtest', dir='/tmp')\n\n    numFailures = 0\n    with open(join(validResultDir, 'testslist')) as testslist:\n        testNum = 1\n        for line in testslist:\n            if not line.startswith('#'):\n                queryString = line.strip()\n                if len(queryString) > 0:\n                    testName = 'test' + str(testNum)\n                    resultFileName = testName + suffix\n                    qsh(['-mdbhome=' + mdbhome, '-out=' + join(outDir, resultFileName), queryString])\n                    if not generate:\n                        if qshtestCompare(join(outDir, resultFileName), join(validResultDir, resultFileName + '.expected'), sys.stdout, testName + ' ' + queryString):\n                            numFailures += 1\n                    testNum += 1\n    if numFailures > 0:\n        mx.abort('*** FAILED ' + str(numFailures) + ' qshtests')\n\n# Source information is by default set to JRE's used to build the image for Graal classes.\n# This append to a list of gdb commands a list of set substitute-path command for package\n# we interrested in when doing source level debugging with gdb\n# One may filter out unwanted packages -- based on package suffixes, e.g., all hsail packages etc.\ndef appendPathSubstitution(unwanted, gdbCmdsList):\n    graal_projects = [ p for p in mx.projects() if (p.name.startswith('com.oracle.graal') or p.name.startswith('com.oracle.truffle.api')) and not p.native and not p.name.rsplit('.', 1)[1] in unwanted]\n    jreSrc = jdkhome(_get_vm()) + '/jre/src/'\n    cmdPrefix = 'set substitute-path '+ jreSrc\n    \n    for p in graal_projects:\n        projectNameAsPath = p.name.replace('.','/')\n        gdbCmdsList.append(cmdPrefix + projectNameAsPath + ' ' + p.source_dirs()[0] + '/' + projectNameAsPath + '\\n')\n\n\n# Make sure we have a gdb command script for setting up path substitution for Graal packages\n# This is useful only when adding Graal to the image for JIT compilation.\n# This is generated on first run, then only if the project file has changed (in case new Graal projects are created).\ndef ensureGraalPathSubstitutionInGdb():\n    gdbCmdsFile = join(mx.project('com.oracle.walnut.db.qshtest').dir, 'gdb-init-graal-src-path')\n    projectFile = join(mx.project('com.oracle.walnut.db.qshtest').suite.mxDir, \"projects\")\n    print \"Project file = \" + projectFile\n    if not exists(gdbCmdsFile) or os.stat(gdbCmdsFile).st_mtime < os.stat(projectFile).st_mtime:        \n        print \"(re) generating path substitutions GDB script at \" + gdbCmdsFile\n        gdbCmdsList = ['set auto-load python-scripts on\\n']\n        appendPathSubstitution(['test', 'ptx', 'hsail', 'sparc', 'gpu', 'jtt'], gdbCmdsList)      \n        with open(gdbCmdsFile,'w') as fout:\n            fout.writelines(gdbCmdsList)\n    return gdbCmdsFile   \n\n# TODO\n# allow using lldb\ndef qshdebug(exe, queryString):\n    ensureJDKSources()\n    if os.environ.has_key('GDB_BIN'):\n        gdb_binary = os.environ['GDB_BIN']\n    else:\n        gdb_binary = 'gdb'\n    \n    gdb_cmds = ensureGraalPathSubstitutionInGdb()\n    gdb_args = ['-x', gdb_cmds, '--args', exe, queryString]\n    \n    mx.run([gdb_binary] + gdb_args)\n\n\ndef qsh(args):\n    \"\"\"Run Walnut's query string handler\n    Takes a query string in the form servletname:cmd=command[&arg1=arg1value ...], e.g.\n           walnut:cmd=showcol&schema=scott&table=emp\n           Cases are ignored for schema, table and column name\n    Options:\n       -out=<file>         redirect output to <file>\n       -mdbhome=<path>     alternative MOCKUP_DB_HOME\n       -gdb                run under gdb\n    \"\"\"\n    platform = mx.get_os()\n    if platform != 'linux':\n        # only supported on linux for now\n        return\n    mockupDBHome = None\n    resultFileName = None\n    debugger = None\n    if len(args) > 0:\n        i = 0\n        while i < len(args):\n            if args[i].startswith('-out='):\n                resultFileName = args.pop(i)[5:]\n            elif args[i].startswith('-mdbhome='):\n                mockupDBHome = args.pop(i)[9:]\n            elif args[i] == '-gdb':\n                debugger = 'gdb'\n                args.pop(i)\n            else:\n                i += 1\n\n    if len(args) > 1:\n        mx.abort('qsh error: invalid number of arguments')\n    elif len(args) < 1:\n        mx.abort('qsh error: no query string argument provided')\n    \n    if debugger and resultFileName:\n        print \"qsh warning: ignore -out argument\"\n        resultFileName = None\n\n    if resultFileName:\n        resultFile = open(resultFileName, 'w')\n    else:\n        resultFile = None\n    queryString = args[0]\n    exe = join(mx.project('com.oracle.walnut.db.qshtest').dir, 'build', platform, 'qsh')\n    # set MOCKUP_DB_HOME for sub-processes -- where db files reside\n    if mockupDBHome:\n        os.environ['MOCKUP_DB_HOME'] = mockupDBHome\n    elif os.getenv('MOCKUP_DB_HOME') == None:\n        mockupdb()\n        os.environ['MOCKUP_DB_HOME'] = join(mx.project('com.oracle.walnut.db.qshtest').dir, 'mdb')\n\n    if debugger:\n        qshdebug(exe, queryString)\n    else:\n        mx.run([exe, queryString], out=resultFile)\n\ndef dbs(args):\n    \"\"\"Generate a Walnut DB servlet shared library\n          By default, generate the image to work with a mockup DB.\n          To generate an image that'll run with an Oracle 12c build from an ADE repo, use the -ade option.\n          The -ade option works only if you have environment variable setup, namely, ORACLE_HOME and ADE_VIEW_ROOT\n    Options:\n       -servlet=walnut   build a Walnut servlet\n       -path             path where to store the generated servlet shared library\n       -ade              install in $(ORACLE_HOME)/lib if in an ADE view\n       -asserts          generate image with asserts enabled\n       -g                build in *full* debug mode: set asserts on, disable inlining, allow source level debugging and set Graal's Debug enabled if -jit is specified\n       -o                build in optimized mode (-B:+Inline -B:-SourceLevelDebug)\n       -jit              build with Truffle compiler and immediate compilation policy (-B:+UseTruffleCompiler -B:+TruffleCompileImmediately)\n       -v                echo the image building command and all its arguments\n       -igv              enable dumping to files for the Ideal Graph Visualizer. Relevant only if -jit is specified\n    \"\"\"\n    servlet = 'walnut'\n    doAde = False\n    doPath = False\n    doJIT = False\n    doIGV = False;\n    doFullDebug = False\n    doOpt = False\n    doAssert = False\n    doEcho   = False\n    debugArgs = ['-da', '-dsa']\n    bflags = []\n    gflags = []\n    dflags = []\n    \n    if len(args) > 0:\n        i = 0\n        while i < len(args):\n            if args[i].startswith('-servlet='):\n                servlet = args.pop(i)[9:]\n            elif args[i] == '-ade':\n                args.pop(i)\n                doAde = True\n            elif args[i].startswith('-path='):\n                doPath = True\n                path = args[i][6:]\n                i += 1\n            elif args[i] == '-asserts':\n                doAssert = True                \n                args.pop(i)\n            elif args[i] == '-o':\n                doOpt = True\n                args.pop(i)\n            elif args[i] == '-jit':\n                doJIT = True\n                args.pop(i)\n            elif args[i] == '-igv':\n                doIGV = True\n                args.pop(i)\n            elif args[i] == '-g':\n                doFullDebug = True\n                doAssert = True\n                args.pop(i)\n            elif args[i] == '-v':\n                doEcho = True\n                args.pop(i)\n            elif args[i].startswith('-B:'):\n                bflags = bflags + [args[i]]\n                args.pop(i)\n            elif args[i].startswith('-G:'):\n                gflags = gflags + [args[i]]\n                args.pop(i)\n            elif args[i].startswith('-D'):\n                dflags = dflags + [args[i]]\n                args.pop(i)\n            else:\n                i += 1\n\n    if servlet not in ['walnut']:\n        mx.abort('dbs error: ' + servlet + ' not a known SVM servlet')\n    if doOpt and doFullDebug:\n        mx.abort('dbs error: -o and -g are incompatible')\n\n    if doOpt:\n        bflags = bflags + ['-B:+Inline', '-B:-SourceLevelDebug']\n    else:\n        bflags = bflags + ['-B:-Inline', '-B:+SourceLevelDebug']\n    \n    if doAssert:\n        debugArgs = ['-ea', '-esa']\n\n    debugGFlags = ['-G:+TraceTruffleCompilation', '-G:+TraceTruffleCompilationDetails', '-G:+TraceTruffleExpansion', '-G:+TraceTruffleInlining', '-G:+TraceTruffleCacheDetails']\n    if doJIT:\n        bflags = bflags + ['-B:+UseTruffleCompiler', '-B:+TruffleCompileImmediately']\n        if doIGV:\n            gflags = gflags + ['-G:+PrintIdealGraphFile', '-G:+PrintBackendCFG']\n            dflags = dflags + ['-Dgraal.debug.enable=true']\n\n    if doFullDebug:\n        dflags = dflags + ['-Dgraal.debug.enable=true']\n        if doJIT:\n            gflags = gflags + debugGFlags\n\n    project = 'com.oracle.walnut.db.servlet.' + servlet\n    servletClass = project + '.' + servlet.title() + 'Servlet'\n\n    bootImgArgs = ['-class=' + servletClass, '-kind=SHARED_LIBRARY', '-name=lib'+servlet, '-B:+AllowUndefinedDLLSymbols'] + bflags\n\n    classpath = mx.classpath('com.oracle.svm.hosted') + ':' + mx.classpath(project)\n    if doAde:\n       # check ADE environment first.\n       if os.getenv('ORACLE_HOME') == None:\n            print 'dbs: ORACLE_HOME not set.'\n            doAde = False\n       elif not os.path.isdir(os.getenv('ORACLE_HOME')):\n           print 'dbs: ORACLE_HOME not a valid directory'\n           doAde = False\n       if os.getenv('ADE_VIEW_ROOT') == None:\n           print 'dbs: ADE_VIEW_ROOT not set.'\n           doAde = False\n       elif not os.path.isdir(os.getenv('ORACLE_HOME')):\n           print 'dbs: ORACLE_HOME not a valid directory'\n           doAde = False\n       if not doAde:\n           mx.abort('dbs error: ADE project transaction cannot be found')\n\n    if doAde:\n        if not os.path.samefile(os.path.dirname(os.path.realpath(os.environ['ORACLE_HOME'])), os.path.realpath(os.getenv('ADE_VIEW_ROOT'))):\n            print 'dbs warning: ORACLE_HOME is outside of ADE VIEW'\n        if doPath:\n            print 'dbs warning: -path argument is ignored when -ade is set'\n        oralib_home = os.getenv('ORACLE_HOME') + '/lib'\n        print 'dbs: Will install Walnut image in ' + oralib_home\n        path = oralib_home\n    else:\n        # clean ADE / ORACLE DB related env variable\n        if (os.getenv('ADE_VIEW_ROOT')):\n        \tos.environ.pop('ADE_VIEW_ROOT')\n\t\tif (os.getenv('ORACLE_HOME')):\n\t\t\tos.environ.pop('ORACLE_HOME')\n        # set ALT_SOKI_DIR for sub-processes\n        mockup_dir = join(mx.project('com.oracle.walnut.db').dir, 'native')\n        os.environ['ALT_SOKI_DIR'] = mockup_dir\n        # add mockup DB project to the classpath\n        classpath = classpath + ':' + mx.classpath('com.oracle.walnut.db.mockup')\n        # if no path was specified, use default one\n        if doPath != True:\n            path = join(_graal_home, 'dbsbuild')\n\n    bootImgArgs.append('-path=' + path)\n\n    # elide all duplicate class path entries\n    cpis = classpath.split(':')\n    cpis = list(set(cpis))\n    classpath = ':'.join(cpis)\n\n    vmArgs, normalArgs = _extract_VM_args(args, useDoubleDash=True, defaultAllVMArgs=False)\n    \n    allArgs = ['-Xms2G', '-Xmx4G'] + debugArgs + dflags + vmArgs + gflags + ['-cp', classpath, 'com.oracle.svm.hosted.BootImageGenerator'] + bootImgArgs + normalArgs\n    # useful to debug image build\n    if doEcho:\n         for a in allArgs:\n             print a + ' '\n         print '\\n'\n    vm(allArgs)\n\n    libsvm = svm_native_dir() + '/libsvm.so'\n    if exists(path) and exists(libsvm):\n        print 'dbs: copying ' + libsvm + ' to ' + path\n        shutil.copy(libsvm, path)\n\n\ndacapo_benchmarks = ['avrora', 'batik', 'eclipse', 'luindex', 'lusearch', 'sunflow']\n\ndef svmdacapoall(args):\n    for bm in dacapo_benchmarks:\n        bmarg = ['-bm=' + bm]\n        svmdacapo(bmarg + args)\n\ndef svmdacapo(args):\n    \"\"\"Generate and run svm images for dacapo benchmarks\n    Options:\n       -bm=<benchmark> (available benchmarks: avrora, batik, eclipse, luindex, lusearch, sunflow)\n    \"\"\"\n    suite = 'dacapo'\n    project = ''\n\n    svmbench(args, suite, dacapo_benchmarks, project)\n\n\nspec_benchmarks = ['compiler.compiler', 'compiler.sunflow', 'compress', 'crypto.aes', 'crypto.rsa', 'crypto.signverify',\n                        'derby', 'mpegaudio',\n                        'scimark.fft', 'scimark.lu', 'scimark.monte_carlo', 'scimark.sor', 'scimark.sparse',\n                        'serial', 'xml.transform', 'xml.validation']\ndef svmspecall(args):\n    for bm in spec_benchmarks:\n        bmarg = ['-bm=' + bm]\n        svmspec(bmarg + args)\n\ndef svmspec(args):\n    \"\"\"Generate and run svm images for SPECjvm2008 benchmarks\n    Options:\n       -bm=<benchmark> (available benchmarks: compiler.compiler, compiler.sunflow, compress,\n                            crypto.aes, crypto.rsa, crypto.signverify, derby, mpegaudio,\n                            scimark.fft, scimark.lu, scimark.monte_carlo, scimark.sor,\n                            scimark.sparse, serial, xml.transform, xml.validation)\n    \"\"\"\n    suite = 'specjvm'\n    project = 'com.oracle.svm.bench.spec'\n\n    svmbench(args, suite, spec_benchmarks, project)\n\n\njolden_benchmarks = ['bh', 'bisort', 'em3d', 'health', 'mst', 'perimeter', 'power', 'treeadd', 'tsp', 'voronoi']\n\ndef svmjoldenall(args):\n    for bm in jolden_benchmarks:\n        bmarg = ['-bm=' + bm]\n        svmjolden(bmarg + args)\n\ndef svmjolden(args):\n    \"\"\"Generate and run svm images for jolden benchmarks\n    Options:\n       -bm=<benchmark> (available benchmarks: bh, bisort, em3d, health, mst, perimeter, power, treeadd, tsp, voronoi)\n    \"\"\"\n\n    suite = 'jolden'\n    project = 'com.oracle.svm.bench.jolden'\n    svmbench(args, suite, jolden_benchmarks, project)\n\n\n\nsvm_profile_filters = {}\n# dacapo\nsvm_profile_filters['avrora'] = 'avrora,org.dacapo,cck'\nsvm_profile_filters['batik'] = 'org.dacapo,org.apache.batik'\nsvm_profile_filters['eclipse'] = 'org.dacapo,org.eclipse'\nsvm_profile_filters['luindex'] = 'luindex,org.dacapo,org.apache.lucene'\nsvm_profile_filters['lusearch'] = 'lusearch,org.dacapo,org.apache.lucene'\nsvm_profile_filters['sunflow'] = 'org.sunflow,org.dacapo'\n\ndef svmbench(args, suite, benchmarks, project):\n    \"\"\"Generate and run svm images for available benchmarks: dacapo, specjvm,  jolden\n    \"\"\"\n\n    profile = False\n    benchmark = ''\n    path = 'svmbenchbuild'\n\n    if len(args) > 0:\n        i = 0\n        while i < len(args):\n            if args[i].startswith('-bm='):\n                benchmark = args.pop(i)[4:]\n            elif args[i].startswith('-profile'):\n                args.pop(i)\n                profile = True\n            else:\n                i = i + 1\n\n    if benchmark == '':\n        print 'Please specify a benchmark using -bm=<benchmark>. \\nAvailable benchmarks are: ' + ', '.join(benchmarks)\n        return\n\n    if benchmark not in benchmarks:\n        print benchmark + ' is not a known ' + suite + ' benchmark. \\nAvailable benchmarks are: ' + ', '.join(benchmarks)\n        return\n\n    if suite == 'dacapo':\n        project = 'org.dacapo.' + benchmark\n        clazz = 'org.dacapo.' + benchmark + '.' + benchmark.title() + 'Main'\n\n        dumpFilter = svm_profile_filters[benchmark]\n\n        # set the SVM_DACAPO_ROOT\n        mockup_dir = join(mx.project(project, True).dir, '')\n        os.environ['SVM_DACAPO_ROOT'] = mockup_dir\n\n    elif suite == 'specjvm':\n        # com.oracle.svm.bench.spec.compress.Main\n        clazz = project + '.benchmarks.' + benchmark + '.' + 'Main'\n\n        dumpFilter = 'spec'\n\n        specjvm_home_dir = join(mx.project(project, True).dir, '')\n        spec_javac_lib = mx.library(\"SPEC_JAVAC\", True).get_path(resolve=True)\n        # spec_javac_lib = mx.project('spec.javac').dir + '/bin'\n\n        specArgs = ['-Xbootclasspath/p:' + spec_javac_lib, '-Dspecjvm.home.dir=' + specjvm_home_dir, '--']\n        args = specArgs + args\n\n\n    elif suite == 'jolden':\n        clazz = project + '.benchmarks.' + benchmark + '.' + benchmark.title() + 'Main'\n        dumpFilter = 'jolden'\n\n    method = 'main'\n\n    if profile:\n        svmAnalysisOut = benchmark + '_svmAnalysisOut.json'\n        hotSpotOut = benchmark + '_hotSpotOut.json'\n        diffOut = benchmark + '_diffOut.json'\n        diffSummary = benchmark + '_diffSummary.txt'\n        svmUnsupported = benchmark + '_svmUnsupportedFeatures.txt'\n\n\n        svm_profile_args = ['-project=' + project, '-class=' + clazz, '-method=' + method,\n                            '-svmAnalysisOut=' + svmAnalysisOut, '-hotSpotOut=' + hotSpotOut,\n                            '-diffOut=' + diffOut, '-diffSummary=' + diffSummary,\n                            '-svmUnsupported=' + svmUnsupported,\n                            '-dumpFilter=' + dumpFilter]\n\n        svm_profile(svm_profile_args + args)\n    else:\n        print 'Generating image for ' + suite  + ':' + benchmark\n        imgArgs = ['-project=' + project, '-class=' + clazz, '-method=' + method, '-name=' + benchmark, '-path=' + path]\n        image(args + imgArgs)\n\n        print 'Executing the generated image for ' + suite  + ':' + benchmark\n        svmArgs = ['-image', benchmark, '-path', path]\n        svm(svmArgs)\n\n\ndef svm_sl_profile(args):\n\n    project = 'com.oracle.svm.truffle.sl'\n    clazz = 'com.oracle.svm.truffle.sl.TestSuiteMain'\n    method = 'main'\n\n    svmAnalysisOut = 'sl_svmAnalysisOut.json'\n    hotSpotOut = 'sl_hotSpotOut.json'\n    diffOut = 'sl_diffOut.json'\n    diffSummary = 'sl_diffSummary.txt'\n\n    svm_profile_args = ['-project=' + project, '-class=' + clazz, '-method=' + method,\n                        '-svmAnalysisOut=' + svmAnalysisOut, '-hotSpotOut=' + hotSpotOut,\n                        '-diffOut=' + diffOut, '-diffSummary=' + diffSummary,\n                        '-dumpFilter=com.oracle.truffle.sl']\n\n    svm_profile(svm_profile_args + args)\n\n\ndef svm_js_profile(args):\n    project = 'com.oracle.svm.truffle.js'\n    clazz = 'com.oracle.svm.truffle.js.Main'\n    method = 'main'\n\n    svmAnalysisOut = 'js_svmAnalysisOut.json'\n    hotSpotOut = 'js_hotSpotOut.json'\n    diffOut = 'js_diffOut.json'\n    diffSummary = 'js_diffSummary.txt'\n\n    svm_profile_args = ['-project=' + project, '-class=' + clazz, '-method=' + method,\n                        '-svmAnalysisOut=' + svmAnalysisOut, '-hotSpotOut=' + hotSpotOut,\n                        '-diffOut=' + diffOut, '-diffSummary=' + diffSummary,\n                        '-dumpFilter=com.oracle.truffle.js']\n\n    # -- simple.js\n    # args += ['--', 'simple.js']\n    # -- lib/js-benchmarks/harness.js -- lib/js-benchmarks/octane-richards.js\n    # args += ['--', 'lib/js-benchmarks/harness.js', '--', 'lib/js-benchmarks/octane-richards.js']\n    # run script with: mx svm_js_profile -phases=hs -- lib/js-benchmarks/harness.js -- lib/js-benchmarks/octane-deltablue.js\n    svm_profile(svm_profile_args + args)\n\ndef svm_js262_profile(args):\n    project = 'com.oracle.svm.truffle.js'\n    clazz = 'com.oracle.svm.truffle.js.MainTest262'\n    method = 'main'\n\n    svmAnalysisOut = 'js262_svmAnalysisOut.json'\n    hotSpotOut = 'js262_hotSpotOut.json'\n    diffOut = 'js262_diffOut.json'\n    diffSummary = 'js262_diffSummary.txt'\n\n    svm_profile_args = ['-project=' + project, '-class=' + clazz, '-method=' + method,\n                        '-svmAnalysisOut=' + svmAnalysisOut, '-hotSpotOut=' + hotSpotOut,\n                        '-diffOut=' + diffOut, '-diffSummary=' + diffSummary,\n                        '-dumpFilter=com.oracle.truffle.js']\n\n    # args += ['--', 'gate']\n    svm_profile(svm_profile_args + args)\n\n\ndef svm_test_profile(args):\n    project = 'com.oracle.svm.test.analysis'\n    clazz = 'com.oracle.svm.test.analysis.profiling.CodeExampleProfilingTest'\n    method = 'main'\n\n    svmAnalysisOut = 'test_profile_svmAnalysisOut.json'\n    hotSpotOut = 'test_profile_hotSpotOut.json'\n    diffOut = 'test_profile_diffOut.json'\n    diffSummary = 'test_profile_diffSummary.txt'\n\n    svm_profile_args = ['-project=' + project, '-class=' + clazz, '-method=' + method,\n                        '-svmAnalysisOut=' + svmAnalysisOut, '-hotSpotOut=' + hotSpotOut,\n                        '-diffOut=' + diffOut, '-diffSummary=' + diffSummary,\n                        '-dumpFilter=com.oracle.svm.test.analysis.profiling']\n\n    svm_profile(svm_profile_args + args)\n\ndef svm_profile(args):\n    project = ''\n    clazz = ''\n    method = ''\n    svmAnalysisOut = 'svmAnalysisOut.json'\n    hotSpotOut = 'hotSpotOut.json'\n    diffOut = 'diffOut.json'\n    diffSummary = 'diffSummary.txt'\n    svmUnsupported = 'svmUnsupported.txt'\n    phases = 'svm-hs-diff'\n    isolateAnalysis = False\n    dumpFilter = ''\n\n    debugArgs = ['-da', '-dsa']\n\n    i = 0\n    while i < len(args):\n        if args[i].startswith('-project='):\n            project = args.pop(i)[9:]\n        elif args[i].startswith('-class='):\n            clazz = args.pop(i)[7:]\n        elif args[i].startswith('-method='):\n            method = args.pop(i)[8:]\n        elif args[i].startswith('-svmAnalysisOut='):\n            svmAnalysisOut = args.pop(i)[16:]\n        elif args[i].startswith('-hotSpotOut='):\n            hotSpotOut = args.pop(i)[12:]\n        elif args[i].startswith('-diffOut='):\n            diffOut = args.pop(i)[9:]\n        elif args[i].startswith('-diffSummary='):\n            diffSummary = args.pop(i)[13:]\n        elif args[i].startswith('-svmUnsupported='):\n            svmUnsupported = args.pop(i)[16:]\n        elif args[i].startswith('-phases='):\n            phases = args.pop(i)[8:]\n        elif args[i].startswith('-dumpFilter='):\n            dumpFilter = args.pop(i)[12:]\n        elif args[i].startswith('-isolateAnalysis'):\n            args.pop(i)\n            isolateAnalysis = True\n        elif args[i] == '-asserts':\n            debugArgs = ['-ea', '-esa']\n            args.pop(i)\n        else:\n            i = i + 1\n\n    classpath = mx.classpath('com.oracle.svm.hosted')\n\n    # if a project is given the classpath of which needs to be added, elide all duplicate class path entries\n    if project != '':\n        cpis = (classpath + ':' + mx.classpath(project)).split(':')\n        cpis = list(set(cpis))\n        classpath = ':'.join(cpis)\n    classpath += ':' + mx.java().jdk + '/lib/tools.jar'\n\n    vmArgs, normalArgs = _extract_VM_args(args, useDoubleDash=True, defaultAllVMArgs=False)\n\n    if 'svm' in phases:\n        # place the normalArgs, i.e application args, at the end for now to avoid argument parsing issues in AnalysisProfiler\n        svmProfileArgs = ['-class', clazz] + ['-method', method] + ['-analysisOut', svmAnalysisOut]\n        svmProfileArgs += ['-svmUnsupported', svmUnsupported]\n        svmProfileArgs += ['-dumpFilter', dumpFilter]\n        if isolateAnalysis:\n            svmProfileArgs += ['-isolateAnalysis']\n        svmProfileArgs += normalArgs\n\n        vm(['-Xms2G', '-Xmx4G'] + debugArgs + vmArgs + ['-cp', classpath, 'com.oracle.svm.hosted.analysis.AnalysisProfiler'] + svmProfileArgs)\n\n    if 'hs' in phases:\n        hsVmArgs = vmArgs + ['-XX:TypeProfileWidth=10', '-XX:MethodProfileWidth=10']\n        # hsVmArgs = hsVmArgs + ['-XX:CompileThreshold=10']\n        # hsVmArgs = hsVmArgs + ['-XX:InterpreterProfilePercentage=0']\n        # hsVmArgs = hsVmArgs + ['-XX:ProfileMaturityPercentage=0']\n        # hsVmArgs = hsVmArgs + ['-XX:+PrintMethodData']\n        # hsVmArgs = hsVmArgs + ['-XX:+PrintCompilation']\n\n\n        hsVmArgs = hsVmArgs + ['-XX:Tier0ProfilingStartPercentage=0']\n        hsVmArgs = hsVmArgs + ['-XX:-Inline']\n        # hsVmArgs = hsVmArgs + ['-XX:+TypeProfileCasts']\n        # disable tiered compilation, so that the only profiling is in the interpreter, no profile update in the client compiler\n        hsVmArgs = hsVmArgs + ['-XX:-TieredCompilation']\n        hsVmArgs = hsVmArgs + ['-XX:+ProfileInterpreter']\n\n        hsVmArgs = hsVmArgs + ['-XX:CompileThreshold=100000']\n        hsVmArgs = hsVmArgs + ['-XX:InterpreterProfilePercentage=0']\n\n        hsVmArgs += ['-XX:+DumpProfilingToFile', '-XX:DumpProfilingFile=' + hotSpotOut, '-XX:DumpProfilingFilter=' + dumpFilter]\n        hsVmArgs += ['-Dtruffle.ForceInterpreter=true']\n\n        print 'Writing HotSpot runtime profiling to ' + hotSpotOut\n\n        vm(['-Xms2G', '-Xmx4G'] + debugArgs + hsVmArgs + ['-cp', classpath, clazz] + normalArgs, \"server\", \"product\")\n\n    if 'diff' in phases:\n        diffProfileArgs = ['-analysisIn', svmAnalysisOut] +  ['-runtimeIn', hotSpotOut] + ['-diffOut', diffOut] + ['-diffSummary', diffSummary]\n        diffProfileArgs += normalArgs\n\n        vm(['-Xms2G', '-Xmx4G'] + debugArgs + vmArgs + ['-cp', classpath, 'com.oracle.svm.hosted.analysis.DiffProfiler'] + diffProfileArgs)\n\ndef svm_profile_report(args):\n\n\n    report_file = 'profiling_report.md'\n    with open(report_file, 'w+') as fout:\n\n        def summary_to_report(title, bm_summary_file):\n            with open(bm_summary_file) as fin:\n                fout.write(title + '\\n')\n                fout.write('------------------\\n')\n                line = fin.readline()\n                while 'Errors' not in line:\n                    fout.write(line)\n                    line = fin.readline()\n\n        def profile(suite, suite_prof, bms):\n            bmarg = ['-profile']\n            for bm in bms:\n                print 'Profiling ' + suite +':' + bm\n                bmarg += ['-bm=' + bm]\n                suite_prof(bmarg + args)\n                summary_to_report(suite +':' + bm, bm + '_diffSummary.txt')\n\n        # run dacapo benchmarks\n        working_dacapo_bms = ['avrora', 'luindex', 'lusearch']\n        profile('dacapo', svmdacapo, working_dacapo_bms)\n\n        # run spec benchmarks\n        # working_spec_bms = ['compress', 'mpegaudio', 'scimark.fft', 'scimark.lu',\n        #                     'scimark.monte_carlo', 'scimark.sor', 'scimark.sparse', 'serial']\n        working_spec_bms = ['compress', 'mpegaudio', 'scimark.sor']\n\n        profile('spec', svmspec, working_spec_bms)\n\n        # run js octane-deltablue\n        print 'Profiling js:deltablue'\n        js_args = args + ['--', 'lib/js-benchmarks/harness.js', '--', 'lib/js-benchmarks/octane-deltablue.js']\n        svm_js_profile(js_args)\n        summary_to_report('js:deltablue', 'js_diffSummary.txt')\n\n        # run js 262\n        print 'Profiling js:262'\n        svm_js262_profile(args)\n        summary_to_report('js:262', 'js262_diffSummary.txt')\n\n        # run jolden benchmarks\n        # working_jolden_benchmarks = ['bh', 'bisort', 'em3d', 'health', 'perimeter', 'power', 'treeadd', 'tsp', 'voronoi']\n        working_jolden_benchmarks = ['bh', 'voronoi']\n        profile('jolden', svmjolden, working_jolden_benchmarks)\n\n\n\n    print \"Profiling report wrote to \" + report_file\n\n\ndef svm_native_dir():\n    return join(mx.project('com.oracle.svm.native', True).dir, 'generated', mx.get_os())\n\ndef svm(args):\n    \"\"\"Launches the Substrate VM.\n    Options: -image <imagename.vm> launch the given image.\n             -default Assumes an image built with -kind=DEFAULT instead of -kind=EXECUTABLE\n    All other options are passed to SVM.\"\"\"\n\n    kind = \"EXECUTABLE\"\n    imagename = 'substrate.vm'\n    path = svm_native_dir()\n\n    filtered_args = []\n    while len(args) > 0:\n        arg = args.pop(0)\n        if arg == '-image':\n            imagename = args.pop(0)\n        elif arg == '-default':\n            kind = \"DEFAULT\"\n        elif arg == '-path':\n            path = args.pop(0)\n        else:\n            filtered_args.append(arg)\n\n    if kind == \"DEFAULT\":\n        mx.run([join(path, 'svm'), imagename] + filtered_args)\n    else:\n        mx.run([join(path, imagename)] + filtered_args)\n\ndef svmdebug(args):\n    \"\"\"Launches the Substrate VM in gdb.\n    Options:\n       -mi to launch gdb in GDB/MI mode\n       -nemiver (Linux only!) to launch Nemiver\n                To enable loading of Python extensions, make sure you have a .gdbinit in $HOME that contains the following line:\n                set auto-load safe-path <path/to/svm/working/directory>\n       -affinic (Mac OS X only!) to launch Affinic\"\"\"\n\n    ensureJDKSources()\n    ddir = mx.project('com.oracle.svm.debug', True).dir\n    sdir = mx.suites()[0].dir\n    ensureGdbInit(ddir, sdir)\n    ensureSvmGdbPython(ddir)\n\n    svm_cmd = [join(svm_native_dir(), 'svm'), 'substrate.vm']\n\n    if len(args) == 1 and args[0] == '-nemiver':\n        mx.run(['nemiver'] + svm_cmd)\n    else:\n        if os.environ.has_key('GDB_BIN'):\n            gdb_binary = os.environ['GDB_BIN']\n        else:\n            gdb_binary = 'gdb'\n\n        if len(args) == 1 and args[0] == '-affinic':\n            affinic_binary = os.environ['AFFINIC_BIN']\n            gdb_args = ['-iex \"set auto-load safe-path ' + sdir + '\"', '--args']\n            mx.run([affinic_binary, '--debugger', gdb_binary] + gdb_args + svm_cmd)\n        else:\n            if len(args) == 1 and args[0] == '-mi':\n                mi = '--interpreter=mi'\n            else:\n                mi = ''\n\n            gdb_args = ['-iex', 'set auto-load safe-path ' + sdir, '--args']\n            mx.run([gdb_binary, mi] + gdb_args + [join(svm_native_dir(), 'svm'), 'substrate.vm'])\n\ndef svmtest(args):\n    \"\"\"Builds and runs the Substrate VM unit tests (which include the Graal JTT tests).\n    Pass test name fragments on the command line as filters.\n    Filters starting with '!' exclude matching tests. Filters are applied in the specified order.\n    For example to test all svm_test tests but no svm_test_graal tests except BasicCompileTest:\n           mx svmtest svm_test '!svm_test_graal' BasicCompileTest\n    In combination with -B:+Benchmark it is possible to specify how many times a test is executed (for\n    more accurate time measurement). The repeat count can be added to a filter with a colon, e.g.\n           mx svmtest -B:+Benchmark svm_jtt_micro_Fibonacci_run7:100000\n\n    Options:\n       -lib to build the test boot images as shared libraries\n       -exe to build the test boot images as executables (default)\n       -default to build the test boot images in the old format\n       -dump <prefix> to dump the names of ok/unsupported/failed tests in separate files with the given prefix\n       -tests <file> to use the test names given in <file> as filter. This option can be given more than once. Additional test names can be specified.\n       -B:<option> Specify an option for the boot image generator. To get a list of -B options run 'mx image -help'.\"\"\"\n\n    vmArgs, normalArgs = _extract_VM_args(args, useDoubleDash=True, defaultAllVMArgs=False)\n    vm(['-Xss10m', '-Xms2G', '-Xmx4G', '-ea', '-esa'] + vmArgs + ['-cp', mx.classpath('com.oracle.svm.test'), 'com.oracle.svm.test.runner.UnitTests', '-g'] + normalArgs)\n\ndef svmdebugtest(args):\n    \"\"\"builds and runs the Substrate VM debugging tests\"\"\"\n\n    ensureJDKSources()\n    ddir = mx.project('com.oracle.svm.debug', True).dir\n    ensureGdbInit(ddir, svm_native_dir())\n    ensureSvmGdbPython(ddir)\n\n    vm(['-ea', '-esa', '-cp', mx.classpath('com.oracle.svm.debug.test'), 'com.oracle.svm.debug.test.runner.TestRunner'] + args)\n\n\n# ensure the JDK sources are unzipped in the project JDK directory\ndef ensureJDKSources():\n    if not exists(jdkhome()):\n        mx.log('Project JDK not found - cannot create JDK source directory')\n        return\n    srcdir = jdkhome() + '/jre/src'\n    if not exists(srcdir):\n        srczip = mx.java().jdk + '/src.zip'\n        if not exists(srczip):\n            mx.log('JDK sources missing - debugger cannot display source code for JDK classes')\n            return\n        mx.log('Creating and populating JDK source directory ...')\n        os.mkdir(srcdir)\n        subprocess.call(['unzip', '-q', srczip, '-d', srcdir])\n\n# ensure there is a .gdbinit file in the expected place\ndef ensureGdbInit(debugProjectDir, targetDir):\n    sourceFile = join(debugProjectDir, 'gdb-init')\n    targetFile = join(targetDir, '.gdbinit')\n    with open(sourceFile) as f:\n        content = f.read()\n    content = content.replace('${svm_debug_test}', debugProjectDir)\n    mx.update_file(targetFile, content)\n\ndef svmLibName():\n    if mx.get_os() == 'darwin':\n        return 'libsvm.dylib'\n    else:\n        return 'libsvm.so'\n\n# ensure the SVM/gdb Python support code is in place next to the svm library\ndef ensureSvmGdbPython(debugProjectDir):\n    sourceFile = join(debugProjectDir, 'libsvm-gdb.py.rename')\n    targetFile = join(svm_native_dir(), svmLibName() + '-gdb.py')\n    with open(sourceFile) as f:\n        content = f.read()\n    mx.update_file(targetFile, content)\n\ndef mx_init(suite):\n    commands = {\n        'build': [build, ''],\n        'buildjmh': [buildjmh, '[-options]'],\n        'buildvars': [buildvars, ''],\n        'buildvms': [buildvms, '[-options]'],\n        'c1visualizer' : [c1visualizer, ''],\n        'checkheaders': [checkheaders, ''],\n        'clean': [clean, ''],\n        'findbugs': [findbugs, ''],\n        'generateZshCompletion' : [generateZshCompletion, ''],\n        'hsdis': [hsdis, '[att]'],\n        'hcfdis': [hcfdis, ''],\n        'igv' : [igv, ''],\n        'jdkhome': [print_jdkhome, ''],\n        'jmh': [jmh, '[VM options] [filters|JMH-args-as-json...]'],\n        'dacapo': [dacapo, '[VM options] benchmarks...|\"all\" [DaCapo options]'],\n        'scaladacapo': [scaladacapo, '[VM options] benchmarks...|\"all\" [Scala DaCapo options]'],\n        'specjvm2008': [specjvm2008, '[VM options] benchmarks...|\"all\" [SPECjvm2008 options]'],\n        'specjbb2013': [specjbb2013, '[VM options] [-- [SPECjbb2013 options]]'],\n        'specjbb2005': [specjbb2005, '[VM options] [-- [SPECjbb2005 options]]'],\n        'gate' : [gate, '[-options]'],\n        'bench' : [bench, '[-resultfile file] [all(default)|dacapo|specjvm2008|bootstrap]'],\n        'unittest' : [unittest, '[unittest options] [--] [VM options] [filters...]', _unittestHelpSuffix],\n        'makejmhdeps' : [makejmhdeps, ''],\n        'shortunittest' : [shortunittest, '[unittest options] [--] [VM options] [filters...]', _unittestHelpSuffix],\n        'jacocoreport' : [jacocoreport, '[output directory]'],\n        'site' : [site, '[-options]'],\n        'vm': [vm, '[-options] class [args...]'],\n        'vmg': [vmg, '[-options] class [args...]'],\n        'vmfg': [vmfg, '[-options] class [args...]'],\n        'deoptalot' : [deoptalot, '[n]'],\n        'longtests' : [longtests, ''],\n        'sl' : [sl, '[SL args|@VM options]'],\n        'jol' : [jol, ''],\n        # enterprise-truffle\n        'processorjars' : [processorjars, ''],\n        'js' : [js, '[JS args|@VM options]'],\n        'jsmozilla' : [jsmozilla, '[JS Mozilla args|@VM options]'],\n        'jsjar' : [jsjar, ''],\n        'avatarjsjar' : [avatarjsjar, ''],\n        'jsrepl' : [jsrepl, '[JS args|@VM options]'],\n        'ruby' : [ruby, '[Ruby args|@VM options]'],\n        'rubyrepl' : [rubyrepl, '[Ruby args|@VM options]'],\n        'jruby' : [jruby, '[JRuby args|@VM options]'],\n        'nodetruffle' : [nodeTruffle, '[Node.Truffle args|@VM options]'],\n        'testnodetruffle' : [testNodeTruffle, '[Node.Truffle args|@VM options]'],\n        'px' : [parallelJS, '[Px.Truffle args|@VM options]'],\n        'pxtest': [testParallelJS, ''],\n        'avatarjs' : [avatarJS, '[Avatar.Truffle args|@VM options]'],\n        'avatarjsorig' : [avatarJSOrig, '[Avatar.js args|@VM options]'],\n        'avatarjsbench' : [avatarJSBench, '[Avatar.js args|@VM option]'],\n        'pullavatarjs': [getAvatarJS, ''],\n        'pullavatarjsorig': [getAvatarJSOrig, ''],\n        'testavatarjs': [testAvatarJS, ''],\n        'trufflebench': [trufflebench, ''],\n        'jsbench': [trufflebench, ''],\n        'test262': [test262, ''],\n        'testnashorn': [testnashorn, ''],\n        'pulljsbenchmarks': [pulljsbenchmarks, ''],\n        'pullavatarjsbench': [pullavatarjsbench, ''],\n        'spidermonkey': [spidermonkey, ''],\n        'v8': [v8, ''],\n        'nashorn': [jsnashorn, ''],\n        'jsc': [javascriptcore, ''],\n        # Substrate VM\n        'image' : [image, ''],\n        'svm' : [svm, ''],\n        'svmdebug' : [svmdebug, '[-options]'],\n        'svmtest' : [svmtest, ''],\n        'svmdebugtest' : [svmdebugtest, '[test case classes ...]'],\n        'svmdacapo' : [svmdacapo, ''],\n        'svmdacapoall' : [svmdacapoall, ''],\n        'svmspec' : [svmspec, ''],\n        'svmspecall' : [svmspecall, ''],\n        'svmjolden' : [svmjolden, ''],\n        'svmjoldenall' : [svmjoldenall, ''],\n        'svm_profile' : [svm_profile, ''],\n        'svm_js_profile' : [svm_js_profile, ''],\n        'svm_js262_profile' : [svm_js262_profile, ''],\n        'svm_test_profile' : [svm_test_profile, ''],\n        'svm_sl_profile' : [svm_sl_profile, ''],\n        'svm_profile_report' : [svm_profile_report, ''],\n        # Walnut\n        'dbs' : [dbs, ''],\n        'qsh' : [qsh, ''],\n        'qshtest' : [qshtest, ''],\n        'mockupdb': [mockupdb, '']\n\n    }\n\n    mx.add_argument('--jacoco', help='instruments com.oracle.* classes using JaCoCo', default='off', choices=['off', 'on', 'append'])\n    mx.add_argument('--vmcwd', dest='vm_cwd', help='current directory will be changed to <path> before the VM is executed', default=None, metavar='<path>')\n    mx.add_argument('--installed-jdks', help='the base directory in which the JDKs cloned from $JAVA_HOME exist. ' +\n                    'The VM selected by --vm and --vmbuild options is under this directory (i.e., ' +\n                    join('<path>', '<jdk-version>', '<vmbuild>', 'jre', 'lib', '<vm>', mx.add_lib_prefix(mx.add_lib_suffix('jvm'))) + ')', default=None, metavar='<path>')\n\n    if _vmSourcesAvailable:\n        mx.add_argument('--vm', action='store', dest='vm', choices=_vmChoices.keys(), help='the VM type to build/run')\n        mx.add_argument('--vmbuild', action='store', dest='vmbuild', choices=_vmbuildChoices, help='the VM build to build/run (default: ' + _vmbuildChoices[0] + ')')\n        mx.add_argument('--ecl', action='store_true', dest='make_eclipse_launch', help='create launch configuration for running VM execution(s) in Eclipse')\n        mx.add_argument('--vmprefix', action='store', dest='vm_prefix', help='prefix for running the VM (e.g. \"/usr/bin/gdb --args\")', metavar='<prefix>')\n        mx.add_argument('--gdb', action='store_const', const='/usr/bin/gdb --args', dest='vm_prefix', help='alias for --vmprefix \"/usr/bin/gdb --args\"')\n\n        commands.update({\n            'export': [export, '[-options] [zipfile]'],\n        })\n\n    mx.update_commands(suite, commands)\n\ndef mx_post_parse_cmd_line(opts):  #\n    # TODO _minVersion check could probably be part of a Suite in mx?\n    if mx.java().version < _minVersion:\n        mx.abort('Requires Java version ' + str(_minVersion) + ' or greater, got version ' + str(mx.java().version))\n\n    if _vmSourcesAvailable:\n        if hasattr(opts, 'vm') and opts.vm is not None:\n            global _vm\n            _vm = opts.vm\n        if hasattr(opts, 'vmbuild') and opts.vmbuild is not None:\n            global _vmbuild\n            _vmbuild = opts.vmbuild\n        global _make_eclipse_launch\n        _make_eclipse_launch = getattr(opts, 'make_eclipse_launch', False)\n    global _jacoco\n    _jacoco = opts.jacoco\n    global _vm_cwd\n    _vm_cwd = opts.vm_cwd\n    global _installed_jdks\n    _installed_jdks = opts.installed_jdks\n    global _vm_prefix\n    _vm_prefix = opts.vm_prefix\n\n    mx.distribution('GRAAL').add_update_listener(_installGraalJarInJdks)\n    mx.distribution('GRAAL_LOADER').add_update_listener(_installGraalJarInJdks)\n","markers":{"markers":{"1":{"id":1,"range":[[915,0],[915,0]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":745,"autoscroll":true,"goalBufferRange":null,"preserveFolds":true},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/zwei/Workspace/oracle/fastr-svm-home/graal/mx/mx_graal.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"ee2ff76bb8f28695540b8e5dd27ff3d7c03dbdaa","deserializer":"TextBuffer"},{"text":"#!/usr/bin/env python2.7\n#\n# ----------------------------------------------------------------------------------------------------\n#\n# Copyright (c) 2007, 2012, Oracle and/or its affiliates. All rights reserved.\n# DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n#\n# This code is free software; you can redistribute it and/or modify it\n# under the terms of the GNU General Public License version 2 only, as\n# published by the Free Software Foundation.\n#\n# This code is distributed in the hope that it will be useful, but WITHOUT\n# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n# version 2 for more details (a copy is included in the LICENSE file that\n# accompanied this code).\n#\n# You should have received a copy of the GNU General Public License version\n# 2 along with this work; if not, write to the Free Software Foundation,\n# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n#\n# Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n# or visit www.oracle.com if you need additional information or have any\n# questions.\n#\n# ----------------------------------------------------------------------------------------------------\n#\nr\"\"\"\nmx is a command line tool for managing the development of Java code organized as suites of projects.\n\nVersion 1.x supports a single suite of projects.\n\nFull documentation can be found at https://wiki.openjdk.java.net/display/Graal/The+mx+Tool\n\"\"\"\n\nimport sys, os, errno, time, subprocess, shlex, types, StringIO, zipfile, signal, xml.sax.saxutils, tempfile, fnmatch\nimport multiprocessing\nimport textwrap\nimport socket\nimport tarfile\nimport hashlib\nimport xml.parsers.expat\nimport shutil, re, xml.dom.minidom\nimport pipes\nimport difflib\nfrom collections import Callable\nfrom threading import Thread\nfrom argparse import ArgumentParser, REMAINDER\nfrom os.path import join, basename, dirname, exists, getmtime, isabs, expandvars, isdir, isfile\n\n_projects = dict()\n_libs = dict()\n_jreLibs = dict()\n_dists = dict()\n_suites = dict()\n_annotationProcessors = None\n_primary_suite_path = None\n_primary_suite = None\n_opts = None\n_java_homes = None\n_warn = False\n\n\"\"\"\nA distribution is a jar or zip file containing the output from one or more Java projects.\n\"\"\"\nclass Distribution:\n    def __init__(self, suite, name, path, sourcesPath, deps, mainClass, excludedDependencies, distDependencies):\n        self.suite = suite\n        self.name = name\n        self.path = path.replace('/', os.sep)\n        self.path = _make_absolute(self.path, suite.dir)\n        self.sourcesPath = _make_absolute(sourcesPath.replace('/', os.sep), suite.dir) if sourcesPath else None\n        self.deps = deps\n        self.update_listeners = set()\n        self.mainClass = mainClass\n        self.excludedDependencies = excludedDependencies\n        self.distDependencies = distDependencies\n\n    def sorted_deps(self, includeLibs=False):\n        try:\n            excl = [dependency(d) for d in self.excludedDependencies]\n        except SystemExit as e:\n            abort('invalid excluded dependency for {} distribution: {}'.format(self.name, e))\n        return [d for d in sorted_deps(self.deps, includeLibs=includeLibs) if d not in excl]\n\n    def __str__(self):\n        return self.name\n\n    def add_update_listener(self, listener):\n        self.update_listeners.add(listener)\n\n    def make_archive(self):\n        # are sources combined into main archive?\n        unified = self.path == self.sourcesPath\n\n        with Archiver(self.path) as arc, Archiver(None if unified else self.sourcesPath) as srcArcRaw:\n            srcArc = arc if unified else srcArcRaw\n            services = {}\n            def overwriteCheck(zf, arcname, source):\n                if not hasattr(zf, '_provenance'):\n                    zf._provenance = {}\n                existingSource = zf._provenance.get(arcname, None)\n                isOverwrite = False\n                if existingSource and existingSource != source:\n                    if arcname[-1] != os.path.sep:\n                        logv('warning: ' + self.path + ': avoid overwrite of ' + arcname + '\\n  new: ' + source + '\\n  old: ' + existingSource)\n                    isOverwrite = True\n                zf._provenance[arcname] = source\n                return isOverwrite\n\n            if self.mainClass:\n                manifest = \"Manifest-Version: 1.0\\nMain-Class: %s\\n\\n\" % (self.mainClass)\n                if not overwriteCheck(arc.zf, \"META-INF/MANIFEST.MF\", \"project files\"):\n                    arc.zf.writestr(\"META-INF/MANIFEST.MF\", manifest)\n\n            for dep in self.sorted_deps(includeLibs=True):\n                if dep.isLibrary():\n                    l = dep\n                    # merge library jar into distribution jar\n                    logv('[' + self.path + ': adding library ' + l.name + ']')\n                    lpath = l.get_path(resolve=True)\n                    libSourcePath = l.get_source_path(resolve=True)\n                    if lpath:\n                        with zipfile.ZipFile(lpath, 'r') as lp:\n                            for arcname in lp.namelist():\n                                if arcname.startswith('META-INF/services/') and not arcname == 'META-INF/services/':\n                                    service = arcname[len('META-INF/services/'):]\n                                    assert '/' not in service\n                                    services.setdefault(service, []).extend(lp.read(arcname).splitlines())\n                                else:\n                                    if not overwriteCheck(arc.zf, arcname, lpath + '!' + arcname):\n                                        arc.zf.writestr(arcname, lp.read(arcname))\n                    if srcArc.zf and libSourcePath:\n                        with zipfile.ZipFile(libSourcePath, 'r') as lp:\n                            for arcname in lp.namelist():\n                                if not overwriteCheck(srcArc.zf, arcname, lpath + '!' + arcname):\n                                    srcArc.zf.writestr(arcname, lp.read(arcname))\n                elif dep.isProject():\n                    p = dep\n\n                    isCoveredByDependecy = False\n                    for d in self.distDependencies:\n                        if p in _dists[d].sorted_deps():\n                            logv(\"Excluding {0} from {1} because it's provided by the dependency {2}\".format(p.name, self.path, d))\n                            isCoveredByDependecy = True\n                            break\n\n                    if isCoveredByDependecy:\n                        continue\n\n                    # skip a  Java project if its Java compliance level is \"higher\" than the configured JDK\n                    jdk = java(p.javaCompliance)\n                    assert jdk\n\n                    logv('[' + self.path + ': adding project ' + p.name + ']')\n                    outputDir = p.output_dir()\n                    for root, _, files in os.walk(outputDir):\n                        relpath = root[len(outputDir) + 1:]\n                        if relpath == join('META-INF', 'services'):\n                            for service in files:\n                                with open(join(root, service), 'r') as fp:\n                                    services.setdefault(service, []).extend([provider.strip() for provider in fp.readlines()])\n                        elif relpath == join('META-INF', 'providers'):\n                            for provider in files:\n                                with open(join(root, provider), 'r') as fp:\n                                    for service in fp:\n                                        services.setdefault(service.strip(), []).append(provider)\n                        else:\n                            for f in files:\n                                arcname = join(relpath, f).replace(os.sep, '/')\n                                if not overwriteCheck(arc.zf, arcname, join(root, f)):\n                                    arc.zf.write(join(root, f), arcname)\n                    if srcArc.zf:\n                        sourceDirs = p.source_dirs()\n                        if p.source_gen_dir():\n                            sourceDirs.append(p.source_gen_dir())\n                        for srcDir in sourceDirs:\n                            for root, _, files in os.walk(srcDir):\n                                relpath = root[len(srcDir) + 1:]\n                                for f in files:\n                                    if f.endswith('.java'):\n                                        arcname = join(relpath, f).replace(os.sep, '/')\n                                        if not overwriteCheck(srcArc.zf, arcname, join(root, f)):\n                                            srcArc.zf.write(join(root, f), arcname)\n\n            for service, providers in services.iteritems():\n                arcname = 'META-INF/services/' + service\n                arc.zf.writestr(arcname, '\\n'.join(providers))\n\n        self.notify_updated()\n\n\n    def notify_updated(self):\n        for l in self.update_listeners:\n            l(self)\n\n\"\"\"\nA dependency is a library or project specified in a suite.\n\"\"\"\nclass Dependency:\n    def __init__(self, suite, name):\n        self.name = name\n        self.suite = suite\n\n    def __str__(self):\n        return self.name\n\n    def __eq__(self, other):\n        return self.name == other.name\n\n    def __ne__(self, other):\n        return self.name != other.name\n\n    def __hash__(self):\n        return hash(self.name)\n\n    def isLibrary(self):\n        return isinstance(self, Library)\n\n    def isJreLibrary(self):\n        return isinstance(self, JreLibrary)\n\n    def isProject(self):\n        return isinstance(self, Project)\n\nclass Project(Dependency):\n    def __init__(self, suite, name, srcDirs, deps, javaCompliance, workingSets, d):\n        Dependency.__init__(self, suite, name)\n        self.srcDirs = srcDirs\n        self.deps = deps\n        self.checkstyleProj = name\n        self.javaCompliance = JavaCompliance(javaCompliance) if javaCompliance is not None else None\n        self.native = False\n        self.workingSets = workingSets\n        self.dir = d\n\n        # Verify that a JDK exists for this project if its compliance level is\n        # less than the compliance level of the default JDK\n        jdk = java(self.javaCompliance)\n        if jdk is None and self.javaCompliance < java().javaCompliance:\n            abort('Cannot find ' + str(self.javaCompliance) + ' JDK required by ' + name + '. ' +\n                  'Specify it with --extra-java-homes option or EXTRA_JAVA_HOMES environment variable.')\n\n        # Create directories for projects that don't yet exist\n        if not exists(d):\n            os.mkdir(d)\n        for s in self.source_dirs():\n            if not exists(s):\n                os.mkdir(s)\n\n    def all_deps(self, deps, includeLibs, includeSelf=True, includeJreLibs=False, includeAnnotationProcessors=False):\n        \"\"\"\n        Add the transitive set of dependencies for this project, including\n        libraries if 'includeLibs' is true, to the 'deps' list.\n        \"\"\"\n        childDeps = list(self.deps)\n        if includeAnnotationProcessors and len(self.annotation_processors()) > 0:\n            childDeps = self.annotation_processors() + childDeps\n        if self in deps:\n            return deps\n        for name in childDeps:\n            assert name != self.name\n            dep = dependency(name)\n            if not dep in deps and (dep.isProject or (dep.isLibrary() and includeLibs) or (dep.isJreLibrary() and includeJreLibs)):\n                dep.all_deps(deps, includeLibs=includeLibs, includeJreLibs=includeJreLibs, includeAnnotationProcessors=includeAnnotationProcessors)\n        if not self in deps and includeSelf:\n            deps.append(self)\n        return deps\n\n    def _compute_max_dep_distances(self, name, distances, dist):\n        currentDist = distances.get(name)\n        if currentDist is None or currentDist < dist:\n            distances[name] = dist\n            p = project(name, False)\n            if p is not None:\n                for dep in p.deps:\n                    self._compute_max_dep_distances(dep, distances, dist + 1)\n\n    def canonical_deps(self):\n        \"\"\"\n        Get the dependencies of this project that are not recursive (i.e. cannot be reached\n        via other dependencies).\n        \"\"\"\n        distances = dict()\n        result = set()\n        self._compute_max_dep_distances(self.name, distances, 0)\n        for n, d in distances.iteritems():\n            assert d > 0 or n == self.name\n            if d == 1:\n                result.add(n)\n\n        if len(result) == len(self.deps) and frozenset(self.deps) == result:\n            return self.deps\n        return result\n\n    def max_depth(self):\n        \"\"\"\n        Get the maximum canonical distance between this project and its most distant dependency.\n        \"\"\"\n        distances = dict()\n        self._compute_max_dep_distances(self.name, distances, 0)\n        return max(distances.values())\n\n    def source_dirs(self):\n        \"\"\"\n        Get the directories in which the sources of this project are found.\n        \"\"\"\n        return [join(self.dir, s) for s in self.srcDirs]\n\n    def source_gen_dir(self):\n        \"\"\"\n        Get the directory in which source files generated by the annotation processor are found/placed.\n        \"\"\"\n        if self.native:\n            return None\n        return join(self.dir, 'src_gen')\n\n    def output_dir(self):\n        \"\"\"\n        Get the directory in which the class files of this project are found/placed.\n        \"\"\"\n        if self.native:\n            return None\n        return join(self.dir, 'bin')\n\n    def jasmin_output_dir(self):\n        \"\"\"\n        Get the directory in which the Jasmin assembled class files of this project are found/placed.\n        \"\"\"\n        if self.native:\n            return None\n        return join(self.dir, 'jasmin_classes')\n\n    def append_to_classpath(self, cp, resolve):\n        if not self.native:\n            cp.append(self.output_dir())\n\n    def find_classes_with_matching_source_line(self, pkgRoot, function, includeInnerClasses=False):\n        \"\"\"\n        Scan the sources of this project for Java source files containing a line for which\n        'function' returns true. A map from class name to source file path for each existing class\n        corresponding to a matched source file is returned.\n        \"\"\"\n        result = dict()\n        pkgDecl = re.compile(r\"^package\\s+([a-zA-Z_][\\w\\.]*)\\s*;$\")\n        for srcDir in self.source_dirs():\n            outputDir = self.output_dir()\n            for root, _, files in os.walk(srcDir):\n                for name in files:\n                    if name.endswith('.java') and name != 'package-info.java':\n                        matchFound = False\n                        source = join(root, name)\n                        with open(source) as f:\n                            pkg = None\n                            for line in f:\n                                if line.startswith(\"package \"):\n                                    match = pkgDecl.match(line)\n                                    if match:\n                                        pkg = match.group(1)\n                                if function(line.strip()):\n                                    matchFound = True\n                                if pkg and matchFound:\n                                    break\n\n                        if matchFound:\n                            simpleClassName = name[:-len('.java')]\n                            assert pkg is not None\n                            if pkgRoot is None or pkg.startswith(pkgRoot):\n                                pkgOutputDir = join(outputDir, pkg.replace('.', os.path.sep))\n                                if exists(pkgOutputDir):\n                                    for e in os.listdir(pkgOutputDir):\n                                        if includeInnerClasses:\n                                            if e.endswith('.class') and (e.startswith(simpleClassName) or e.startswith(simpleClassName + '$')):\n                                                className = pkg + '.' + e[:-len('.class')]\n                                                result[className] = source\n                                        elif e == simpleClassName + '.class':\n                                            className = pkg + '.' + simpleClassName\n                                            result[className] = source\n        return result\n\n    def _init_packages_and_imports(self):\n        if not hasattr(self, '_defined_java_packages'):\n            packages = set()\n            extendedPackages = set()\n            depPackages = set()\n            for d in self.all_deps([], includeLibs=False, includeSelf=False):\n                depPackages.update(d.defined_java_packages())\n            imports = set()\n            importRe = re.compile(r'import\\s+(?:static\\s+)?([^;]+);')\n            for sourceDir in self.source_dirs():\n                for root, _, files in os.walk(sourceDir):\n                    javaSources = [name for name in files if name.endswith('.java')]\n                    if len(javaSources) != 0:\n                        pkg = root[len(sourceDir) + 1:].replace(os.sep, '.')\n                        if not pkg in depPackages:\n                            packages.add(pkg)\n                        else:\n                            # A project extends a package already defined by one of it dependencies\n                            extendedPackages.add(pkg)\n                            imports.add(pkg)\n\n                        for n in javaSources:\n                            with open(join(root, n)) as fp:\n                                content = fp.read()\n                                imports.update(importRe.findall(content))\n            self._defined_java_packages = frozenset(packages)\n            self._extended_java_packages = frozenset(extendedPackages)\n\n            importedPackages = set()\n            for imp in imports:\n                name = imp\n                while not name in depPackages and len(name) > 0:\n                    lastDot = name.rfind('.')\n                    if lastDot == -1:\n                        name = None\n                        break\n                    name = name[0:lastDot]\n                if name is not None:\n                    importedPackages.add(name)\n            self._imported_java_packages = frozenset(importedPackages)\n\n    def defined_java_packages(self):\n        \"\"\"Get the immutable set of Java packages defined by the Java sources of this project\"\"\"\n        self._init_packages_and_imports()\n        return self._defined_java_packages\n\n    def extended_java_packages(self):\n        \"\"\"Get the immutable set of Java packages extended by the Java sources of this project\"\"\"\n        self._init_packages_and_imports()\n        return self._extended_java_packages\n\n    def imported_java_packages(self):\n        \"\"\"Get the immutable set of Java packages defined by other Java projects that are\n           imported by the Java sources of this project.\"\"\"\n        self._init_packages_and_imports()\n        return self._imported_java_packages\n\n    def annotation_processors(self):\n        if not hasattr(self, '_annotationProcessors'):\n            ap = set()\n            if hasattr(self, '_declaredAnnotationProcessors'):\n                ap = set(self._declaredAnnotationProcessors)\n\n            # find dependencies that auto-inject themselves as annotation processors to all dependents\n            allDeps = self.all_deps([], includeLibs=False, includeSelf=False, includeAnnotationProcessors=False)\n            for p in allDeps:\n                if hasattr(p, 'annotationProcessorForDependents') and p.annotationProcessorForDependents.lower() == 'true':\n                    ap.add(p.name)\n            self._annotationProcessors = list(ap)\n        return self._annotationProcessors\n\n    def update_current_annotation_processors_file(self):\n        aps = self.annotation_processors()\n        outOfDate = False\n        currentApsFile = join(self.suite.mxDir, 'currentAnnotationProcessors', self.name)\n        currentApsFileExists = exists(currentApsFile)\n        if currentApsFileExists:\n            with open(currentApsFile) as fp:\n                currentAps = [l.strip() for l in fp.readlines()]\n                if currentAps != aps:\n                    outOfDate = True\n        if outOfDate or not currentApsFileExists:\n            if not exists(dirname(currentApsFile)):\n                os.mkdir(dirname(currentApsFile))\n            with open(currentApsFile, 'w') as fp:\n                for ap in aps:\n                    print >> fp, ap\n        return outOfDate\n\n    def make_archive(self, path=None):\n        outputDir = self.output_dir()\n        if not path:\n            path = join(self.dir, self.name + '.jar')\n        with Archiver(path) as arc:\n            for root, _, files in os.walk(outputDir):\n                for f in files:\n                    relpath = root[len(outputDir) + 1:]\n                    arcname = join(relpath, f).replace(os.sep, '/')\n                    arc.zf.write(join(root, f), arcname)\n        return path\n\ndef _make_absolute(path, prefix):\n    \"\"\"\n    Makes 'path' absolute if it isn't already by prefixing 'prefix'\n    \"\"\"\n    if not isabs(path):\n        return join(prefix, path)\n    return path\n\ndef _download_file_with_sha1(name, path, urls, sha1, sha1path, resolve, mustExist, sources=False):\n    def _download_lib():\n        print 'Downloading ' + (\"Sources \" if sources else \"\") + name + ' from ' + str(urls)\n        download(path, urls)\n\n    def _sha1Cached():\n        with open(sha1path, 'r') as f:\n            return f.read()[0:40]\n\n    def _writeSha1Cached():\n        with open(sha1path, 'w') as f:\n            f.write(_sha1OfFile())\n\n    def _sha1OfFile():\n        with open(path, 'rb') as f:\n            d = hashlib.sha1()\n            while True:\n                buf = f.read(4096)\n                if not buf:\n                    break\n                d.update(buf)\n            return d.hexdigest()\n\n    if resolve and mustExist and not exists(path):\n        assert not len(urls) == 0, 'cannot find required library ' + name + ' ' + path\n        _download_lib()\n\n    if sha1 and not exists(sha1path):\n        _writeSha1Cached()\n\n    if sha1 and sha1 != _sha1Cached():\n        _download_lib()\n        if sha1 != _sha1OfFile():\n            abort(\"SHA1 does not match for \" + name + \". Broken download? SHA1 not updated in projects file?\")\n        _writeSha1Cached()\n\n    return path\n\nclass BaseLibrary(Dependency):\n    def __init__(self, suite, name, optional):\n        Dependency.__init__(self, suite, name)\n        self.optional = optional\n\n    def __ne__(self, other):\n        result = self.__eq__(other)\n        if result is NotImplemented:\n            return result\n        return not result\n\n\"\"\"\nA library that will be provided by the JDK but may be absent.\nAny project or normal library that depends on a missing library\nwill be removed from the global project and library dictionaries\n(i.e., _projects and _libs).\n\nThis mechanism exists primarily to be able to support code\nthat may use functionality in one JDK (e.g., Oracle JDK)\nthat is not present in another JDK (e.g., OpenJDK). A\nmotivating example is the Java Flight Recorder library\nfound in the Oracle JDK. \n\"\"\"\nclass JreLibrary(BaseLibrary):\n    def __init__(self, suite, name, jar, optional):\n        BaseLibrary.__init__(self, suite, name, optional)\n        self.jar = jar\n\n    def __eq__(self, other):\n        if isinstance(other, JreLibrary):\n            return self.jar == other.jar\n        else:\n            return NotImplemented\n\n    def is_present_in_jdk(self, jdk):\n        for e in jdk.bootclasspath().split(os.pathsep):\n            if basename(e) == self.jar:\n                return True\n        for d in jdk.extdirs().split(os.pathsep):\n            if len(d) and self.jar in os.listdir(d):\n                return True\n        for d in jdk.endorseddirs().split(os.pathsep):\n            if len(d) and self.jar in os.listdir(d):\n                return True\n        return False\n\n    def all_deps(self, deps, includeLibs, includeSelf=True, includeJreLibs=False, includeAnnotationProcessors=False):\n        \"\"\"\n        Add the transitive set of dependencies for this JRE library to the 'deps' list.\n        \"\"\"\n        if includeJreLibs and includeSelf and not self in deps:\n            deps.append(self)\n        return deps\n\nclass Library(BaseLibrary):\n    def __init__(self, suite, name, path, optional, urls, sha1, sourcePath, sourceUrls, sourceSha1, deps):\n        BaseLibrary.__init__(self, suite, name, optional)\n        self.path = path.replace('/', os.sep)\n        self.urls = urls\n        self.sha1 = sha1\n        self.sourcePath = sourcePath\n        self.sourceUrls = sourceUrls\n        self.sourceSha1 = sourceSha1\n        self.deps = deps\n        abspath = _make_absolute(self.path, self.suite.dir)\n        if not optional and not exists(abspath):\n            if not len(urls):\n                abort('Non-optional library {} must either exist at {} or specify one or more URLs from which it can be retrieved'.format(name, abspath))\n        for url in urls:\n            if url.endswith('/') != self.path.endswith(os.sep):\n                abort('Path for dependency directory must have a URL ending with \"/\": path=' + self.path + ' url=' + url)\n\n    def __eq__(self, other):\n        if isinstance(other, Library):\n            if len(self.urls) == 0:\n                return self.path == other.path\n            else:\n                return self.urls == other.urls\n        else:\n            return NotImplemented\n\n    def get_path(self, resolve):\n        path = _make_absolute(self.path, self.suite.dir)\n        sha1path = path + '.sha1'\n\n        includedInJDK = getattr(self, 'includedInJDK', None)\n        if includedInJDK and java().javaCompliance >= JavaCompliance(includedInJDK):\n            return None\n\n        return _download_file_with_sha1(self.name, path, self.urls, self.sha1, sha1path, resolve, not self.optional)\n\n    def get_source_path(self, resolve):\n        if self.sourcePath is None:\n            return None\n        path = _make_absolute(self.sourcePath, self.suite.dir)\n        sha1path = path + '.sha1'\n\n        return _download_file_with_sha1(self.name, path, self.sourceUrls, self.sourceSha1, sha1path, resolve, len(self.sourceUrls) != 0, sources=True)\n\n    def append_to_classpath(self, cp, resolve):\n        path = self.get_path(resolve)\n        if path and (exists(path) or not resolve):\n            cp.append(path)\n\n    def all_deps(self, deps, includeLibs, includeSelf=True, includeJreLibs=False, includeAnnotationProcessors=False):\n        \"\"\"\n        Add the transitive set of dependencies for this library to the 'deps' list.\n        \"\"\"\n        if not includeLibs:\n            return deps\n        childDeps = list(self.deps)\n        if self in deps:\n            return deps\n        for name in childDeps:\n            assert name != self.name\n            dep = library(name)\n            if not dep in deps:\n                dep.all_deps(deps, includeLibs=includeLibs, includeJreLibs=includeJreLibs, includeAnnotationProcessors=includeAnnotationProcessors)\n        if not self in deps and includeSelf:\n            deps.append(self)\n        return deps\n\nclass HgConfig:\n    \"\"\"\n    Encapsulates access to Mercurial (hg)\n    \"\"\"\n    def __init__(self):\n        self.missing = 'no hg executable found'\n        self.has_hg = None\n\n    def check(self, abortOnFail=True):\n        if self.has_hg is None:\n            try:\n                subprocess.check_output(['hg'])\n                self.has_hg = True\n            except OSError:\n                self.has_hg = False\n                warn(self.missing)\n\n        if not self.has_hg:\n            if abortOnFail:\n                abort(self.missing)\n            else:\n                warn(self.missing)\n\n    def tip(self, sDir, abortOnError=True):\n        try:\n            return subprocess.check_output(['hg', 'tip', '-R', sDir, '--template', '{node}'])\n        except OSError:\n            warn(self.missing)\n        except subprocess.CalledProcessError:\n            if abortOnError:\n                abort('failed to get tip revision id')\n            else:\n                return None\n\n    def isDirty(self, sDir, abortOnError=True):\n        try:\n            return len(subprocess.check_output(['hg', 'status', '-R', sDir])) > 0\n        except OSError:\n            warn(self.missing)\n        except subprocess.CalledProcessError:\n            if abortOnError:\n                abort('failed to get status')\n            else:\n                return None\n\nclass Suite:\n    def __init__(self, mxDir, primary, load=True):\n        self.dir = dirname(mxDir)\n        self.mxDir = mxDir\n        self.projects = []\n        self.libs = []\n        self.jreLibs = []\n        self.dists = []\n        self.commands = None\n        self.primary = primary\n        self.requiredMxVersion = None\n        self.name = _suitename(mxDir)  # validated in _load_projects\n        if load:\n            # just check that there are no imports\n            self._load_imports()\n            self._load_env()\n            self._load_commands()\n        _suites[self.name] = self\n\n    def __str__(self):\n        return self.name\n\n    def _load_projects(self):\n        libsMap = dict()\n        jreLibsMap = dict()\n        projsMap = dict()\n        distsMap = dict()\n        projectsFile = join(self.mxDir, 'projects')\n        if not exists(projectsFile):\n            return\n\n        with open(projectsFile) as f:\n            prefix = ''\n            lineNum = 0\n\n            def error(message):\n                abort(projectsFile + ':' + str(lineNum) + ': ' + message)\n\n            for line in f:\n                lineNum = lineNum + 1\n                line = line.strip()\n                if line.endswith('\\\\'):\n                    prefix = prefix + line[:-1]\n                    continue\n                if len(prefix) != 0:\n                    line = prefix + line\n                    prefix = ''\n                if len(line) != 0 and line[0] != '#':\n                    if '=' not in line:\n                        error('non-comment line does not contain an \"=\" character')\n                    key, value = line.split('=', 1)\n\n                    parts = key.split('@')\n\n                    if len(parts) == 1:\n                        if parts[0] == 'suite':\n                            if self.name != value:\n                                error('suite name in project file does not match ' + _suitename(self.mxDir))\n                        elif parts[0] == 'mxversion':\n                            try:\n                                self.requiredMxVersion = VersionSpec(value)\n                            except AssertionError as ae:\n                                error('Exception while parsing \"mxversion\" in project file: ' + str(ae))\n                        else:\n                            error('Single part property must be \"suite\": ' + key)\n\n                        continue\n                    if len(parts) != 3:\n                        error('Property name does not have 3 parts separated by \"@\": ' + key)\n                    kind, name, attr = parts\n                    if kind == 'project':\n                        m = projsMap\n                    elif kind == 'library':\n                        m = libsMap\n                    elif kind == 'jrelibrary':\n                        m = jreLibsMap\n                    elif kind == 'distribution':\n                        m = distsMap\n                    else:\n                        error('Property name does not start with \"project@\", \"library@\" or \"distribution@\": ' + key)\n\n                    attrs = m.get(name)\n                    if attrs is None:\n                        attrs = dict()\n                        m[name] = attrs\n                    value = expandvars_in_property(value)\n                    attrs[attr] = value\n\n        def pop_list(attrs, name):\n            v = attrs.pop(name, None)\n            if v is None or len(v.strip()) == 0:\n                return []\n            return [n.strip() for n in v.split(',')]\n\n        for name, attrs in projsMap.iteritems():\n            srcDirs = pop_list(attrs, 'sourceDirs')\n            deps = pop_list(attrs, 'dependencies')\n            ap = pop_list(attrs, 'annotationProcessors')\n            # deps += ap\n            javaCompliance = attrs.pop('javaCompliance', None)\n            subDir = attrs.pop('subDir', None)\n            if subDir is None:\n                d = join(self.dir, name)\n            else:\n                d = join(self.dir, subDir, name)\n            workingSets = attrs.pop('workingSets', None)\n            p = Project(self, name, srcDirs, deps, javaCompliance, workingSets, d)\n            p.checkstyleProj = attrs.pop('checkstyle', name)\n            p.native = attrs.pop('native', '') == 'true'\n            if not p.native and p.javaCompliance is None:\n                error('javaCompliance property required for non-native project ' + name)\n            if len(ap) > 0:\n                p._declaredAnnotationProcessors = ap\n            p.__dict__.update(attrs)\n            self.projects.append(p)\n\n        for name, attrs in jreLibsMap.iteritems():\n            jar = attrs.pop('jar')\n            # JRE libraries are optional by default\n            optional = attrs.pop('optional', 'true') != 'false'\n            l = JreLibrary(self, name, jar, optional)\n            self.jreLibs.append(l)\n\n        for name, attrs in libsMap.iteritems():\n            path = attrs.pop('path')\n            urls = pop_list(attrs, 'urls')\n            sha1 = attrs.pop('sha1', None)\n            sourcePath = attrs.pop('sourcePath', None)\n            sourceUrls = pop_list(attrs, 'sourceUrls')\n            sourceSha1 = attrs.pop('sourceSha1', None)\n            deps = pop_list(attrs, 'dependencies')\n            # Add support optional libraries once we have a good use case\n            optional = False\n            l = Library(self, name, path, optional, urls, sha1, sourcePath, sourceUrls, sourceSha1, deps)\n            l.__dict__.update(attrs)\n            self.libs.append(l)\n\n        for name, attrs in distsMap.iteritems():\n            path = attrs.pop('path')\n            sourcesPath = attrs.pop('sourcesPath', None)\n            deps = pop_list(attrs, 'dependencies')\n            mainClass = attrs.pop('mainClass', None)\n            exclDeps = pop_list(attrs, 'exclude')\n            distDeps = pop_list(attrs, 'distDependencies')\n            d = Distribution(self, name, path, sourcesPath, deps, mainClass, exclDeps, distDeps)\n            d.__dict__.update(attrs)\n            self.dists.append(d)\n\n        if self.name is None:\n            abort('Missing \"suite=<name>\" in ' + projectsFile)\n\n    def _commands_name(self):\n        return 'mx_' + self.name.replace('-', '_')\n\n    def _find_commands(self, name):\n        commandsPath = join(self.mxDir, name + '.py')\n        if exists(commandsPath):\n            return name\n        else:\n            return None\n\n    def _load_commands(self):\n        commandsName = self._find_commands(self._commands_name())\n        if commandsName is None:\n            # backwards compatibility\n            commandsName = self._find_commands('commands')\n        if commandsName is not None:\n            if commandsName in sys.modules:\n                abort(commandsName + '.py in suite ' + self.name + ' duplicates ' + sys.modules[commandsName].__file__)\n            # temporarily extend the Python path\n            sys.path.insert(0, self.mxDir)\n            mod = __import__(commandsName)\n\n            self.commands = sys.modules.pop(commandsName)\n            sys.modules[commandsName] = self.commands\n\n            # revert the Python path\n            del sys.path[0]\n\n            if not hasattr(mod, 'mx_init'):\n                abort(commandsName + '.py in suite ' + self.name + ' must define an mx_init(suite) function')\n            if hasattr(mod, 'mx_post_parse_cmd_line'):\n                self.mx_post_parse_cmd_line = mod.mx_post_parse_cmd_line\n\n            mod.mx_init(self)\n            self.commands = mod\n\n    def _load_imports(self):\n        if exists(join(self.mxDir, 'imports')):\n            abort('multiple suites are not supported in this version of mx')\n\n    def _load_env(self):\n        e = join(self.mxDir, 'env')\n        if exists(e):\n            with open(e) as f:\n                lineNum = 0\n                for line in f:\n                    lineNum = lineNum + 1\n                    line = line.strip()\n                    if len(line) != 0 and line[0] != '#':\n                        if not '=' in line:\n                            abort(e + ':' + str(lineNum) + ': line does not match pattern \"key=value\"')\n                        key, value = line.split('=', 1)\n                        os.environ[key.strip()] = expandvars_in_property(value.strip())\n\n    def _post_init(self, opts):\n        self._load_projects()\n        if self.requiredMxVersion is None:\n            warn(\"This suite does not express any required mx version. Consider adding 'mxversion=<version>' to your projects file.\")\n        elif self.requiredMxVersion > version:\n            abort(\"This suite requires mx version \" + str(self.requiredMxVersion) + \" while your current mx version is \" + str(version) + \". Please update mx.\")\n        # set the global data structures, checking for conflicts unless _check_global_structures is False\n        for p in self.projects:\n            existing = _projects.get(p.name)\n            if existing is not None:\n                abort('cannot override project  ' + p.name + ' in ' + p.dir + \" with project of the same name in  \" + existing.dir)\n            if not p.name in _opts.ignored_projects:\n                _projects[p.name] = p\n        for l in self.libs:\n            existing = _libs.get(l.name)\n            # Check that suites that define same library are consistent\n            if existing is not None and existing != l:\n                abort('inconsistent library redefinition of ' + l.name + ' in ' + existing.suite.dir + ' and ' + l.suite.dir)\n            _libs[l.name] = l\n        for l in self.jreLibs:\n            existing = _jreLibs.get(l.name)\n            # Check that suites that define same library are consistent\n            if existing is not None and existing != l:\n                abort('inconsistent JRE library redefinition of ' + l.name + ' in ' + existing.suite.dir + ' and ' + l.suite.dir)\n            _jreLibs[l.name] = l\n        for d in self.dists:\n            existing = _dists.get(d.name)\n            if existing is not None:\n                # allow redefinition, so use path from existing\n                # abort('cannot redefine distribution  ' + d.name)\n                warn('distribution ' + d.name + ' redefined')\n                d.path = existing.path\n            _dists[d.name] = d\n\n        # Remove projects and libraries that (recursively) depend on an optional library\n        # whose artifact does not exist or on a JRE library that is not present in the\n        # JDK for a project. Also remove projects whose Java compliance requirement\n        # cannot be satisfied by the configured JDKs.\n        #\n        # Removed projects and libraries are also removed from\n        # distributions in they are listed as dependencies.\n        for d in sorted_deps(includeLibs=True):\n            if d.isLibrary():\n                if d.optional:\n                    try:\n                        d.optional = False\n                        path = d.get_path(resolve=True)\n                    except SystemExit:\n                        path = None\n                    finally:\n                        d.optional = True\n                    if not path:\n                        logv('[omitting optional library {} as {} does not exist]'.format(d, d.path))\n                        del _libs[d.name]\n                        self.libs.remove(d)\n            elif d.isProject():\n                if java(d.javaCompliance) is None:\n                    logv('[omitting project {} as Java compliance {} cannot be satisfied by configured JDKs]'.format(d, d.javaCompliance))\n                    del _projects[d.name]\n                    self.projects.remove(d)\n                else:\n                    for name in list(d.deps):\n                        jreLib = _jreLibs.get(name)\n                        if jreLib:\n                            if not jreLib.is_present_in_jdk(java(d.javaCompliance)):\n                                if jreLib.optional:\n                                    logv('[omitting project {} as dependency {} is missing]'.format(d, name))\n                                    del _projects[d.name]\n                                    self.projects.remove(d)\n                                else:\n                                    abort('JRE library {} required by {} not found'.format(jreLib, d))\n                        elif not dependency(name, fatalIfMissing=False):\n                            logv('[omitting project {} as dependency {} is missing]'.format(d, name))\n                            del _projects[d.name]\n                            self.projects.remove(d)\n        for dist in _dists.values():\n            for name in list(dist.deps):\n                if not dependency(name, fatalIfMissing=False):\n                    logv('[omitting {} from distribution {}]'.format(name, dist))\n                    dist.deps.remove(name)\n\n        if hasattr(self, 'mx_post_parse_cmd_line'):\n            self.mx_post_parse_cmd_line(opts)\n\nclass XMLElement(xml.dom.minidom.Element):\n    def writexml(self, writer, indent=\"\", addindent=\"\", newl=\"\"):\n        writer.write(indent + \"<\" + self.tagName)\n\n        attrs = self._get_attributes()\n        a_names = attrs.keys()\n        a_names.sort()\n\n        for a_name in a_names:\n            writer.write(\" %s=\\\"\" % a_name)\n            xml.dom.minidom._write_data(writer, attrs[a_name].value)\n            writer.write(\"\\\"\")\n        if self.childNodes:\n            if not self.ownerDocument.padTextNodeWithoutSiblings and len(self.childNodes) == 1 and isinstance(self.childNodes[0], xml.dom.minidom.Text):\n                # if the only child of an Element node is a Text node, then the\n                # text is printed without any indentation or new line padding\n                writer.write(\">\")\n                self.childNodes[0].writexml(writer)\n                writer.write(\"</%s>%s\" % (self.tagName, newl))\n            else:\n                writer.write(\">%s\" % (newl))\n                for node in self.childNodes:\n                    node.writexml(writer, indent + addindent, addindent, newl)\n                writer.write(\"%s</%s>%s\" % (indent, self.tagName, newl))\n        else:\n            writer.write(\"/>%s\" % (newl))\n\nclass XMLDoc(xml.dom.minidom.Document):\n\n    def __init__(self):\n        xml.dom.minidom.Document.__init__(self)\n        self.current = self\n        self.padTextNodeWithoutSiblings = False\n\n    def createElement(self, tagName):\n        # overwritten to create XMLElement\n        e = XMLElement(tagName)\n        e.ownerDocument = self\n        return e\n\n    def comment(self, txt):\n        self.current.appendChild(self.createComment(txt))\n\n    def open(self, tag, attributes=None, data=None):\n        if attributes is None:\n            attributes = {}\n        element = self.createElement(tag)\n        for key, value in attributes.items():\n            element.setAttribute(key, value)\n        self.current.appendChild(element)\n        self.current = element\n        if data is not None:\n            element.appendChild(self.createTextNode(data))\n        return self\n\n    def close(self, tag):\n        assert self.current != self\n        assert tag == self.current.tagName, str(tag) + ' != ' + self.current.tagName\n        self.current = self.current.parentNode\n        return self\n\n    def element(self, tag, attributes=None, data=None):\n        if attributes is None:\n            attributes = {}\n        return self.open(tag, attributes, data).close(tag)\n\n    def xml(self, indent='', newl='', escape=False, standalone=None):\n        assert self.current == self\n        result = self.toprettyxml(indent, newl, encoding=\"UTF-8\")\n        if escape:\n            entities = {'\"':  \"&quot;\", \"'\":  \"&apos;\", '\\n': '&#10;'}\n            result = xml.sax.saxutils.escape(result, entities)\n        if standalone is not None:\n            result = result.replace('encoding=\"UTF-8\"?>', 'encoding=\"UTF-8\" standalone=\"' + str(standalone) + '\"?>')\n        return result\n\ndef get_os():\n    \"\"\"\n    Get a canonical form of sys.platform.\n    \"\"\"\n    if sys.platform.startswith('darwin'):\n        return 'darwin'\n    elif sys.platform.startswith('linux'):\n        return 'linux'\n    elif sys.platform.startswith('sunos'):\n        return 'solaris'\n    elif sys.platform.startswith('win32') or sys.platform.startswith('cygwin'):\n        return 'windows'\n    else:\n        abort('Unknown operating system ' + sys.platform)\n\ndef _loadSuite(mxDir, primary=False):\n    \"\"\"\n    Load a suite from 'mxDir'.\n    \"\"\"\n    for s in _suites.itervalues():\n        if s.mxDir == mxDir:\n            return s\n    # create the new suite\n    s = Suite(mxDir, primary)\n    return s\n\ndef suites(opt_limit_to_suite=False):\n    \"\"\"\n    Get the list of all loaded suites.\n    \"\"\"\n    return _suites.values()\n\ndef suite(name, fatalIfMissing=True):\n    \"\"\"\n    Get the suite for a given name.\n    \"\"\"\n    s = _suites.get(name)\n    if s is None and fatalIfMissing:\n        abort('suite named ' + name + ' not found')\n    return s\n\n\ndef projects_from_names(projectNames):\n    \"\"\"\n    Get the list of projects corresponding to projectNames; all projects if None\n    \"\"\"\n    if projectNames is None:\n        return projects()\n    else:\n        return [project(name) for name in projectNames]\n\ndef projects(opt_limit_to_suite=False):\n    \"\"\"\n    Get the list of all loaded projects limited by --suite option if opt_limit_to_suite == True\n    \"\"\"\n\n    if opt_limit_to_suite:\n        return _projects_opt_limit_to_suites(_projects.values())\n    else:\n        return _projects.values()\n\ndef projects_opt_limit_to_suites():\n    \"\"\"\n    Get the list of all loaded projects optionally limited by --suite option\n    \"\"\"\n    return projects(True)\n\ndef _projects_opt_limit_to_suites(projects):\n    return projects\n\ndef annotation_processors():\n    \"\"\"\n    Get the list of all loaded projects that define an annotation processor.\n    \"\"\"\n    global _annotationProcessors\n    if _annotationProcessors is None:\n        aps = set()\n        for p in projects():\n            for ap in p.annotation_processors():\n                if project(ap, False):\n                    aps.add(ap)\n        _annotationProcessors = list(aps)\n    return _annotationProcessors\n\ndef distribution(name, fatalIfMissing=True):\n    \"\"\"\n    Get the distribution for a given name. This will abort if the named distribution does\n    not exist and 'fatalIfMissing' is true.\n    \"\"\"\n    d = _dists.get(name)\n    if d is None and fatalIfMissing:\n        abort('distribution named ' + name + ' not found')\n    return d\n\ndef dependency(name, fatalIfMissing=True):\n    \"\"\"\n    Get the project or library for a given name. This will abort if a project  or library does\n    not exist for 'name' and 'fatalIfMissing' is true.\n    \"\"\"\n    d = _projects.get(name)\n    if d is None:\n        d = _libs.get(name)\n        if d is None:\n            d = _jreLibs.get(name)\n    if d is None and fatalIfMissing:\n        if name in _opts.ignored_projects:\n            abort('project named ' + name + ' is ignored')\n        abort('project or library named ' + name + ' not found')\n    return d\n\ndef project(name, fatalIfMissing=True):\n    \"\"\"\n    Get the project for a given name. This will abort if the named project does\n    not exist and 'fatalIfMissing' is true.\n    \"\"\"\n    p = _projects.get(name)\n    if p is None and fatalIfMissing:\n        if name in _opts.ignored_projects:\n            abort('project named ' + name + ' is ignored')\n        abort('project named ' + name + ' not found')\n    return p\n\ndef library(name, fatalIfMissing=True):\n    \"\"\"\n    Gets the library for a given name. This will abort if the named library does\n    not exist and 'fatalIfMissing' is true.\n    \"\"\"\n    l = _libs.get(name)\n    if l is None and fatalIfMissing:\n        if _projects.get(name):\n            abort(name + ' is a project, not a library')\n        abort('library named ' + name + ' not found')\n    return l\n\ndef _as_classpath(deps, resolve):\n    cp = []\n    if _opts.cp_prefix is not None:\n        cp = [_opts.cp_prefix]\n    for d in deps:\n        d.append_to_classpath(cp, resolve)\n    if _opts.cp_suffix is not None:\n        cp += [_opts.cp_suffix]\n    return os.pathsep.join(cp)\n\ndef classpath(names=None, resolve=True, includeSelf=True, includeBootClasspath=False):\n    \"\"\"\n    Get the class path for a list of given dependencies and distributions, resolving each entry in the\n    path (e.g. downloading a missing library) if 'resolve' is true.\n    \"\"\"\n    if names is None:\n        deps = sorted_deps(includeLibs=True)\n        dists = list(_dists.values())\n    else:\n        deps = []\n        dists = []\n        if isinstance(names, types.StringTypes):\n            names = [names]\n        for n in names:\n            dep = dependency(n, fatalIfMissing=False)\n            if dep:\n                dep.all_deps(deps, True, includeSelf)\n            else:\n                dist = distribution(n)\n                if not dist:\n                    abort('project, library or distribution named ' + n + ' not found')\n                dists.append(dist)\n\n    if len(dists):\n        distsDeps = set()\n        for d in dists:\n            distsDeps.update(d.sorted_deps())\n\n        # remove deps covered by a dist that will be on the class path\n        deps = [d for d in deps if d not in distsDeps]\n\n    result = _as_classpath(deps, resolve)\n\n    # prepend distributions\n    if len(dists):\n        distsCp = os.pathsep.join(dist.path for dist in dists)\n        if len(result):\n            result = distsCp + os.pathsep + result\n        else:\n            result = distsCp\n\n    if includeBootClasspath:\n        result = os.pathsep.join([java().bootclasspath(), result])\n    return result\n\ndef classpath_walk(names=None, resolve=True, includeSelf=True, includeBootClasspath=False):\n    \"\"\"\n    Walks the resources available in a given classpath, yielding a tuple for each resource\n    where the first member of the tuple is a directory path or ZipFile object for a\n    classpath entry and the second member is the qualified path of the resource relative\n    to the classpath entry.\n    \"\"\"\n    cp = classpath(names, resolve, includeSelf, includeBootClasspath)\n    for entry in cp.split(os.pathsep):\n        if not exists(entry):\n            continue\n        if isdir(entry):\n            for root, dirs, files in os.walk(entry):\n                for d in dirs:\n                    entryPath = join(root[len(entry) + 1:], d)\n                    yield entry, entryPath\n                for f in files:\n                    entryPath = join(root[len(entry) + 1:], f)\n                    yield entry, entryPath\n        elif entry.endswith('.jar') or entry.endswith('.zip'):\n            with zipfile.ZipFile(entry, 'r') as zf:\n                for zi in zf.infolist():\n                    entryPath = zi.filename\n                    yield zf, entryPath\n\ndef sorted_deps(projectNames=None, includeLibs=False, includeJreLibs=False, includeAnnotationProcessors=False):\n    \"\"\"\n    Gets projects and libraries sorted such that dependencies\n    are before the projects that depend on them. Unless 'includeLibs' is\n    true, libraries are omitted from the result.\n    \"\"\"\n    projects = projects_from_names(projectNames)\n\n    return sorted_project_deps(projects, includeLibs=includeLibs, includeJreLibs=includeJreLibs, includeAnnotationProcessors=includeAnnotationProcessors)\n\ndef sorted_project_deps(projects, includeLibs=False, includeJreLibs=False, includeAnnotationProcessors=False):\n    deps = []\n    for p in projects:\n        p.all_deps(deps, includeLibs=includeLibs, includeJreLibs=includeJreLibs, includeAnnotationProcessors=includeAnnotationProcessors)\n    return deps\n\ndef _handle_missing_java_home():\n    if not sys.stdout.isatty():\n        abort('Could not find bootstrap JDK. Use --java-home option or ensure JAVA_HOME environment variable is set.')\n\n    candidateJdks = []\n    if get_os() == 'darwin':\n        base = '/Library/Java/JavaVirtualMachines'\n        candidateJdks = [join(base, n, 'Contents/Home') for n in os.listdir(base) if exists(join(base, n, 'Contents/Home'))]\n    elif get_os() == 'linux':\n        base = '/usr/lib/jvm'\n        candidateJdks = [join(base, n) for n in os.listdir(base) if exists(join(base, n, 'jre/lib/rt.jar'))]\n    elif get_os() == 'solaris':\n        base = '/usr/jdk/instances'\n        candidateJdks = [join(base, n) for n in os.listdir(base) if exists(join(base, n, 'jre/lib/rt.jar'))]\n    elif get_os() == 'windows':\n        base = r'C:\\Program Files\\Java'\n        candidateJdks = [join(base, n) for n in os.listdir(base) if exists(join(base, n, r'jre\\lib\\rt.jar'))]\n\n    javaHome = None\n    if len(candidateJdks) != 0:\n        javaHome = select_items(candidateJdks + ['<other>'], allowMultiple=False)\n        if javaHome == '<other>':\n            javaHome = None\n\n    while javaHome is None:\n        javaHome = raw_input('Enter path of bootstrap JDK: ')\n        rtJarPath = join(javaHome, 'jre', 'lib', 'rt.jar')\n        if not exists(rtJarPath):\n            log('Does not appear to be a valid JDK as ' + rtJarPath + ' does not exist')\n            javaHome = None\n        else:\n            break\n\n    envPath = join(_primary_suite.mxDir, 'env')\n    if ask_yes_no('Persist this setting by adding \"JAVA_HOME=' + javaHome + '\" to ' + envPath, 'y'):\n        with open(envPath, 'a') as fp:\n            print >> fp, 'JAVA_HOME=' + javaHome\n\n    return javaHome\n\nclass ArgParser(ArgumentParser):\n    # Override parent to append the list of available commands\n    def format_help(self):\n        return ArgumentParser.format_help(self) + _format_commands()\n\n\n    def __init__(self):\n        self.java_initialized = False\n        # this doesn't resolve the right way, but can't figure out how to override _handle_conflict_resolve in _ActionsContainer\n        ArgumentParser.__init__(self, prog='mx', conflict_handler='resolve')\n\n        self.add_argument('-v', action='store_true', dest='verbose', help='enable verbose output')\n        self.add_argument('-V', action='store_true', dest='very_verbose', help='enable very verbose output')\n        self.add_argument('-w', action='store_true', dest='warn', help='enable warning messages')\n        self.add_argument('-p', '--primary-suite-path', help='set the primary suite directory', metavar='<path>')\n        self.add_argument('--dbg', type=int, dest='java_dbg_port', help='make Java processes wait on <port> for a debugger', metavar='<port>')\n        self.add_argument('-d', action='store_const', const=8000, dest='java_dbg_port', help='alias for \"-dbg 8000\"')\n        self.add_argument('--cp-pfx', dest='cp_prefix', help='class path prefix', metavar='<arg>')\n        self.add_argument('--cp-sfx', dest='cp_suffix', help='class path suffix', metavar='<arg>')\n        self.add_argument('--J', dest='java_args', help='Java VM arguments (e.g. --J @-dsa)', metavar='@<args>')\n        self.add_argument('--Jp', action='append', dest='java_args_pfx', help='prefix Java VM arguments (e.g. --Jp @-dsa)', metavar='@<args>', default=[])\n        self.add_argument('--Ja', action='append', dest='java_args_sfx', help='suffix Java VM arguments (e.g. --Ja @-dsa)', metavar='@<args>', default=[])\n        self.add_argument('--user-home', help='users home directory', metavar='<path>', default=os.path.expanduser('~'))\n        self.add_argument('--java-home', help='primary JDK directory (must be JDK 7 or later)', metavar='<path>')\n        self.add_argument('--extra-java-homes', help='secondary JDK directories separated by \"' + os.pathsep + '\"', metavar='<path>')\n        self.add_argument('--ignore-project', action='append', dest='ignored_projects', help='name of project to ignore', metavar='<name>', default=[])\n        self.add_argument('--kill-with-sigquit', action='store_true', dest='killwithsigquit', help='send sigquit first before killing child processes')\n        if get_os() != 'windows':\n            # Time outs are (currently) implemented with Unix specific functionality\n            self.add_argument('--timeout', help='timeout (in seconds) for command', type=int, default=0, metavar='<secs>')\n            self.add_argument('--ptimeout', help='timeout (in seconds) for subprocesses', type=int, default=0, metavar='<secs>')\n\n    def _parse_cmd_line(self, args=None):\n        if args is None:\n            args = sys.argv[1:]\n\n        self.add_argument('commandAndArgs', nargs=REMAINDER, metavar='command args...')\n\n        opts = self.parse_args()\n\n        # Give the timeout options a default value to avoid the need for hasattr() tests\n        opts.__dict__.setdefault('timeout', 0)\n        opts.__dict__.setdefault('ptimeout', 0)\n\n        if opts.very_verbose:\n            opts.verbose = True\n\n        if opts.java_home is None:\n            opts.java_home = os.environ.get('JAVA_HOME')\n        if opts.extra_java_homes is None:\n            opts.extra_java_homes = os.environ.get('EXTRA_JAVA_HOMES')\n\n        if opts.java_home is None or opts.java_home == '':\n            opts.java_home = _handle_missing_java_home()\n\n        if opts.user_home is None or opts.user_home == '':\n            abort('Could not find user home. Use --user-home option or ensure HOME environment variable is set.')\n\n        os.environ['JAVA_HOME'] = opts.java_home\n        os.environ['HOME'] = opts.user_home\n\n        opts.ignored_projects = opts.ignored_projects + os.environ.get('IGNORED_PROJECTS', '').split(',')\n\n        commandAndArgs = opts.__dict__.pop('commandAndArgs')\n        return opts, commandAndArgs\n\n    def _handle_conflict_resolve(self, action, conflicting_actions):\n        self._handle_conflict_error(action, conflicting_actions)\n\ndef _format_commands():\n    msg = '\\navailable commands:\\n\\n'\n    for cmd in sorted(_commands.iterkeys()):\n        c, _ = _commands[cmd][:2]\n        doc = c.__doc__\n        if doc is None:\n            doc = ''\n        msg += ' {0:<20} {1}\\n'.format(cmd, doc.split('\\n', 1)[0])\n    return msg + '\\n'\n\ndef java(requiredCompliance=None):\n    \"\"\"\n    Get a JavaConfig object containing Java commands launch details.\n    If requiredCompliance is None, the compliance level specified by --java-home/JAVA_HOME\n    is returned. Otherwise, the JavaConfig exactly matching requiredCompliance is returned\n    or None if there is no exact match.\n    \"\"\"\n    assert _java_homes\n    if not requiredCompliance:\n        return _java_homes[0]\n    for java in _java_homes:\n        if java.javaCompliance == requiredCompliance:\n            return java\n    return None\n\n\ndef run_java(args, nonZeroIsFatal=True, out=None, err=None, cwd=None, addDefaultArgs=True, javaConfig=None):\n    if not javaConfig:\n        javaConfig = java()\n    return run(javaConfig.format_cmd(args, addDefaultArgs), nonZeroIsFatal=nonZeroIsFatal, out=out, err=err, cwd=cwd)\n\ndef _kill_process_group(pid, sig):\n    if not sig:\n        sig = signal.SIGKILL\n    pgid = os.getpgid(pid)\n    try:\n        os.killpg(pgid, sig)\n        return True\n    except:\n        log('Error killing subprocess ' + str(pgid) + ': ' + str(sys.exc_info()[1]))\n        return False\n\ndef _waitWithTimeout(process, args, timeout):\n    def _waitpid(pid):\n        while True:\n            try:\n                return os.waitpid(pid, os.WNOHANG)\n            except OSError, e:\n                if e.errno == errno.EINTR:\n                    continue\n                raise\n\n    def _returncode(status):\n        if os.WIFSIGNALED(status):\n            return -os.WTERMSIG(status)\n        elif os.WIFEXITED(status):\n            return os.WEXITSTATUS(status)\n        else:\n            # Should never happen\n            raise RuntimeError(\"Unknown child exit status!\")\n\n    end = time.time() + timeout\n    delay = 0.0005\n    while True:\n        (pid, status) = _waitpid(process.pid)\n        if pid == process.pid:\n            return _returncode(status)\n        remaining = end - time.time()\n        if remaining <= 0:\n            abort('Process timed out after {0} seconds: {1}'.format(timeout, ' '.join(args)))\n        delay = min(delay * 2, remaining, .05)\n        time.sleep(delay)\n\n# Makes the current subprocess accessible to the abort() function\n# This is a list of tuples of the subprocess.Popen or\n# multiprocessing.Process object and args.\n_currentSubprocesses = []\n\ndef _addSubprocess(p, args):\n    entry = (p, args)\n    _currentSubprocesses.append(entry)\n    return entry\n\ndef _removeSubprocess(entry):\n    if entry and entry in _currentSubprocesses:\n        try:\n            _currentSubprocesses.remove(entry)\n        except:\n            pass\n\ndef waitOn(p):\n    if get_os() == 'windows':\n        # on windows use a poll loop, otherwise signal does not get handled\n        retcode = None\n        while retcode == None:\n            retcode = p.poll()\n            time.sleep(0.05)\n    else:\n        retcode = p.wait()\n    return retcode\n\ndef run(args, nonZeroIsFatal=True, out=None, err=None, cwd=None, timeout=None, env=None):\n    \"\"\"\n    Run a command in a subprocess, wait for it to complete and return the exit status of the process.\n    If the exit status is non-zero and `nonZeroIsFatal` is true, then mx is exited with\n    the same exit status.\n    Each line of the standard output and error streams of the subprocess are redirected to\n    out and err if they are callable objects.\n    \"\"\"\n\n    assert isinstance(args, types.ListType), \"'args' must be a list: \" + str(args)\n    for arg in args:\n        assert isinstance(arg, types.StringTypes), 'argument is not a string: ' + str(arg)\n\n    if env is None:\n        env = os.environ\n\n    if _opts.verbose:\n        if _opts.very_verbose:\n            log('Environment variables:')\n            for key in sorted(env.keys()):\n                log('    ' + key + '=' + env[key])\n        log(' '.join(map(pipes.quote, args)))\n\n    if timeout is None and _opts.ptimeout != 0:\n        timeout = _opts.ptimeout\n\n    sub = None\n    try:\n        # On Unix, the new subprocess should be in a separate group so that a timeout alarm\n        # can use os.killpg() to kill the whole subprocess group\n        preexec_fn = None\n        creationflags = 0\n        if get_os() == 'windows':\n            creationflags = subprocess.CREATE_NEW_PROCESS_GROUP\n        else:\n            preexec_fn = os.setsid\n\n        def redirect(stream, f):\n            for line in iter(stream.readline, ''):\n                f(line)\n            stream.close()\n        stdout = out if not callable(out) else subprocess.PIPE\n        stderr = err if not callable(err) else subprocess.PIPE\n        p = subprocess.Popen(args, cwd=cwd, stdout=stdout, stderr=stderr, preexec_fn=preexec_fn, creationflags=creationflags, env=env)\n        sub = _addSubprocess(p, args)\n        joiners = []\n        if callable(out):\n            t = Thread(target=redirect, args=(p.stdout, out))\n            # Don't make the reader thread a daemon otherwise output can be droppped\n            t.start()\n            joiners.append(t)\n        if callable(err):\n            t = Thread(target=redirect, args=(p.stderr, err))\n            # Don't make the reader thread a daemon otherwise output can be droppped\n            t.start()\n            joiners.append(t)\n        while any([t.is_alive() for t in joiners]):\n            # Need to use timeout otherwise all signals (including CTRL-C) are blocked\n            # see: http://bugs.python.org/issue1167930\n            for t in joiners:\n                t.join(10)\n        if timeout is None or timeout == 0:\n            retcode = waitOn(p)\n        else:\n            if get_os() == 'windows':\n                abort('Use of timeout not (yet) supported on Windows')\n            retcode = _waitWithTimeout(p, args, timeout)\n    except OSError as e:\n        log('Error executing \\'' + ' '.join(args) + '\\': ' + str(e))\n        if _opts.verbose:\n            raise e\n        abort(e.errno)\n    except KeyboardInterrupt:\n        abort(1)\n    finally:\n        _removeSubprocess(sub)\n\n    if retcode and nonZeroIsFatal:\n        if _opts.verbose:\n            if _opts.very_verbose:\n                raise subprocess.CalledProcessError(retcode, ' '.join(args))\n            else:\n                log('[exit code: ' + str(retcode) + ']')\n        abort(retcode)\n\n    return retcode\n\ndef exe_suffix(name):\n    \"\"\"\n    Gets the platform specific suffix for an executable\n    \"\"\"\n    if get_os() == 'windows':\n        return name + '.exe'\n    return name\n\ndef add_lib_prefix(name):\n    \"\"\"\n    Adds the platform specific library prefix to a name\n    \"\"\"\n    os = get_os()\n    if os == 'linux' or os == 'solaris' or os == 'darwin':\n        return 'lib' + name\n    return name\n\ndef add_lib_suffix(name):\n    \"\"\"\n    Adds the platform specific library suffix to a name\n    \"\"\"\n    os = get_os()\n    if os == 'windows':\n        return name + '.dll'\n    if os == 'linux' or os == 'solaris':\n        return name + '.so'\n    if os == 'darwin':\n        return name + '.dylib'\n    return name\n\n\"\"\"\nUtility for filtering duplicate lines.\n\"\"\"\nclass DuplicateSuppressingStream:\n    \"\"\"\n    Creates an object that will suppress duplicate lines sent to 'out'.\n    The lines considered for suppression are those that contain one of the\n    strings in 'restrictTo' if it is not None.\n    \"\"\"\n    def __init__(self, restrictTo=None, out=sys.stdout):\n        self.restrictTo = restrictTo\n        self.seen = set()\n        self.out = out\n        self.currentFilteredLineCount = 0\n        self.currentFilteredTime = None\n\n    def isSuppressionCandidate(self, line):\n        if self.restrictTo:\n            for p in self.restrictTo:\n                if p in line:\n                    return True\n            return False\n        else:\n            return True\n\n    def write(self, line):\n        if self.isSuppressionCandidate(line):\n            if line in self.seen:\n                self.currentFilteredLineCount += 1\n                if self.currentFilteredTime:\n                    if time.time() - self.currentFilteredTime > 1 * 60:\n                        self.out.write(\"  Filtered \" + str(self.currentFilteredLineCount) + \" repeated lines...\\n\")\n                        self.currentFilteredTime = time.time()\n                else:\n                    self.currentFilteredTime = time.time()\n                return\n            self.seen.add(line)\n        self.currentFilteredLineCount = 0\n        self.out.write(line)\n        self.currentFilteredTime = None\n\n\"\"\"\nA JavaCompliance simplifies comparing Java compliance values extracted from a JDK version string.\n\"\"\"\nclass JavaCompliance:\n    def __init__(self, ver):\n        m = re.match(r'1\\.(\\d+).*', ver)\n        assert m is not None, 'not a recognized version string: ' + ver\n        self.value = int(m.group(1))\n\n    def __str__(self):\n        return '1.' + str(self.value)\n\n    def __cmp__(self, other):\n        if isinstance(other, types.StringType):\n            other = JavaCompliance(other)\n\n        return cmp(self.value, other.value)\n\n    def __hash__(self):\n        return self.value.__hash__()\n\n\"\"\"\nA version specification as defined in JSR-56\n\"\"\"\nclass VersionSpec:\n    def __init__(self, versionString):\n        validChar = r'[\\x21-\\x25\\x27-\\x29\\x2c\\x2f-\\x5e\\x60-\\x7f]'\n        separator = r'[.\\-_]'\n        m = re.match(\"^\" + validChar + '+(' + separator + validChar + '+)*$', versionString)\n        assert m is not None, 'not a recognized version string: ' + versionString\n        self.versionString = versionString\n        self.parts = [int(f) if f.isdigit() else f for f in re.split(separator, versionString)]\n\n    def __str__(self):\n        return self.versionString\n\n    def __cmp__(self, other):\n        return cmp(self.parts, other.parts)\n\ndef _filter_non_existant_paths(paths):\n    return os.pathsep.join([path for path in paths.split(os.pathsep) if exists(path)])\n\n\"\"\"\nA JavaConfig object encapsulates info on how Java commands are run.\n\"\"\"\nclass JavaConfig:\n    def __init__(self, java_home, java_dbg_port):\n        self.jdk = java_home\n        self.debug_port = java_dbg_port\n        self.jar = exe_suffix(join(self.jdk, 'bin', 'jar'))\n        self.java = exe_suffix(join(self.jdk, 'bin', 'java'))\n        self.javac = exe_suffix(join(self.jdk, 'bin', 'javac'))\n        self.javap = exe_suffix(join(self.jdk, 'bin', 'javap'))\n        self.javadoc = exe_suffix(join(self.jdk, 'bin', 'javadoc'))\n        self.pack200 = exe_suffix(join(self.jdk, 'bin', 'pack200'))\n        self.toolsjar = join(self.jdk, 'lib', 'tools.jar')\n        self._bootclasspath = None\n        self._extdirs = None\n        self._endorseddirs = None\n\n        if not exists(self.java):\n            abort('Java launcher does not exist: ' + self.java)\n\n        def delAtAndSplit(s):\n            return shlex.split(s.lstrip('@'))\n\n        self.java_args = delAtAndSplit(_opts.java_args) if _opts.java_args else []\n        self.java_args_pfx = sum(map(delAtAndSplit, _opts.java_args_pfx), [])\n        self.java_args_sfx = sum(map(delAtAndSplit, _opts.java_args_sfx), [])\n\n        # Prepend the -d64 VM option only if the java command supports it\n        try:\n            output = subprocess.check_output([self.java, '-d64', '-version'], stderr=subprocess.STDOUT)\n            self.java_args = ['-d64'] + self.java_args\n        except subprocess.CalledProcessError as e:\n            try:\n                output = subprocess.check_output([self.java, '-version'], stderr=subprocess.STDOUT)\n            except subprocess.CalledProcessError as e:\n                print e.output\n                abort(e.returncode)\n\n        def _checkOutput(out):\n            return 'java version' in out\n\n        # hotspot can print a warning, e.g. if there's a .hotspot_compiler file in the cwd\n        output = output.split('\\n')\n        version = None\n        for o in output:\n            if _checkOutput(o):\n                assert version is None\n                version = o\n\n        self.version = VersionSpec(version.split()[2].strip('\"'))\n        self.javaCompliance = JavaCompliance(self.version.versionString)\n\n        if self.debug_port is not None:\n            self.java_args += ['-Xdebug', '-Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=' + str(self.debug_port)]\n\n    def _init_classpaths(self):\n        myDir = dirname(__file__)\n        outDir = join(dirname(__file__), '.jdk' + str(self.version))\n        if not exists(outDir):\n            os.makedirs(outDir)\n        javaSource = join(myDir, 'ClasspathDump.java')\n        if not exists(join(outDir, 'ClasspathDump.class')):\n            subprocess.check_call([self.javac, '-d', outDir, javaSource], stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n        self._bootclasspath, self._extdirs, self._endorseddirs = [x if x != 'null' else None for x in subprocess.check_output([self.java, '-cp', outDir, 'ClasspathDump'], stderr=subprocess.PIPE).split('|')]\n        if not self._bootclasspath or not self._extdirs or not self._endorseddirs:\n            warn(\"Could not find all classpaths: boot='\" + str(self._bootclasspath) + \"' extdirs='\" + str(self._extdirs) + \"' endorseddirs='\" + str(self._endorseddirs) + \"'\")\n        self._bootclasspath = _filter_non_existant_paths(self._bootclasspath)\n        self._extdirs = _filter_non_existant_paths(self._extdirs)\n        self._endorseddirs = _filter_non_existant_paths(self._endorseddirs)\n\n    def __hash__(self):\n        return hash(self.jdk)\n\n    def __cmp__(self, other):\n        if isinstance(other, JavaConfig):\n            return cmp(self.javaCompliance, other.javaCompliance)\n        raise TypeError()\n\n    def format_cmd(self, args, addDefaultArgs):\n        if addDefaultArgs:\n            return [self.java] + self.processArgs(args)\n        else:\n            return [self.java] + args\n\n    def processArgs(self, args):\n        return self.java_args_pfx + self.java_args + self.java_args_sfx + args\n\n    def bootclasspath(self):\n        if self._bootclasspath is None:\n            self._init_classpaths()\n        return self._bootclasspath\n\n    def extdirs(self):\n        if self._extdirs is None:\n            self._init_classpaths()\n        return self._extdirs\n\n    def endorseddirs(self):\n        if self._endorseddirs is None:\n            self._init_classpaths()\n        return self._endorseddirs\n\ndef check_get_env(key):\n    \"\"\"\n    Gets an environment variable, aborting with a useful message if it is not set.\n    \"\"\"\n    value = get_env(key)\n    if value is None:\n        abort('Required environment variable ' + key + ' must be set')\n    return value\n\ndef get_env(key, default=None):\n    \"\"\"\n    Gets an environment variable.\n    \"\"\"\n    value = os.environ.get(key, default)\n    return value\n\ndef logv(msg=None):\n    if _opts.verbose:\n        log(msg)\n\ndef log(msg=None):\n    \"\"\"\n    Write a message to the console.\n    All script output goes through this method thus allowing a subclass\n    to redirect it.\n    \"\"\"\n    if msg is None:\n        print\n    else:\n        print msg\n\ndef expand_project_in_class_path_arg(cpArg):\n    cp = []\n    for part in cpArg.split(os.pathsep):\n        if part.startswith('@'):\n            cp += classpath(part[1:]).split(os.pathsep)\n        else:\n            cp.append(part)\n    return os.pathsep.join(cp)\n\ndef expand_project_in_args(args):\n    for i in range(len(args)):\n        if args[i] == '-cp' or args[i] == '-classpath':\n            if i + 1 < len(args):\n                args[i + 1] = expand_project_in_class_path_arg(args[i + 1])\n            return\n\n\ndef gmake_cmd():\n    for a in ['make', 'gmake', 'gnumake']:\n        try:\n            output = subprocess.check_output([a, '--version'])\n            if 'GNU' in output:\n                return a\n        except:\n            pass\n    abort('Could not find a GNU make executable on the current path.')\n\ndef expandvars_in_property(value):\n    result = expandvars(value)\n    if '$' in result or '%' in result:\n        abort('Property contains an undefined environment variable: ' + value)\n    return result\n\ndef _send_sigquit():\n    for p, args in _currentSubprocesses:\n\n        def _isJava():\n            if args:\n                name = args[0].split(os.sep)[-1]\n                return name == \"java\"\n            return False\n\n        if p is not None and _isJava():\n            if get_os() == 'windows':\n                log(\"mx: implement me! want to send SIGQUIT to my child process\")\n            else:\n                _kill_process_group(p.pid, sig=signal.SIGQUIT)\n            time.sleep(0.1)\n\ndef abort(codeOrMessage):\n    \"\"\"\n    Aborts the program with a SystemExit exception.\n    If 'codeOrMessage' is a plain integer, it specifies the system exit status;\n    if it is None, the exit status is zero; if it has another type (such as a string),\n    the object's value is printed and the exit status is one.\n    \"\"\"\n\n    if _opts.killwithsigquit:\n        _send_sigquit()\n\n    def is_alive(p):\n        if isinstance(p, subprocess.Popen):\n            return p.poll() is None\n        assert isinstance(p, multiprocessing.Process), p\n        return p.is_alive()\n\n    for p, args in _currentSubprocesses:\n        if is_alive(p):\n            try:\n                if get_os() == 'windows':\n                    p.terminate()\n                else:\n                    _kill_process_group(p.pid, signal.SIGKILL)\n            except BaseException as e:\n                if is_alive(p):\n                    log('error while killing subprocess {} \"{}\": {}'.format(p.pid, ' '.join(args), e))\n\n    if _opts and _opts.verbose:\n        import traceback\n        traceback.print_stack()\n    raise SystemExit(codeOrMessage)\n\ndef download(path, urls, verbose=False):\n    \"\"\"\n    Attempts to downloads content for each URL in a list, stopping after the first successful download.\n    If the content cannot be retrieved from any URL, the program is aborted. The downloaded content\n    is written to the file indicated by 'path'.\n    \"\"\"\n    d = dirname(path)\n    if d != '' and not exists(d):\n        os.makedirs(d)\n\n    assert not path.endswith(os.sep)\n\n    myDir = dirname(__file__)\n    javaSource = join(myDir, 'URLConnectionDownload.java')\n    javaClass = join(myDir, 'URLConnectionDownload.class')\n    if not exists(javaClass) or getmtime(javaClass) < getmtime(javaSource):\n        subprocess.check_call([java().javac, '-d', myDir, javaSource])\n    verbose = []\n    if sys.stderr.isatty():\n        verbose.append(\"-v\")\n    if run([java().java, '-cp', myDir, 'URLConnectionDownload', path] + verbose + urls, nonZeroIsFatal=False) == 0:\n        return\n\n    abort('Could not download to ' + path + ' from any of the following URLs:\\n\\n    ' +\n              '\\n    '.join(urls) + '\\n\\nPlease use a web browser to do the download manually')\n\ndef update_file(path, content):\n    \"\"\"\n    Updates a file with some given content if the content differs from what's in\n    the file already. The return value indicates if the file was updated.\n    \"\"\"\n    existed = exists(path)\n    try:\n        old = None\n        if existed:\n            with open(path, 'rb') as f:\n                old = f.read()\n\n        if old == content:\n            return False\n\n        with open(path, 'wb') as f:\n            f.write(content)\n\n        log(('modified ' if existed else 'created ') + path)\n        return True\n    except IOError as e:\n        abort('Error while writing to ' + path + ': ' + str(e))\n\n# Builtin commands\n\ndef _defaultEcjPath():\n    return get_env('JDT', join(_primary_suite.mxDir, 'ecj.jar'))\n\nclass JavaCompileTask:\n    def __init__(self, args, proj, reason, javafilelist, jdk, outputDir, jdtJar, deps):\n        self.proj = proj\n        self.reason = reason\n        self.javafilelist = javafilelist\n        self.deps = deps\n        self.jdk = jdk\n        self.outputDir = outputDir\n        self.done = False\n        self.jdtJar = jdtJar\n        self.args = args\n\n    def __str__(self):\n        return self.proj.name\n\n    def logCompilation(self, compiler):\n        log('Compiling Java sources for {} with {}... [{}]'.format(self.proj.name, compiler, self.reason))\n\n    def execute(self):\n        argfileName = join(self.proj.dir, 'javafilelist.txt')\n        argfile = open(argfileName, 'wb')\n        argfile.write('\\n'.join(self.javafilelist))\n        argfile.close()\n\n        processorArgs = []\n\n        aps = self.proj.annotation_processors()\n        if len(aps) > 0:\n            processorPath = classpath(aps, resolve=True)\n            genDir = self.proj.source_gen_dir()\n            if exists(genDir):\n                shutil.rmtree(genDir)\n            os.mkdir(genDir)\n            processorArgs += ['-processorpath', join(processorPath), '-s', genDir]\n        else:\n            processorArgs += ['-proc:none']\n\n        args = self.args\n        jdk = self.jdk\n        outputDir = self.outputDir\n        compliance = str(jdk.javaCompliance)\n        cp = classpath(self.proj.name, includeSelf=True)\n        toBeDeleted = [argfileName]\n\n        try:\n            if not self.jdtJar:\n                mainJava = java()\n                if not args.error_prone:\n                    javac = args.alt_javac if args.alt_javac else mainJava.javac\n                    self.logCompilation('javac' if not args.alt_javac else args.alt_javac)\n                    javacCmd = [javac, '-g', '-J-Xmx1g', '-source', compliance, '-target', compliance, '-classpath', cp, '-d', outputDir, '-bootclasspath', jdk.bootclasspath(), '-endorseddirs', jdk.endorseddirs(), '-extdirs', jdk.extdirs()]\n                    if jdk.debug_port is not None:\n                        javacCmd += ['-J-Xdebug', '-J-Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=' + str(jdk.debug_port)]\n                    javacCmd += processorArgs\n                    javacCmd += ['@' + argfile.name]\n\n                    if not args.warnAPI:\n                        javacCmd.append('-XDignore.symbol.file')\n                    run(javacCmd)\n                else:\n                    self.logCompilation('javac (with error-prone)')\n                    javaArgs = ['-Xmx1g']\n                    javacArgs = ['-g', '-source', compliance, '-target', compliance, '-classpath', cp, '-d', outputDir, '-bootclasspath', jdk.bootclasspath(), '-endorseddirs', jdk.endorseddirs(), '-extdirs', jdk.extdirs()]\n                    javacArgs += processorArgs\n                    javacArgs += ['@' + argfile.name]\n                    if not args.warnAPI:\n                        javacArgs.append('-XDignore.symbol.file')\n                    run_java(javaArgs + ['-cp', os.pathsep.join([mainJava.toolsjar, args.error_prone]), 'com.google.errorprone.ErrorProneCompiler'] + javacArgs)\n            else:\n                self.logCompilation('JDT')\n\n                jdtVmArgs = ['-Xmx1g', '-jar', self.jdtJar]\n\n                jdtArgs = ['-' + compliance,\n                         '-cp', cp, '-g', '-enableJavadoc',\n                         '-d', outputDir,\n                         '-bootclasspath', jdk.bootclasspath(),\n                         '-endorseddirs', jdk.endorseddirs(),\n                         '-extdirs', jdk.extdirs()]\n                jdtArgs += processorArgs\n\n                jdtProperties = join(self.proj.dir, '.settings', 'org.eclipse.jdt.core.prefs')\n                rootJdtProperties = join(self.proj.suite.mxDir, 'eclipse-settings', 'org.eclipse.jdt.core.prefs')\n                if not exists(jdtProperties) or os.path.getmtime(jdtProperties) < os.path.getmtime(rootJdtProperties):\n                    # Try to fix a missing properties file by running eclipseinit\n                    _eclipseinit_project(self.proj)\n                if not exists(jdtProperties):\n                    log('JDT properties file {0} not found'.format(jdtProperties))\n                else:\n                    with open(jdtProperties) as fp:\n                        origContent = fp.read()\n                        content = origContent\n                        if args.jdt_warning_as_error:\n                            content = content.replace('=warning', '=error')\n                        if not args.jdt_show_task_tags:\n                            content = content + '\\norg.eclipse.jdt.core.compiler.problem.tasks=ignore'\n                    if origContent != content:\n                        jdtPropertiesTmp = jdtProperties + '.tmp'\n                        with open(jdtPropertiesTmp, 'w') as fp:\n                            fp.write(content)\n                        toBeDeleted.append(jdtPropertiesTmp)\n                        jdtArgs += ['-properties', jdtPropertiesTmp]\n                    else:\n                        jdtArgs += ['-properties', jdtProperties]\n                jdtArgs.append('@' + argfile.name)\n\n                run_java(jdtVmArgs + jdtArgs)\n        finally:\n            for n in toBeDeleted:\n                os.remove(n)\n            self.done = True\n\ndef build(args, parser=None):\n    \"\"\"compile the Java and C sources, linking the latter\n\n    Compile all the Java source code using the appropriate compilers\n    and linkers for the various source code types.\"\"\"\n\n    suppliedParser = parser is not None\n    if not suppliedParser:\n        parser = ArgumentParser(prog='mx build')\n\n    parser = parser if parser is not None else ArgumentParser(prog='mx build')\n    parser.add_argument('-f', action='store_true', dest='force', help='force build (disables timestamp checking)')\n    parser.add_argument('-c', action='store_true', dest='clean', help='removes existing build output')\n    parser.add_argument('-p', action='store_true', dest='parallelize', help='parallelizes Java compilation')\n    parser.add_argument('--source', dest='compliance', help='Java compliance level for projects without an explicit one')\n    parser.add_argument('--Wapi', action='store_true', dest='warnAPI', help='show warnings about using internal APIs')\n    parser.add_argument('--projects', action='store', help='comma separated projects to build (omit to build all projects)')\n    parser.add_argument('--only', action='store', help='comma separated projects to build, without checking their dependencies (omit to build all projects)')\n    parser.add_argument('--no-java', action='store_false', dest='java', help='do not build Java projects')\n    parser.add_argument('--no-native', action='store_false', dest='native', help='do not build native projects')\n    parser.add_argument('--jdt-warning-as-error', action='store_true', help='convert all Eclipse batch compiler warnings to errors')\n    parser.add_argument('--jdt-show-task-tags', action='store_true', help='show task tags as Eclipse batch compiler warnings')\n    parser.add_argument('--alt-javac', dest='alt_javac', help='path to alternative javac executable', metavar='<path>')\n    compilerSelect = parser.add_mutually_exclusive_group()\n    compilerSelect.add_argument('--error-prone', dest='error_prone', help='path to error-prone.jar', metavar='<path>')\n    compilerSelect.add_argument('--jdt', help='path to ecj.jar, the Eclipse batch compiler', default=_defaultEcjPath(), metavar='<path>')\n    compilerSelect.add_argument('--force-javac', action='store_true', dest='javac', help='use javac whether ecj.jar is found or not')\n\n    if suppliedParser:\n        parser.add_argument('remainder', nargs=REMAINDER, metavar='...')\n\n    args = parser.parse_args(args)\n\n    jdtJar = None\n    if not args.javac and args.jdt is not None:\n        if not args.jdt.endswith('.jar'):\n            abort('Path for Eclipse batch compiler does not look like a jar file: ' + args.jdt)\n        jdtJar = args.jdt\n        if not exists(jdtJar):\n            if os.path.abspath(jdtJar) == os.path.abspath(_defaultEcjPath()) and get_env('JDT', None) is None:\n                # Silently ignore JDT if default location is used but does not exist\n                jdtJar = None\n            else:\n                abort('Eclipse batch compiler jar does not exist: ' + args.jdt)\n\n    if args.only is not None:\n        # N.B. This build will not include dependencies including annotation processor dependencies\n        sortedProjects = [project(name) for name in args.only.split(',')]\n    else:\n        if args.projects is not None:\n            projectNames = args.projects.split(',')\n        else:\n            projectNames = None\n\n        projects = _projects_opt_limit_to_suites(projects_from_names(projectNames))\n        # N.B. Limiting to a suite only affects the starting set of projects. Dependencies in other suites will still be compiled\n        sortedProjects = sorted_project_deps(projects, includeAnnotationProcessors=True)\n\n    if args.java:\n        ideinit([], refreshOnly=True, buildProcessorJars=False)\n\n    def prepareOutputDirs(p, clean):\n        outputDir = p.output_dir()\n        if exists(outputDir):\n            if clean:\n                log('Cleaning {0}...'.format(outputDir))\n                shutil.rmtree(outputDir)\n                os.mkdir(outputDir)\n        else:\n            os.mkdir(outputDir)\n        genDir = p.source_gen_dir()\n        if genDir != '' and exists(genDir) and clean:\n            log('Cleaning {0}...'.format(genDir))\n            for f in os.listdir(genDir):\n                shutil.rmtree(join(genDir, f))\n        return outputDir\n\n    tasks = {}\n    for p in sortedProjects:\n        if p.native:\n            if args.native:\n                log('Calling GNU make {0}...'.format(p.dir))\n\n                if args.clean:\n                    run([gmake_cmd(), 'clean'], cwd=p.dir)\n\n                run([gmake_cmd()], cwd=p.dir)\n            continue\n        else:\n            if not args.java:\n                continue\n            if exists(join(p.dir, 'plugin.xml')):  # eclipse plugin project\n                continue\n\n        # skip building this Java project if its Java compliance level is \"higher\" than the configured JDK\n        requiredCompliance = p.javaCompliance if p.javaCompliance else JavaCompliance(args.compliance) if args.compliance else None\n        jdk = java(requiredCompliance)\n        assert jdk\n\n        outputDir = prepareOutputDirs(p, args.clean)\n\n        sourceDirs = p.source_dirs()\n        buildReason = 'forced build' if args.force else None\n        taskDeps = []\n        if not buildReason:\n            for dep in p.all_deps([], includeLibs=False, includeAnnotationProcessors=True):\n                taskDep = tasks.get(dep.name)\n                if taskDep:\n                    if not buildReason:\n                        buildReason = dep.name + ' rebuilt'\n                    taskDeps.append(taskDep)\n\n        jasminAvailable = None\n        javafilelist = []\n        for sourceDir in sourceDirs:\n            for root, _, files in os.walk(sourceDir):\n                javafiles = [join(root, name) for name in files if name.endswith('.java') and name != 'package-info.java']\n                javafilelist += javafiles\n\n                # Copy all non Java resources or assemble Jasmin files\n                nonjavafilelist = [join(root, name) for name in files if not name.endswith('.java')]\n                for src in nonjavafilelist:\n                    if src.endswith('.jasm'):\n                        className = None\n                        with open(src) as f:\n                            for line in f:\n                                if line.startswith('.class '):\n                                    className = line.split()[-1]\n                                    break\n\n                        if className is not None:\n                            jasminOutputDir = p.jasmin_output_dir()\n                            classFile = join(jasminOutputDir, className.replace('/', os.sep) + '.class')\n                            if exists(dirname(classFile)) and (not exists(classFile) or os.path.getmtime(classFile) < os.path.getmtime(src)):\n                                if jasminAvailable is None:\n                                    try:\n                                        with open(os.devnull) as devnull:\n                                            subprocess.call('jasmin', stdout=devnull, stderr=subprocess.STDOUT)\n                                        jasminAvailable = True\n                                    except OSError:\n                                        jasminAvailable = False\n\n                                if jasminAvailable:\n                                    log('Assembling Jasmin file ' + src)\n                                    run(['jasmin', '-d', jasminOutputDir, src])\n                                else:\n                                    log('The jasmin executable could not be found - skipping ' + src)\n                                    with file(classFile, 'a'):\n                                        os.utime(classFile, None)\n\n                        else:\n                            log('could not file .class directive in Jasmin source: ' + src)\n                    else:\n                        dst = join(outputDir, src[len(sourceDir) + 1:])\n                        if not exists(dirname(dst)):\n                            os.makedirs(dirname(dst))\n                        if exists(dirname(dst)) and (not exists(dst) or os.path.getmtime(dst) < os.path.getmtime(src)):\n                            shutil.copyfile(src, dst)\n\n                if not buildReason:\n                    for javafile in javafiles:\n                        classfile = TimeStampFile(outputDir + javafile[len(sourceDir):-len('java')] + 'class')\n                        if not classfile.exists() or classfile.isOlderThan(javafile):\n                            buildReason = 'class file(s) out of date'\n                            break\n\n        apsOutOfDate = p.update_current_annotation_processors_file()\n        if apsOutOfDate:\n            buildReason = 'annotation processor(s) changed'\n\n        if not buildReason:\n            logv('[all class files for {0} are up to date - skipping]'.format(p.name))\n            continue\n\n        if len(javafilelist) == 0:\n            logv('[no Java sources for {0} - skipping]'.format(p.name))\n            continue\n\n        task = JavaCompileTask(args, p, buildReason, javafilelist, jdk, outputDir, jdtJar, taskDeps)\n\n        if args.parallelize:\n            # Best to initialize class paths on main process\n            jdk.bootclasspath()\n            task.proc = None\n            tasks[p.name] = task\n        else:\n            task.execute()\n\n    if args.parallelize:\n\n        def joinTasks(tasks):\n            failed = []\n            for t in tasks:\n                t.proc.join()\n                _removeSubprocess(t.sub)\n                if t.proc.exitcode != 0:\n                    failed.append(t)\n            return failed\n\n        def checkTasks(tasks):\n            active = []\n            for t in tasks:\n                if t.proc.is_alive():\n                    active.append(t)\n                else:\n                    if t.proc.exitcode != 0:\n                        return ([], joinTasks(tasks))\n            return (active, [])\n\n        def remainingDepsDepth(task):\n            if task._d is None:\n                incompleteDeps = [d for d in task.deps if d.proc is None or d.proc.is_alive()]\n                if len(incompleteDeps) == 0:\n                    task._d = 0\n                else:\n                    task._d = max([remainingDepsDepth(t) for t in incompleteDeps]) + 1\n            return task._d\n\n        def compareTasks(t1, t2):\n            d = remainingDepsDepth(t1) - remainingDepsDepth(t2)\n            if d == 0:\n                t1Work = (1 + len(t1.proj.annotation_processors())) * len(t1.javafilelist)\n                t2Work = (1 + len(t2.proj.annotation_processors())) * len(t2.javafilelist)\n                d = t1Work - t2Work\n            return d\n\n        def sortWorklist(tasks):\n            for t in tasks:\n                t._d = None\n            return sorted(tasks, compareTasks)\n\n        cpus = multiprocessing.cpu_count()\n        worklist = sortWorklist(tasks.values())\n        active = []\n        failed = []\n        while len(worklist) != 0:\n            while True:\n                active, failed = checkTasks(active)\n                if len(failed) != 0:\n                    assert not active, active\n                    break\n                if len(active) == cpus:\n                    # Sleep for 1 second\n                    time.sleep(1)\n                else:\n                    break\n\n            if len(failed) != 0:\n                break\n\n            def executeTask(task):\n                # Clear sub-process list cloned from parent process\n                del _currentSubprocesses[:]\n                task.execute()\n\n            def depsDone(task):\n                for d in task.deps:\n                    if d.proc is None or d.proc.exitcode is None:\n                        return False\n                return True\n\n            for task in worklist:\n                if depsDone(task):\n                    worklist.remove(task)\n                    task.proc = multiprocessing.Process(target=executeTask, args=(task,))\n                    task.proc.start()\n                    active.append(task)\n                    task.sub = _addSubprocess(task.proc, ['JavaCompileTask', str(task)])\n                if len(active) == cpus:\n                    break\n\n            worklist = sortWorklist(worklist)\n\n        failed += joinTasks(active)\n        if len(failed):\n            for t in failed:\n                log('Compiling {} failed'.format(t.proj.name))\n            abort('{} Java compilation tasks failed'.format(len(failed)))\n\n    for dist in _dists.values():\n        archive(['@' + dist.name])\n\n    if suppliedParser:\n        return args\n    return None\n\ndef _chunk_files_for_command_line(files, limit=None, pathFunction=None):\n    \"\"\"\n    Returns a generator for splitting up a list of files into chunks such that the\n    size of the space separated file paths in a chunk is less than a given limit.\n    This is used to work around system command line length limits.\n    \"\"\"\n    chunkSize = 0\n    chunkStart = 0\n    if limit is None:\n        commandLinePrefixAllowance = 3000\n        if get_os() == 'windows':\n            # The CreateProcess function on Windows limits the length of a command line to\n            # 32,768 characters (http://msdn.microsoft.com/en-us/library/ms682425%28VS.85%29.aspx)\n            limit = 32768 - commandLinePrefixAllowance\n        else:\n            # Using just SC_ARG_MAX without extra downwards adjustment\n            # results in \"[Errno 7] Argument list too long\" on MacOS.\n            syslimit = os.sysconf('SC_ARG_MAX') - 20000\n            limit = syslimit - commandLinePrefixAllowance\n    for i in range(len(files)):\n        path = files[i] if pathFunction is None else pathFunction(files[i])\n        size = len(path) + 1\n        if chunkSize + size < limit:\n            chunkSize += size\n        else:\n            assert i > chunkStart\n            yield files[chunkStart:i]\n            chunkStart = i\n            chunkSize = 0\n    if chunkStart == 0:\n        assert chunkSize < limit\n        yield files\n\ndef eclipseformat(args):\n    \"\"\"run the Eclipse Code Formatter on the Java sources\n\n    The exit code 1 denotes that at least one file was modified.\"\"\"\n\n    parser = ArgumentParser(prog='mx eclipseformat')\n    parser.add_argument('-e', '--eclipse-exe', help='location of the Eclipse executable')\n    parser.add_argument('-C', '--no-backup', action='store_false', dest='backup', help='do not save backup of modified files')\n    parser.add_argument('--projects', action='store', help='comma separated projects to process (omit to process all projects)')\n\n    args = parser.parse_args(args)\n    if args.eclipse_exe is None:\n        args.eclipse_exe = os.environ.get('ECLIPSE_EXE')\n    if args.eclipse_exe is None:\n        abort('Could not find Eclipse executable. Use -e option or ensure ECLIPSE_EXE environment variable is set.')\n\n    # Maybe an Eclipse installation dir was specified - look for the executable in it\n    if isdir(args.eclipse_exe):\n        args.eclipse_exe = join(args.eclipse_exe, exe_suffix('eclipse'))\n        warn(\"The eclipse-exe was a directory, now using \" + args.eclipse_exe)\n\n    if not os.path.isfile(args.eclipse_exe):\n        abort('File does not exist: ' + args.eclipse_exe)\n    if not os.access(args.eclipse_exe, os.X_OK):\n        abort('Not an executable file: ' + args.eclipse_exe)\n\n    eclipseinit([], buildProcessorJars=False)\n\n    # build list of projects to be processed\n    projects = sorted_deps()\n    if args.projects is not None:\n        projects = [project(name) for name in args.projects.split(',')]\n\n    class Batch:\n        def __init__(self, settingsDir, javaCompliance):\n            self.path = join(settingsDir, 'org.eclipse.jdt.core.prefs')\n            self.javaCompliance = javaCompliance\n            self.javafiles = list()\n            with open(join(settingsDir, 'org.eclipse.jdt.ui.prefs')) as fp:\n                jdtUiPrefs = fp.read()\n            self.removeTrailingWhitespace = 'sp_cleanup.remove_trailing_whitespaces_all=true' in jdtUiPrefs\n            if self.removeTrailingWhitespace:\n                assert 'sp_cleanup.remove_trailing_whitespaces=true' in jdtUiPrefs and 'sp_cleanup.remove_trailing_whitespaces_ignore_empty=false' in jdtUiPrefs\n\n        def settings(self):\n            with open(self.path) as fp:\n                return fp.read() + java(self.javaCompliance).java + str(self.removeTrailingWhitespace)\n\n    class FileInfo:\n        def __init__(self, path):\n            self.path = path\n            with open(path) as fp:\n                self.content = fp.read()\n            self.times = (os.path.getatime(path), os.path.getmtime(path))\n\n        def update(self, removeTrailingWhitespace):\n            with open(self.path) as fp:\n                content = fp.read()\n\n            if self.content != content:\n                # Only apply *after* formatting to match the order in which the IDE does it\n                if removeTrailingWhitespace:\n                    content, n = re.subn(r'[ \\t]+$', '', content, flags=re.MULTILINE)\n                    if n != 0 and self.content == content:\n                        # undo on-disk changes made by the Eclipse formatter\n                        with open(self.path, 'w') as fp:\n                            fp.write(content)\n\n                if self.content != content:\n                    self.diff = difflib.unified_diff(self.content.splitlines(1), content.splitlines(1))\n                    self.content = content\n                    return True\n\n            # reset access and modification time of file\n            os.utime(self.path, self.times)\n\n    modified = list()\n    batches = dict()  # all sources with the same formatting settings are formatted together\n    for p in projects:\n        if p.native:\n            continue\n        sourceDirs = p.source_dirs()\n\n        batch = Batch(join(p.dir, '.settings'), p.javaCompliance)\n\n        if not exists(batch.path):\n            if _opts.verbose:\n                log('[no Eclipse Code Formatter preferences at {0} - skipping]'.format(batch.path))\n            continue\n\n        for sourceDir in sourceDirs:\n            for root, _, files in os.walk(sourceDir):\n                for f in [join(root, name) for name in files if name.endswith('.java')]:\n                    batch.javafiles.append(FileInfo(f))\n        if len(batch.javafiles) == 0:\n            logv('[no Java sources in {0} - skipping]'.format(p.name))\n            continue\n\n        res = batches.setdefault(batch.settings(), batch)\n        if res is not batch:\n            res.javafiles = res.javafiles + batch.javafiles\n\n    log(\"we have: \" + str(len(batches)) + \" batches\")\n    for batch in batches.itervalues():\n        for chunk in _chunk_files_for_command_line(batch.javafiles, pathFunction=lambda f: f.path):\n            run([args.eclipse_exe,\n                '-nosplash',\n                '-application',\n                'org.eclipse.jdt.core.JavaCodeFormatter',\n                '-vm', java(batch.javaCompliance).java,\n                '-config', batch.path]\n                + [f.path for f in chunk])\n            for fi in chunk:\n                if fi.update(batch.removeTrailingWhitespace):\n                    modified.append(fi)\n\n    log('{0} files were modified'.format(len(modified)))\n\n    if len(modified) != 0:\n        arcbase = _primary_suite.dir\n        if args.backup:\n            backup = os.path.abspath('eclipseformat.backup.zip')\n            zf = zipfile.ZipFile(backup, 'w', zipfile.ZIP_DEFLATED)\n        for fi in modified:\n            name = os.path.relpath(fi.path, arcbase)\n            log(' - {0}'.format(name))\n            log('Changes:')\n            log(''.join(fi.diff))\n            if args.backup:\n                arcname = name.replace(os.sep, '/')\n                zf.writestr(arcname, fi.content)\n        if args.backup:\n            zf.close()\n            log('Wrote backup of {0} modified files to {1}'.format(len(modified), backup))\n        return 1\n    return 0\n\ndef processorjars():\n    for s in suites(True):\n        _processorjars_suite(s)\n\ndef _processorjars_suite(s):\n    projs = set()\n    candidates = sorted_project_deps(s.projects)\n    for p in candidates:\n        if _isAnnotationProcessorDependency(p):\n            projs.add(p)\n\n    if len(projs) <= 0:\n        return []\n\n    pnames = [p.name for p in projs]\n    build(['--jdt-warning-as-error', '--projects', \",\".join(pnames)])\n    return archive(pnames)\n\ndef pylint(args):\n    \"\"\"run pylint (if available) over Python source files (found by 'hg locate' or by tree walk with -walk)\"\"\"\n\n    parser = ArgumentParser(prog='mx pylint')\n    parser.add_argument('--walk', action='store_true', help='use tree walk find .py files')\n    args = parser.parse_args(args)\n\n    rcfile = join(dirname(__file__), '.pylintrc')\n    if not exists(rcfile):\n        log('pylint configuration file does not exist: ' + rcfile)\n        return\n\n    try:\n        output = subprocess.check_output(['pylint', '--version'], stderr=subprocess.STDOUT)\n        m = re.match(r'.*pylint (\\d+)\\.(\\d+)\\.(\\d+).*', output, re.DOTALL)\n        if not m:\n            log('could not determine pylint version from ' + output)\n            return\n        major, minor, micro = (int(m.group(1)), int(m.group(2)), int(m.group(3)))\n        if major < 1:\n            log('require pylint version >= 1 (got {0}.{1}.{2})'.format(major, minor, micro))\n            return\n    except BaseException:\n        log('pylint is not available')\n        return\n\n    def findfiles_by_walk():\n        result = []\n        for suite in suites(True):\n            for root, dirs, files in os.walk(suite.dir):\n                for f in files:\n                    if f.endswith('.py'):\n                        pyfile = join(root, f)\n                        result.append(pyfile)\n                if 'bin' in dirs:\n                    dirs.remove('bin')\n                if 'lib' in dirs:\n                    # avoids downloaded .py files\n                    dirs.remove('lib')\n        return result\n\n    def findfiles_by_hg():\n        result = []\n        for suite in suites(True):\n            versioned = subprocess.check_output(['hg', 'locate', '-f'], stderr=subprocess.STDOUT, cwd=suite.dir).split(os.linesep)\n            for f in versioned:\n                if f.endswith('.py') and exists(f):\n                    result.append(f)\n        return result\n\n    # Perhaps we should just look in suite.mxDir directories for .py files?\n    if args.walk:\n        pyfiles = findfiles_by_walk()\n    else:\n        pyfiles = findfiles_by_hg()\n\n    env = os.environ.copy()\n\n    pythonpath = dirname(__file__)\n    for suite in suites(True):\n        pythonpath = os.pathsep.join([pythonpath, suite.mxDir])\n\n    env['PYTHONPATH'] = pythonpath\n\n    for pyfile in pyfiles:\n        log('Running pylint on ' + pyfile + '...')\n        run(['pylint', '--reports=n', '--rcfile=' + rcfile, pyfile], env=env)\n\n\"\"\"\nUtility for creating and updating a zip file atomically.\n\"\"\"\nclass Archiver:\n    def __init__(self, path):\n        self.path = path\n\n    def __enter__(self):\n        if self.path:\n            fd, tmp = tempfile.mkstemp(suffix='', prefix=basename(self.path) + '.', dir=dirname(self.path))\n            self.tmpFd = fd\n            self.tmpPath = tmp\n            self.zf = zipfile.ZipFile(tmp, 'w')\n        else:\n            self.tmpFd = None\n            self.tmpPath = None\n            self.zf = None\n        return self\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        if self.zf:\n            self.zf.close()\n            os.close(self.tmpFd)\n            # Correct the permissions on the temporary file which is created with restrictive permissions\n            os.chmod(self.tmpPath, 0o666 & ~currentUmask)\n            # Atomic on Unix\n            shutil.move(self.tmpPath, self.path)\n\ndef _archive(args):\n    archive(args)\n    return 0\n\ndef archive(args):\n    \"\"\"create jar files for projects and distributions\"\"\"\n    parser = ArgumentParser(prog='mx archive')\n    parser.add_argument('names', nargs=REMAINDER, metavar='[<project>|@<distribution>]...')\n    args = parser.parse_args(args)\n\n    archives = []\n    for name in args.names:\n        if name.startswith('@'):\n            dname = name[1:]\n            d = distribution(dname)\n            d.make_archive()\n            archives.append(d.path)\n        else:\n            p = project(name)\n            archives.append(p.make_archive())\n\n    logv(\"generated archives: \" + str(archives))\n    return archives\n\ndef canonicalizeprojects(args):\n    \"\"\"process all project files to canonicalize the dependencies\n\n    The exit code of this command reflects how many files were updated.\"\"\"\n\n    changedFiles = 0\n    for s in suites(True):\n        projectsFile = join(s.mxDir, 'projects')\n        if not exists(projectsFile):\n            continue\n        with open(projectsFile) as f:\n            out = StringIO.StringIO()\n            pattern = re.compile('project@([^@]+)@dependencies=.*')\n            lineNo = 1\n            for line in f:\n                line = line.strip()\n                m = pattern.match(line)\n                p = project(m.group(1), fatalIfMissing=False) if m else None\n                if m is None or p is None:\n                    out.write(line + '\\n')\n                else:\n                    for pkg in p.defined_java_packages():\n                        if not pkg.startswith(p.name):\n                            abort('package in {0} does not have prefix matching project name: {1}'.format(p, pkg))\n\n                    ignoredDeps = set([name for name in p.deps if project(name, False) is not None])\n                    for pkg in p.imported_java_packages():\n                        for name in p.deps:\n                            dep = project(name, False)\n                            if dep is None:\n                                ignoredDeps.discard(name)\n                            else:\n                                if pkg in dep.defined_java_packages():\n                                    ignoredDeps.discard(name)\n                                if pkg in dep.extended_java_packages():\n                                    ignoredDeps.discard(name)\n                    if len(ignoredDeps) != 0:\n                        candidates = set()\n                        # Compute dependencies based on projects required by p\n                        for d in sorted_deps():\n                            if not d.defined_java_packages().isdisjoint(p.imported_java_packages()):\n                                candidates.add(d)\n                        # Remove non-canonical candidates\n                        for c in list(candidates):\n                            candidates.difference_update(c.all_deps([], False, False))\n                        candidates = [d.name for d in candidates]\n\n                        abort('{0}:{1}: {2} does not use any packages defined in these projects: {3}\\nComputed project dependencies: {4}'.format(\n                            projectsFile, lineNo, p, ', '.join(ignoredDeps), ','.join(candidates)))\n\n                    out.write('project@' + m.group(1) + '@dependencies=' + ','.join(p.canonical_deps()) + '\\n')\n                lineNo = lineNo + 1\n            content = out.getvalue()\n        if update_file(projectsFile, content):\n            changedFiles += 1\n    return changedFiles\n\nclass TimeStampFile:\n    def __init__(self, path):\n        self.path = path\n        self.timestamp = os.path.getmtime(path) if exists(path) else None\n\n    def isOlderThan(self, arg):\n        if not self.timestamp:\n            return True\n        if isinstance(arg, TimeStampFile):\n            if arg.timestamp is None:\n                return False\n            else:\n                return arg.timestamp > self.timestamp\n        elif isinstance(arg, types.ListType):\n            files = arg\n        else:\n            files = [arg]\n        for f in files:\n            if os.path.getmtime(f) > self.timestamp:\n                return True\n        return False\n\n    def exists(self):\n        return exists(self.path)\n\n    def touch(self):\n        if exists(self.path):\n            os.utime(self.path, None)\n        else:\n            if not isdir(dirname(self.path)):\n                os.makedirs(dirname(self.path))\n            file(self.path, 'a')\n\ndef checkstyle(args):\n    \"\"\"run Checkstyle on the Java sources\n\n   Run Checkstyle over the Java sources. Any errors or warnings\n   produced by Checkstyle result in a non-zero exit code.\"\"\"\n\n    parser = ArgumentParser(prog='mx checkstyle')\n\n    parser.add_argument('-f', action='store_true', dest='force', help='force checking (disables timestamp checking)')\n    args = parser.parse_args(args)\n\n    totalErrors = 0\n    for p in projects_opt_limit_to_suites():\n        if p.native:\n            continue\n        sourceDirs = p.source_dirs()\n\n        csConfig = join(p.dir, '.checkstyle_checks.xml')\n        if not exists(csConfig):\n            abort('ERROR: Checkstyle configuration for project {} is missing: {}'.format(p.name, csConfig))\n\n        # skip checking this Java project if its Java compliance level is \"higher\" than the configured JDK\n        jdk = java(p.javaCompliance)\n        assert jdk\n\n        for sourceDir in sourceDirs:\n            javafilelist = []\n            for root, _, files in os.walk(sourceDir):\n                javafilelist += [join(root, name) for name in files if name.endswith('.java') and name != 'package-info.java']\n            if len(javafilelist) == 0:\n                logv('[no Java sources in {0} - skipping]'.format(sourceDir))\n                continue\n\n            timestamp = TimeStampFile(join(p.suite.mxDir, 'checkstyle-timestamps', sourceDir[len(p.suite.dir) + 1:].replace(os.sep, '_') + '.timestamp'))\n            mustCheck = False\n            if not args.force and timestamp.exists():\n                mustCheck = timestamp.isOlderThan(javafilelist)\n            else:\n                mustCheck = True\n\n            if not mustCheck:\n                if _opts.verbose:\n                    log('[all Java sources in {0} already checked - skipping]'.format(sourceDir))\n                continue\n\n            dotCheckstyleXML = xml.dom.minidom.parse(csConfig)\n            localCheckConfig = dotCheckstyleXML.getElementsByTagName('local-check-config')[0]\n            configLocation = localCheckConfig.getAttribute('location')\n            configType = localCheckConfig.getAttribute('type')\n            if configType == 'project':\n                # Eclipse plugin \"Project Relative Configuration\" format:\n                #\n                #  '/<project_name>/<suffix>'\n                #\n                if configLocation.startswith('/'):\n                    name, _, suffix = configLocation.lstrip('/').partition('/')\n                    config = join(project(name).dir, suffix)\n                else:\n                    config = join(p.dir, configLocation)\n            else:\n                logv('[unknown Checkstyle configuration type \"' + configType + '\" in {0} - skipping]'.format(sourceDir))\n                continue\n\n            exclude = join(p.dir, '.checkstyle.exclude')\n\n            if exists(exclude):\n                with open(exclude) as f:\n                    # Convert patterns to OS separators\n                    patterns = [name.rstrip().replace('/', os.sep) for name in f.readlines()]\n                def match(name):\n                    for p in patterns:\n                        if p in name:\n                            if _opts.verbose:\n                                log('excluding: ' + name)\n                            return True\n                    return False\n\n                javafilelist = [name for name in javafilelist if not match(name)]\n\n            auditfileName = join(p.dir, 'checkstyleOutput.txt')\n            log('Running Checkstyle on {0} using {1}...'.format(sourceDir, config))\n\n            try:\n                for chunk in _chunk_files_for_command_line(javafilelist):\n                    try:\n                        run_java(['-Xmx1g', '-jar', library('CHECKSTYLE').get_path(True), '-f', 'xml', '-c', config, '-o', auditfileName] + chunk, nonZeroIsFatal=False)\n                    finally:\n                        if exists(auditfileName):\n                            errors = []\n                            source = [None]\n                            def start_element(name, attrs):\n                                if name == 'file':\n                                    source[0] = attrs['name']\n                                elif name == 'error':\n                                    errors.append('{}:{}: {}'.format(source[0], attrs['line'], attrs['message']))\n\n                            xp = xml.parsers.expat.ParserCreate()\n                            xp.StartElementHandler = start_element\n                            with open(auditfileName) as fp:\n                                xp.ParseFile(fp)\n                            if len(errors) != 0:\n                                map(log, errors)\n                                totalErrors = totalErrors + len(errors)\n                            else:\n                                timestamp.touch()\n            finally:\n                if exists(auditfileName):\n                    os.unlink(auditfileName)\n    return totalErrors\n\ndef clean(args, parser=None):\n    \"\"\"remove all class files, images, and executables\n\n    Removes all files created by a build, including Java class files, executables, and\n    generated images.\n    \"\"\"\n\n    suppliedParser = parser is not None\n\n    parser = parser if suppliedParser else ArgumentParser(prog='mx clean')\n    parser.add_argument('--no-native', action='store_false', dest='native', help='do not clean native projects')\n    parser.add_argument('--no-java', action='store_false', dest='java', help='do not clean Java projects')\n    parser.add_argument('--no-dist', action='store_false', dest='dist', help='do not delete distributions')\n\n    args = parser.parse_args(args)\n\n    def _rmtree(dirPath):\n        path = dirPath\n        if get_os() == 'windows':\n            path = unicode(\"\\\\\\\\?\\\\\" + dirPath)\n        shutil.rmtree(path)\n\n    def _rmIfExists(name):\n        if os.path.isfile(name):\n            os.unlink(name)\n\n    for p in projects_opt_limit_to_suites():\n        if p.native:\n            if args.native:\n                run([gmake_cmd(), '-C', p.dir, 'clean'])\n        else:\n            if args.java:\n                genDir = p.source_gen_dir()\n                if genDir != '' and exists(genDir):\n                    log('Clearing {0}...'.format(genDir))\n                    for f in os.listdir(genDir):\n                        _rmtree(join(genDir, f))\n\n\n                outputDir = p.output_dir()\n                if outputDir != '' and exists(outputDir):\n                    log('Removing {0}...'.format(outputDir))\n                    _rmtree(outputDir)\n\n            for configName in ['netbeans-config.zip', 'eclipse-config.zip']:\n                config = TimeStampFile(join(p.suite.mxDir, configName))\n                if config.exists():\n                    os.unlink(config.path)\n\n    if args.dist:\n        for d in _dists.keys():\n            log('Removing distribution {0}...'.format(d))\n            _rmIfExists(distribution(d).path)\n            _rmIfExists(distribution(d).sourcesPath)\n\n    if suppliedParser:\n        return args\n\ndef about(args):\n    \"\"\"show the 'man page' for mx\"\"\"\n    print __doc__\n\ndef help_(args):\n    \"\"\"show help for a given command\n\nWith no arguments, print a list of commands and short help for each command.\n\nGiven a command name, print help for that command.\"\"\"\n    if len(args) == 0:\n        _argParser.print_help()\n        return\n\n    name = args[0]\n    if not _commands.has_key(name):\n        hits = [c for c in _commands.iterkeys() if c.startswith(name)]\n        if len(hits) == 1:\n            name = hits[0]\n        elif len(hits) == 0:\n            abort('mx: unknown command \\'{0}\\'\\n{1}use \"mx help\" for more options'.format(name, _format_commands()))\n        else:\n            abort('mx: command \\'{0}\\' is ambiguous\\n    {1}'.format(name, ' '.join(hits)))\n\n    value = _commands[name]\n    (func, usage) = value[:2]\n    doc = func.__doc__\n    if len(value) > 2:\n        docArgs = value[2:]\n        fmtArgs = []\n        for d in docArgs:\n            if isinstance(d, Callable):\n                fmtArgs += [d()]\n            else:\n                fmtArgs += [str(d)]\n        doc = doc.format(*fmtArgs)\n    print 'mx {0} {1}\\n\\n{2}\\n'.format(name, usage, doc)\n\ndef projectgraph(args, suite=None):\n    \"\"\"create graph for project structure (\"mx projectgraph | dot -Tpdf -oprojects.pdf\" or \"mx projectgraph --igv\")\"\"\"\n\n    parser = ArgumentParser(prog='mx projectgraph')\n    parser.add_argument('--igv', action='store_true', help='output to IGV listening on 127.0.0.1:4444')\n    parser.add_argument('--igv-format', action='store_true', help='output graph in IGV format')\n\n    args = parser.parse_args(args)\n\n    if args.igv or args.igv_format:\n        ids = {}\n        nextToIndex = {}\n        igv = XMLDoc()\n        igv.open('graphDocument')\n        igv.open('group')\n        igv.open('properties')\n        igv.element('p', {'name' : 'name'}, 'GraalProjectDependencies')\n        igv.close('properties')\n        igv.open('graph', {'name' : 'dependencies'})\n        igv.open('nodes')\n        for p in sorted_deps(includeLibs=True, includeJreLibs=True):\n            ident = len(ids)\n            ids[p.name] = str(ident)\n            igv.open('node', {'id' : str(ident)})\n            igv.open('properties')\n            igv.element('p', {'name' : 'name'}, p.name)\n            igv.close('properties')\n            igv.close('node')\n        igv.close('nodes')\n        igv.open('edges')\n        for p in projects():\n            fromIndex = 0\n            for dep in p.canonical_deps():\n                toIndex = nextToIndex.get(dep, 0)\n                nextToIndex[dep] = toIndex + 1\n                igv.element('edge', {'from' : ids[p.name], 'fromIndex' : str(fromIndex), 'to' : ids[dep], 'toIndex' : str(toIndex), 'label' : 'dependsOn'})\n                fromIndex = fromIndex + 1\n        igv.close('edges')\n        igv.close('graph')\n        igv.close('group')\n        igv.close('graphDocument')\n\n        if args.igv:\n            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            s.connect(('127.0.0.1', 4444))\n            s.send(igv.xml())\n        else:\n            print igv.xml(indent='  ', newl='\\n')\n        return\n\n    print 'digraph projects {'\n    print 'rankdir=BT;'\n    print 'node [shape=rect];'\n    for p in projects():\n        for dep in p.canonical_deps():\n            print '\"' + p.name + '\"->\"' + dep + '\"'\n    print '}'\n\ndef _source_locator_memento(deps):\n    slm = XMLDoc()\n    slm.open('sourceLookupDirector')\n    slm.open('sourceContainers', {'duplicates' : 'false'})\n\n    javaCompliance = None\n    for dep in deps:\n        if dep.isLibrary():\n            if hasattr(dep, 'eclipse.container'):\n                memento = XMLDoc().element('classpathContainer', {'path' : getattr(dep, 'eclipse.container')}).xml(standalone='no')\n                slm.element('classpathContainer', {'memento' : memento, 'typeId':'org.eclipse.jdt.launching.sourceContainer.classpathContainer'})\n            elif dep.get_source_path(resolve=True):\n                memento = XMLDoc().element('archive', {'detectRoot' : 'true', 'path' : dep.get_source_path(resolve=True)}).xml(standalone='no')\n                slm.element('container', {'memento' : memento, 'typeId':'org.eclipse.debug.core.containerType.externalArchive'})\n        elif dep.isProject():\n            memento = XMLDoc().element('javaProject', {'name' : dep.name}).xml(standalone='no')\n            slm.element('container', {'memento' : memento, 'typeId':'org.eclipse.jdt.launching.sourceContainer.javaProject'})\n            if javaCompliance is None or dep.javaCompliance > javaCompliance:\n                javaCompliance = dep.javaCompliance\n\n    if javaCompliance:\n        memento = XMLDoc().element('classpathContainer', {'path' : 'org.eclipse.jdt.launching.JRE_CONTAINER/org.eclipse.jdt.internal.debug.ui.launcher.StandardVMType/JavaSE-' + str(javaCompliance)}).xml(standalone='no')\n        slm.element('classpathContainer', {'memento' : memento, 'typeId':'org.eclipse.jdt.launching.sourceContainer.classpathContainer'})\n    else:\n        memento = XMLDoc().element('classpathContainer', {'path' : 'org.eclipse.jdt.launching.JRE_CONTAINER'}).xml(standalone='no')\n        slm.element('classpathContainer', {'memento' : memento, 'typeId':'org.eclipse.jdt.launching.sourceContainer.classpathContainer'})\n\n    slm.close('sourceContainers')\n    slm.close('sourceLookupDirector')\n    return slm\n\ndef make_eclipse_attach(suite, hostname, port, name=None, deps=None):\n    \"\"\"\n    Creates an Eclipse launch configuration file for attaching to a Java process.\n    \"\"\"\n    if deps is None:\n        deps = []\n    slm = _source_locator_memento(deps)\n    launch = XMLDoc()\n    launch.open('launchConfiguration', {'type' : 'org.eclipse.jdt.launching.remoteJavaApplication'})\n    launch.element('stringAttribute', {'key' : 'org.eclipse.debug.core.source_locator_id', 'value' : 'org.eclipse.jdt.launching.sourceLocator.JavaSourceLookupDirector'})\n    launch.element('stringAttribute', {'key' : 'org.eclipse.debug.core.source_locator_memento', 'value' : '%s'})\n    launch.element('booleanAttribute', {'key' : 'org.eclipse.jdt.launching.ALLOW_TERMINATE', 'value' : 'true'})\n    launch.open('mapAttribute', {'key' : 'org.eclipse.jdt.launching.CONNECT_MAP'})\n    launch.element('mapEntry', {'key' : 'hostname', 'value' : hostname})\n    launch.element('mapEntry', {'key' : 'port', 'value' : port})\n    launch.close('mapAttribute')\n    launch.element('stringAttribute', {'key' : 'org.eclipse.jdt.launching.PROJECT_ATTR', 'value' : ''})\n    launch.element('stringAttribute', {'key' : 'org.eclipse.jdt.launching.VM_CONNECTOR_ID', 'value' : 'org.eclipse.jdt.launching.socketAttachConnector'})\n    launch.close('launchConfiguration')\n    launch = launch.xml(newl='\\n', standalone='no') % slm.xml(escape=True, standalone='no')\n\n    if name is None:\n        if len(suites()) == 1:\n            suitePrefix = ''\n        else:\n            suitePrefix = suite.name + '-'\n        name = suitePrefix + 'attach-' + hostname + '-' + port\n    eclipseLaunches = join(suite.mxDir, 'eclipse-launches')\n    if not exists(eclipseLaunches):\n        os.makedirs(eclipseLaunches)\n    launchFile = join(eclipseLaunches, name + '.launch')\n    return update_file(launchFile, launch), launchFile\n\ndef make_eclipse_launch(javaArgs, jre, name=None, deps=None):\n    \"\"\"\n    Creates an Eclipse launch configuration file for running/debugging a Java command.\n    \"\"\"\n    if deps is None:\n        deps = []\n    mainClass = None\n    vmArgs = []\n    appArgs = []\n    cp = None\n    argsCopy = list(reversed(javaArgs))\n    while len(argsCopy) != 0:\n        a = argsCopy.pop()\n        if a == '-jar':\n            mainClass = '-jar'\n            appArgs = list(reversed(argsCopy))\n            break\n        if a == '-cp' or a == '-classpath':\n            assert len(argsCopy) != 0\n            cp = argsCopy.pop()\n            vmArgs.append(a)\n            vmArgs.append(cp)\n        elif a.startswith('-'):\n            vmArgs.append(a)\n        else:\n            mainClass = a\n            appArgs = list(reversed(argsCopy))\n            break\n\n    if mainClass is None:\n        log('Cannot create Eclipse launch configuration without main class or jar file: java ' + ' '.join(javaArgs))\n        return False\n\n    if name is None:\n        if mainClass == '-jar':\n            name = basename(appArgs[0])\n            if len(appArgs) > 1 and not appArgs[1].startswith('-'):\n                name = name + '_' + appArgs[1]\n        else:\n            name = mainClass\n        name = time.strftime('%Y-%m-%d-%H%M%S_' + name)\n\n    if cp is not None:\n        for e in cp.split(os.pathsep):\n            for s in suites():\n                deps += [p for p in s.projects if e == p.output_dir()]\n                deps += [l for l in s.libs if e == l.get_path(False)]\n\n    slm = _source_locator_memento(deps)\n\n    launch = XMLDoc()\n    launch.open('launchConfiguration', {'type' : 'org.eclipse.jdt.launching.localJavaApplication'})\n    launch.element('stringAttribute', {'key' : 'org.eclipse.debug.core.source_locator_id', 'value' : 'org.eclipse.jdt.launching.sourceLocator.JavaSourceLookupDirector'})\n    launch.element('stringAttribute', {'key' : 'org.eclipse.debug.core.source_locator_memento', 'value' : '%s'})\n    launch.element('stringAttribute', {'key' : 'org.eclipse.jdt.launching.JRE_CONTAINER', 'value' : 'org.eclipse.jdt.launching.JRE_CONTAINER/org.eclipse.jdt.internal.debug.ui.launcher.StandardVMType/' + jre})\n    launch.element('stringAttribute', {'key' : 'org.eclipse.jdt.launching.MAIN_TYPE', 'value' : mainClass})\n    launch.element('stringAttribute', {'key' : 'org.eclipse.jdt.launching.PROGRAM_ARGUMENTS', 'value' : ' '.join(appArgs)})\n    launch.element('stringAttribute', {'key' : 'org.eclipse.jdt.launching.PROJECT_ATTR', 'value' : ''})\n    launch.element('stringAttribute', {'key' : 'org.eclipse.jdt.launching.VM_ARGUMENTS', 'value' : ' '.join(vmArgs)})\n    launch.close('launchConfiguration')\n    launch = launch.xml(newl='\\n', standalone='no') % slm.xml(escape=True, standalone='no')\n\n    eclipseLaunches = join('mx', 'eclipse-launches')\n    if not exists(eclipseLaunches):\n        os.makedirs(eclipseLaunches)\n    return update_file(join(eclipseLaunches, name + '.launch'), launch)\n\ndef eclipseinit(args, buildProcessorJars=True, refreshOnly=False):\n    \"\"\"(re)generate Eclipse project configurations and working sets\"\"\"\n    for s in suites(True):\n        _eclipseinit_suite(args, s, buildProcessorJars, refreshOnly)\n\n    generate_eclipse_workingsets()\n\ndef _check_ide_timestamp(suite, configZip, ide):\n    \"\"\"return True if and only if the projects file, eclipse-settings files, and mx itself are all older than configZip\"\"\"\n    projectsFile = join(suite.mxDir, 'projects')\n    if configZip.isOlderThan(projectsFile):\n        return False\n    # Assume that any mx change might imply changes to the generated IDE files\n    if configZip.isOlderThan(__file__):\n        return False\n\n    if ide == 'eclipse':\n        eclipseSettingsDir = join(suite.mxDir, 'eclipse-settings')\n        if exists(eclipseSettingsDir):\n            for name in os.listdir(eclipseSettingsDir):\n                path = join(eclipseSettingsDir, name)\n                if configZip.isOlderThan(path):\n                    return False\n    return True\n\ndef _eclipseinit_project(p, files=None, libFiles=None):\n    assert java(p.javaCompliance)\n\n    if not exists(p.dir):\n        os.makedirs(p.dir)\n\n    out = XMLDoc()\n    out.open('classpath')\n\n    for src in p.srcDirs:\n        srcDir = join(p.dir, src)\n        if not exists(srcDir):\n            os.mkdir(srcDir)\n        out.element('classpathentry', {'kind' : 'src', 'path' : src})\n\n    if len(p.annotation_processors()) > 0:\n        genDir = p.source_gen_dir()\n        if not exists(genDir):\n            os.mkdir(genDir)\n        out.element('classpathentry', {'kind' : 'src', 'path' : 'src_gen'})\n        if files:\n            files.append(genDir)\n\n    # Every Java program depends on a JRE\n    out.element('classpathentry', {'kind' : 'con', 'path' : 'org.eclipse.jdt.launching.JRE_CONTAINER/org.eclipse.jdt.internal.debug.ui.launcher.StandardVMType/JavaSE-' + str(p.javaCompliance)})\n\n    if exists(join(p.dir, 'plugin.xml')):  # eclipse plugin project\n        out.element('classpathentry', {'kind' : 'con', 'path' : 'org.eclipse.pde.core.requiredPlugins'})\n\n    containerDeps = set()\n    libraryDeps = set()\n    projectDeps = set()\n\n    for dep in p.all_deps([], True):\n        if dep == p:\n            continue\n        if dep.isLibrary():\n            if hasattr(dep, 'eclipse.container'):\n                container = getattr(dep, 'eclipse.container')\n                containerDeps.add(container)\n                libraryDeps -= set(dep.all_deps([], True))\n            else:\n                libraryDeps.add(dep)\n        elif dep.isProject():\n            projectDeps.add(dep)\n\n    for dep in containerDeps:\n        out.element('classpathentry', {'exported' : 'true', 'kind' : 'con', 'path' : dep})\n\n    for dep in libraryDeps:\n        path = dep.path\n        dep.get_path(resolve=True)\n\n        # Relative paths for \"lib\" class path entries have various semantics depending on the Eclipse\n        # version being used (e.g. see https://bugs.eclipse.org/bugs/show_bug.cgi?id=274737) so it's\n        # safest to simply use absolute paths.\n        path = _make_absolute(path, p.suite.dir)\n\n        attributes = {'exported' : 'true', 'kind' : 'lib', 'path' : path}\n\n        sourcePath = dep.get_source_path(resolve=True)\n        if sourcePath is not None:\n            attributes['sourcepath'] = sourcePath\n        out.element('classpathentry', attributes)\n        if libFiles:\n            libFiles.append(path)\n\n    for dep in projectDeps:\n        out.element('classpathentry', {'combineaccessrules' : 'false', 'exported' : 'true', 'kind' : 'src', 'path' : '/' + dep.name})\n\n    out.element('classpathentry', {'kind' : 'output', 'path' : getattr(p, 'eclipse.output', 'bin')})\n    out.close('classpath')\n    classpathFile = join(p.dir, '.classpath')\n    update_file(classpathFile, out.xml(indent='\\t', newl='\\n'))\n    if files:\n        files.append(classpathFile)\n\n    csConfig = join(project(p.checkstyleProj).dir, '.checkstyle_checks.xml')\n    if exists(csConfig):\n        out = XMLDoc()\n\n        dotCheckstyle = join(p.dir, \".checkstyle\")\n        checkstyleConfigPath = '/' + p.checkstyleProj + '/.checkstyle_checks.xml'\n        out.open('fileset-config', {'file-format-version' : '1.2.0', 'simple-config' : 'true'})\n        out.open('local-check-config', {'name' : 'Checks', 'location' : checkstyleConfigPath, 'type' : 'project', 'description' : ''})\n        out.element('additional-data', {'name' : 'protect-config-file', 'value' : 'false'})\n        out.close('local-check-config')\n        out.open('fileset', {'name' : 'all', 'enabled' : 'true', 'check-config-name' : 'Checks', 'local' : 'true'})\n        out.element('file-match-pattern', {'match-pattern' : '.', 'include-pattern' : 'true'})\n        out.close('fileset')\n        out.open('filter', {'name' : 'all', 'enabled' : 'true', 'check-config-name' : 'Checks', 'local' : 'true'})\n        out.element('filter-data', {'value' : 'java'})\n        out.close('filter')\n\n        exclude = join(p.dir, '.checkstyle.exclude')\n        if exists(exclude):\n            out.open('filter', {'name' : 'FilesFromPackage', 'enabled' : 'true'})\n            with open(exclude) as f:\n                for line in f:\n                    if not line.startswith('#'):\n                        line = line.strip()\n                        exclDir = join(p.dir, line)\n                        assert isdir(exclDir), 'excluded source directory listed in ' + exclude + ' does not exist or is not a directory: ' + exclDir\n                    out.element('filter-data', {'value' : line})\n            out.close('filter')\n\n        out.close('fileset-config')\n        update_file(dotCheckstyle, out.xml(indent='  ', newl='\\n'))\n        if files:\n            files.append(dotCheckstyle)\n    else:\n        # clean up existing .checkstyle file\n        dotCheckstyle = join(p.dir, \".checkstyle\")\n        if exists(dotCheckstyle):\n            os.unlink(dotCheckstyle)\n\n    out = XMLDoc()\n    out.open('projectDescription')\n    out.element('name', data=p.name)\n    out.element('comment', data='')\n    out.element('projects', data='')\n    out.open('buildSpec')\n    out.open('buildCommand')\n    out.element('name', data='org.eclipse.jdt.core.javabuilder')\n    out.element('arguments', data='')\n    out.close('buildCommand')\n    if exists(csConfig):\n        out.open('buildCommand')\n        out.element('name', data='net.sf.eclipsecs.core.CheckstyleBuilder')\n        out.element('arguments', data='')\n        out.close('buildCommand')\n    if exists(join(p.dir, 'plugin.xml')):  # eclipse plugin project\n        for buildCommand in ['org.eclipse.pde.ManifestBuilder', 'org.eclipse.pde.SchemaBuilder']:\n            out.open('buildCommand')\n            out.element('name', data=buildCommand)\n            out.element('arguments', data='')\n            out.close('buildCommand')\n\n    # The path should always be p.name/dir. independent of where the workspace actually is.\n    # So we use the parent folder of the project, whatever that is, to generate such a relative path.\n    logicalWorkspaceRoot = os.path.dirname(p.dir)\n    binFolder = os.path.relpath(p.output_dir(), logicalWorkspaceRoot)\n\n    if _isAnnotationProcessorDependency(p):\n        refreshFile = os.path.relpath(join(p.dir, p.name + '.jar'), logicalWorkspaceRoot)\n        _genEclipseBuilder(out, p, 'Jar', 'archive ' + p.name, refresh=True, refreshFile=refreshFile, relevantResources=[binFolder], async=True, xmlIndent='', xmlStandalone='no')\n\n    out.close('buildSpec')\n    out.open('natures')\n    out.element('nature', data='org.eclipse.jdt.core.javanature')\n    if exists(csConfig):\n        out.element('nature', data='net.sf.eclipsecs.core.CheckstyleNature')\n    if exists(join(p.dir, 'plugin.xml')):  # eclipse plugin project\n        out.element('nature', data='org.eclipse.pde.PluginNature')\n    out.close('natures')\n    out.close('projectDescription')\n    projectFile = join(p.dir, '.project')\n    update_file(projectFile, out.xml(indent='\\t', newl='\\n'))\n    if files:\n        files.append(projectFile)\n\n    settingsDir = join(p.dir, \".settings\")\n    if not exists(settingsDir):\n        os.mkdir(settingsDir)\n\n    # collect the defaults from mxtool\n    defaultEclipseSettingsDir = join(dirname(__file__), 'eclipse-settings')\n    esdict = {}\n    if exists(defaultEclipseSettingsDir):\n        for name in os.listdir(defaultEclipseSettingsDir):\n            if isfile(join(defaultEclipseSettingsDir, name)):\n                esdict[name] = os.path.abspath(join(defaultEclipseSettingsDir, name))\n\n    # check for suite overrides\n    eclipseSettingsDir = join(p.suite.mxDir, 'eclipse-settings')\n    if exists(eclipseSettingsDir):\n        for name in os.listdir(eclipseSettingsDir):\n            if isfile(join(eclipseSettingsDir, name)):\n                esdict[name] = os.path.abspath(join(eclipseSettingsDir, name))\n\n    # check for project overrides\n    projectSettingsDir = join(p.dir, 'eclipse-settings')\n    if exists(projectSettingsDir):\n        for name in os.listdir(projectSettingsDir):\n            if isfile(join(projectSettingsDir, name)):\n                esdict[name] = os.path.abspath(join(projectSettingsDir, name))\n\n    # copy a possibly modified file to the project's .settings directory\n    for name, path in esdict.iteritems():\n        # ignore this file altogether if this project has no annotation processors\n        if name == \"org.eclipse.jdt.apt.core.prefs\" and not len(p.annotation_processors()) > 0:\n            continue\n\n        with open(path) as f:\n            content = f.read()\n        content = content.replace('${javaCompliance}', str(p.javaCompliance))\n        if len(p.annotation_processors()) > 0:\n            content = content.replace('org.eclipse.jdt.core.compiler.processAnnotations=disabled', 'org.eclipse.jdt.core.compiler.processAnnotations=enabled')\n        update_file(join(settingsDir, name), content)\n        if files:\n            files.append(join(settingsDir, name))\n\n    if len(p.annotation_processors()) > 0:\n        out = XMLDoc()\n        out.open('factorypath')\n        out.element('factorypathentry', {'kind' : 'PLUGIN', 'id' : 'org.eclipse.jst.ws.annotations.core', 'enabled' : 'true', 'runInBatchMode' : 'false'})\n        for ap in p.annotation_processors():\n            for dep in dependency(ap).all_deps([], True):\n                if dep.isLibrary():\n                    # Relative paths for \"lib\" class path entries have various semantics depending on the Eclipse\n                    # version being used (e.g. see https://bugs.eclipse.org/bugs/show_bug.cgi?id=274737) so it's\n                    # safest to simply use absolute paths.\n                    path = _make_absolute(dep.get_path(resolve=True), p.suite.dir)\n                    out.element('factorypathentry', {'kind' : 'EXTJAR', 'id' : path, 'enabled' : 'true', 'runInBatchMode' : 'false'})\n                    if files:\n                        files.append(path)\n                elif dep.isProject():\n                    out.element('factorypathentry', {'kind' : 'WKSPJAR', 'id' : '/' + dep.name + '/' + dep.name + '.jar', 'enabled' : 'true', 'runInBatchMode' : 'false'})\n        out.close('factorypath')\n        update_file(join(p.dir, '.factorypath'), out.xml(indent='\\t', newl='\\n'))\n        if files:\n            files.append(join(p.dir, '.factorypath'))\n\ndef _eclipseinit_suite(args, suite, buildProcessorJars=True, refreshOnly=False):\n    configZip = TimeStampFile(join(suite.mxDir, 'eclipse-config.zip'))\n    configLibsZip = join(suite.mxDir, 'eclipse-config-libs.zip')\n    if refreshOnly and not configZip.exists():\n        return\n\n    if _check_ide_timestamp(suite, configZip, 'eclipse'):\n        logv('[Eclipse configurations are up to date - skipping]')\n        return\n\n\n\n    files = []\n    libFiles = []\n    if buildProcessorJars:\n        files += _processorjars_suite(suite)\n\n    projToDist = dict()\n    for dist in _dists.values():\n        distDeps = dist.sorted_deps()\n        for p in distDeps:\n            projToDist[p.name] = (dist, [dep.name for dep in distDeps])\n\n    for p in suite.projects:\n        if p.native:\n            continue\n        _eclipseinit_project(p)\n\n    _, launchFile = make_eclipse_attach(suite, 'localhost', '8000', deps=sorted_deps(projectNames=None, includeLibs=True))\n    files.append(launchFile)\n\n    _zip_files(files, suite.dir, configZip.path)\n    _zip_files(libFiles, suite.dir, configLibsZip)\n\n    # Create an Eclipse project for each distribution that will create/update the archive\n    # for the distribution whenever any project of the distribution is updated.\n    for dist in suite.dists:\n        if hasattr(dist, 'subDir'):\n            projectDir = join(suite.dir, dist.subDir, dist.name + '.dist')\n        else:\n            projectDir = join(suite.dir, dist.name + '.dist')\n        if not exists(projectDir):\n            os.makedirs(projectDir)\n        distProjects = [d for d in dist.sorted_deps() if d.isProject()]\n        relevantResources = []\n        for p in distProjects:\n            for srcDir in p.source_dirs():\n                relevantResources.append(join(p.name, os.path.relpath(srcDir, p.dir)))\n            relevantResources.append(join(p.name, os.path.relpath(p.output_dir(), p.dir)))\n        out = XMLDoc()\n        out.open('projectDescription')\n        out.element('name', data=dist.name)\n        out.element('comment', data='Updates ' + dist.path + ' if a project dependency of ' + dist.name + ' is updated')\n        out.open('projects')\n        for p in distProjects:\n            out.element('project', data=p.name)\n        out.close('projects')\n        out.open('buildSpec')\n        dist.dir = projectDir\n        dist.javaCompliance = max([p.javaCompliance for p in distProjects])\n        _genEclipseBuilder(out, dist, 'Create' + dist.name + 'Dist', 'archive @' + dist.name, relevantResources=relevantResources, logToFile=True, refresh=False, async=True)\n        out.close('buildSpec')\n        out.open('natures')\n        out.element('nature', data='org.eclipse.jdt.core.javanature')\n        out.close('natures')\n        out.close('projectDescription')\n        projectFile = join(projectDir, '.project')\n        update_file(projectFile, out.xml(indent='\\t', newl='\\n'))\n        files.append(projectFile)\n\ndef _zip_files(files, baseDir, zipPath):\n    fd, tmp = tempfile.mkstemp(suffix='', prefix=basename(zipPath), dir=baseDir)\n    try:\n        zf = zipfile.ZipFile(tmp, 'w')\n        for f in sorted(set(files)):\n            relpath = os.path.relpath(f, baseDir)\n            arcname = relpath.replace(os.sep, '/')\n            zf.write(f, arcname)\n        zf.close()\n        os.close(fd)\n        # Atomic on Unix\n        shutil.move(tmp, zipPath)\n        # Correct the permissions on the temporary file which is created with restrictive permissions\n        os.chmod(zipPath, 0o666 & ~currentUmask)\n    finally:\n        if exists(tmp):\n            os.remove(tmp)\n\ndef _isAnnotationProcessorDependency(p):\n    \"\"\"\n    Determines if a given project is part of an annotation processor.\n    \"\"\"\n    return p in sorted_deps(annotation_processors())\n\ndef _genEclipseBuilder(dotProjectDoc, p, name, mxCommand, refresh=True, refreshFile=None, relevantResources=None, async=False, logToConsole=False, logToFile=False, appendToLogFile=True, xmlIndent='\\t', xmlStandalone=None):\n    externalToolDir = join(p.dir, '.externalToolBuilders')\n    launchOut = XMLDoc()\n    consoleOn = 'true' if logToConsole else 'false'\n    launchOut.open('launchConfiguration', {'type' : 'org.eclipse.ui.externaltools.ProgramBuilderLaunchConfigurationType'})\n    launchOut.element('booleanAttribute', {'key' : 'org.eclipse.debug.core.capture_output', 'value': consoleOn})\n    launchOut.open('mapAttribute', {'key' : 'org.eclipse.debug.core.environmentVariables'})\n    launchOut.element('mapEntry', {'key' : 'JAVA_HOME', 'value' : java(p.javaCompliance).jdk})\n    launchOut.element('mapEntry', {'key' : 'EXTRA_JAVA_HOMES', 'value' : _opts.extra_java_homes})\n    launchOut.close('mapAttribute')\n\n    if refresh:\n        if refreshFile is None:\n            refreshScope = '${project}'\n        else:\n            refreshScope = '${working_set:<?xml version=\"1.0\" encoding=\"UTF-8\"?><resources><item path=\"' + refreshFile + '\" type=\"1\"/></resources>}'\n\n        launchOut.element('booleanAttribute', {'key' : 'org.eclipse.debug.core.ATTR_REFRESH_RECURSIVE', 'value':  'false'})\n        launchOut.element('stringAttribute', {'key' : 'org.eclipse.debug.core.ATTR_REFRESH_SCOPE', 'value':  refreshScope})\n\n    if relevantResources is not None:\n        resources = '${working_set:<?xml version=\"1.0\" encoding=\"UTF-8\"?><resources>'\n        for relevantResource in relevantResources:\n            resources += '<item path=\"' + relevantResource + '\" type=\"2\" />'\n        resources += '</resources>}'\n        launchOut.element('stringAttribute', {'key' : 'org.eclipse.ui.externaltools.ATTR_BUILD_SCOPE', 'value': resources})\n\n\n    launchOut.element('booleanAttribute', {'key' : 'org.eclipse.debug.ui.ATTR_CONSOLE_OUTPUT_ON', 'value': consoleOn})\n    launchOut.element('booleanAttribute', {'key' : 'org.eclipse.debug.ui.ATTR_LAUNCH_IN_BACKGROUND', 'value': 'true' if async else 'false'})\n    if logToFile:\n        logFile = join(externalToolDir, name + '.log')\n        launchOut.element('stringAttribute', {'key' : 'org.eclipse.debug.ui.ATTR_CAPTURE_IN_FILE', 'value': logFile})\n        launchOut.element('booleanAttribute', {'key' : 'org.eclipse.debug.ui.ATTR_APPEND_TO_FILE', 'value': 'true' if appendToLogFile else 'false'})\n\n    # expect to find the OS command to invoke mx in the same directory\n    baseDir = dirname(os.path.abspath(__file__))\n\n    cmd = 'mx.sh'\n    if get_os() == 'windows':\n        cmd = 'mx.cmd'\n    cmdPath = join(baseDir, cmd)\n    if not os.path.exists(cmdPath):\n        # backwards compatibility for when the commands lived in parent of mxtool\n        cmdPath = join(dirname(baseDir), cmd)\n        if not os.path.exists(cmdPath):\n            abort('cannot locate ' + cmd)\n\n    launchOut.element('stringAttribute', {'key' : 'org.eclipse.ui.externaltools.ATTR_LOCATION', 'value':  cmdPath})\n    launchOut.element('stringAttribute', {'key' : 'org.eclipse.ui.externaltools.ATTR_RUN_BUILD_KINDS', 'value': 'full,incremental,auto,'})\n    launchOut.element('stringAttribute', {'key' : 'org.eclipse.ui.externaltools.ATTR_TOOL_ARGUMENTS', 'value': mxCommand})\n    launchOut.element('booleanAttribute', {'key' : 'org.eclipse.ui.externaltools.ATTR_TRIGGERS_CONFIGURED', 'value': 'true'})\n    launchOut.element('stringAttribute', {'key' : 'org.eclipse.ui.externaltools.ATTR_WORKING_DIRECTORY', 'value': p.suite.dir})\n\n\n    launchOut.close('launchConfiguration')\n\n    if not exists(externalToolDir):\n        os.makedirs(externalToolDir)\n    update_file(join(externalToolDir, name + '.launch'), launchOut.xml(indent=xmlIndent, standalone=xmlStandalone, newl='\\n'))\n\n    dotProjectDoc.open('buildCommand')\n    dotProjectDoc.element('name', data='org.eclipse.ui.externaltools.ExternalToolBuilder')\n    dotProjectDoc.element('triggers', data='auto,full,incremental,')\n    dotProjectDoc.open('arguments')\n    dotProjectDoc.open('dictionary')\n    dotProjectDoc.element('key', data='LaunchConfigHandle')\n    dotProjectDoc.element('value', data='<project>/.externalToolBuilders/' + name + '.launch')\n    dotProjectDoc.close('dictionary')\n    dotProjectDoc.open('dictionary')\n    dotProjectDoc.element('key', data='incclean')\n    dotProjectDoc.element('value', data='true')\n    dotProjectDoc.close('dictionary')\n    dotProjectDoc.close('arguments')\n    dotProjectDoc.close('buildCommand')\n\ndef generate_eclipse_workingsets():\n    \"\"\"\n    Populate the workspace's working set configuration with working sets generated from project data for the primary suite\n    If the workspace already contains working set definitions, the existing ones will be retained and extended.\n    In case mx/env does not contain a WORKSPACE definition pointing to the workspace root directory, a parent search from the primary suite directory is performed.\n    If no workspace root directory can be identified, the primary suite directory is used and the user has to place the workingsets.xml file by hand.\n    \"\"\"\n\n    # identify the location where to look for workingsets.xml\n    wsfilename = 'workingsets.xml'\n    wsloc = '.metadata/.plugins/org.eclipse.ui.workbench'\n    if os.environ.has_key('WORKSPACE'):\n        expected_wsroot = os.environ['WORKSPACE']\n    else:\n        expected_wsroot = _primary_suite.dir\n\n    wsroot = _find_eclipse_wsroot(expected_wsroot)\n    if wsroot is None:\n        # failed to find it\n        wsroot = expected_wsroot\n\n    wsdir = join(wsroot, wsloc)\n    if not exists(wsdir):\n        wsdir = wsroot\n        logv('Could not find Eclipse metadata directory. Please place ' + wsfilename + ' in ' + wsloc + ' manually.')\n    wspath = join(wsdir, wsfilename)\n\n    # gather working set info from project data\n    workingSets = dict()\n    for p in projects():\n        if p.workingSets is None:\n            continue\n        for w in p.workingSets.split(\",\"):\n            if not workingSets.has_key(w):\n                workingSets[w] = [p.name]\n            else:\n                workingSets[w].append(p.name)\n\n    if exists(wspath):\n        wsdoc = _copy_workingset_xml(wspath, workingSets)\n    else:\n        wsdoc = _make_workingset_xml(workingSets)\n\n    update_file(wspath, wsdoc.xml(newl='\\n'))\n\ndef _find_eclipse_wsroot(wsdir):\n    md = join(wsdir, '.metadata')\n    if exists(md):\n        return wsdir\n    split = os.path.split(wsdir)\n    if split[0] == wsdir:  # root directory\n        return None\n    else:\n        return _find_eclipse_wsroot(split[0])\n\ndef _make_workingset_xml(workingSets):\n    wsdoc = XMLDoc()\n    wsdoc.open('workingSetManager')\n\n    for w in sorted(workingSets.keys()):\n        _workingset_open(wsdoc, w)\n        for p in workingSets[w]:\n            _workingset_element(wsdoc, p)\n        wsdoc.close('workingSet')\n\n    wsdoc.close('workingSetManager')\n    return wsdoc\n\ndef _copy_workingset_xml(wspath, workingSets):\n    target = XMLDoc()\n    target.open('workingSetManager')\n\n    parser = xml.parsers.expat.ParserCreate()\n\n    class ParserState(object):\n        def __init__(self):\n            self.current_ws_name = 'none yet'\n            self.current_ws = None\n            self.seen_ws = list()\n            self.seen_projects = list()\n            self.aggregate_ws = False\n            self.nested_ws = False\n\n    ps = ParserState()\n\n    # parsing logic\n    def _ws_start(name, attributes):\n        if name == 'workingSet':\n            if attributes.has_key('name'):\n                ps.current_ws_name = attributes['name']\n                if attributes.has_key('aggregate') and attributes['aggregate'] == 'true':\n                    ps.aggregate_ws = True\n                    ps.current_ws = None\n                elif workingSets.has_key(ps.current_ws_name):\n                    ps.current_ws = workingSets[ps.current_ws_name]\n                    ps.seen_ws.append(ps.current_ws_name)\n                    ps.seen_projects = list()\n                else:\n                    ps.current_ws = None\n            target.open(name, attributes)\n            parser.StartElementHandler = _ws_item\n\n    def _ws_end(name):\n        closeAndResetHandler = False\n        if name == 'workingSet':\n            if ps.aggregate_ws:\n                if ps.nested_ws:\n                    ps.nested_ws = False\n                else:\n                    ps.aggregate_ws = False\n                    closeAndResetHandler = True\n            else:\n                if not ps.current_ws is None:\n                    for p in ps.current_ws:\n                        if not p in ps.seen_projects:\n                            _workingset_element(target, p)\n                closeAndResetHandler = True\n            if closeAndResetHandler:\n                target.close('workingSet')\n                parser.StartElementHandler = _ws_start\n        elif name == 'workingSetManager':\n            # process all working sets that are new to the file\n            for w in sorted(workingSets.keys()):\n                if not w in ps.seen_ws:\n                    _workingset_open(target, w)\n                    for p in workingSets[w]:\n                        _workingset_element(target, p)\n                    target.close('workingSet')\n\n    def _ws_item(name, attributes):\n        if name == 'item':\n            if ps.current_ws is None:\n                target.element(name, attributes)\n            elif not attributes.has_key('elementID') and attributes.has_key('factoryID') and attributes.has_key('path') and attributes.has_key('type'):\n                target.element(name, attributes)\n                p_name = attributes['path'][1:]  # strip off the leading '/'\n                ps.seen_projects.append(p_name)\n            else:\n                p_name = attributes['elementID'][1:]  # strip off the leading '='\n                _workingset_element(target, p_name)\n                ps.seen_projects.append(p_name)\n        elif name == 'workingSet':\n            ps.nested_ws = True\n            target.element(name, attributes)\n\n    # process document\n    parser.StartElementHandler = _ws_start\n    parser.EndElementHandler = _ws_end\n    with open(wspath, 'r') as wsfile:\n        parser.ParseFile(wsfile)\n\n    target.close('workingSetManager')\n    return target\n\ndef _workingset_open(wsdoc, ws):\n    wsdoc.open('workingSet', {'editPageID': 'org.eclipse.jdt.ui.JavaWorkingSetPage', 'factoryID': 'org.eclipse.ui.internal.WorkingSetFactory', 'id': 'wsid_' + ws, 'label': ws, 'name': ws})\n\ndef _workingset_element(wsdoc, p):\n    wsdoc.element('item', {'elementID': '=' + p, 'factoryID': 'org.eclipse.jdt.ui.PersistableJavaElementFactory'})\n\ndef netbeansinit(args, refreshOnly=False, buildProcessorJars=True):\n    \"\"\"(re)generate NetBeans project configurations\"\"\"\n\n    for suite in suites(True):\n        _netbeansinit_suite(args, suite, refreshOnly, buildProcessorJars)\n\ndef _netbeansinit_suite(args, suite, refreshOnly=False, buildProcessorJars=True):\n    configZip = TimeStampFile(join(suite.mxDir, 'netbeans-config.zip'))\n    configLibsZip = join(suite.mxDir, 'eclipse-config-libs.zip')\n    if refreshOnly and not configZip.exists():\n        return\n\n    if _check_ide_timestamp(suite, configZip, 'netbeans'):\n        logv('[NetBeans configurations are up to date - skipping]')\n        return\n\n    updated = False\n    files = []\n    libFiles = []\n    jdks = set()\n    for p in suite.projects:\n        if p.native:\n            continue\n\n        if exists(join(p.dir, 'plugin.xml')):  # eclipse plugin project\n            continue\n\n        if not exists(join(p.dir, 'nbproject')):\n            os.makedirs(join(p.dir, 'nbproject'))\n\n        jdk = java(p.javaCompliance)\n        assert jdk\n\n        jdks.add(jdk)\n\n        out = XMLDoc()\n        out.open('project', {'name' : p.name, 'default' : 'default', 'basedir' : '.'})\n        out.element('description', data='Builds, tests, and runs the project ' + p.name + '.')\n        out.element('import', {'file' : 'nbproject/build-impl.xml'})\n        out.open('target', {'name' : '-post-compile'})\n        out.open('exec', {'executable' : sys.executable})\n        out.element('env', {'key' : 'JAVA_HOME', 'value' : jdk.jdk})\n        out.element('arg', {'value' : os.path.abspath(__file__)})\n        out.element('arg', {'value' : 'archive'})\n        out.element('arg', {'value' : '@GRAAL'})\n        out.close('exec')\n        out.close('target')\n        out.close('project')\n        updated = update_file(join(p.dir, 'build.xml'), out.xml(indent='\\t', newl='\\n')) or updated\n        files.append(join(p.dir, 'build.xml'))\n\n        out = XMLDoc()\n        out.open('project', {'xmlns' : 'http://www.netbeans.org/ns/project/1'})\n        out.element('type', data='org.netbeans.modules.java.j2seproject')\n        out.open('configuration')\n        out.open('data', {'xmlns' : 'http://www.netbeans.org/ns/j2se-project/3'})\n        out.element('name', data=p.name)\n        out.element('explicit-platform', {'explicit-source-supported' : 'true'})\n        out.open('source-roots')\n        out.element('root', {'id' : 'src.dir'})\n        if len(p.annotation_processors()) > 0:\n            out.element('root', {'id' : 'src.ap-source-output.dir'})\n        out.close('source-roots')\n        out.open('test-roots')\n        out.close('test-roots')\n        out.close('data')\n\n        firstDep = True\n        for dep in p.all_deps([], True):\n            if dep == p:\n                continue\n\n            if dep.isProject():\n                n = dep.name.replace('.', '_')\n                if firstDep:\n                    out.open('references', {'xmlns' : 'http://www.netbeans.org/ns/ant-project-references/1'})\n                    firstDep = False\n\n                out.open('reference')\n                out.element('foreign-project', data=n)\n                out.element('artifact-type', data='jar')\n                out.element('script', data='build.xml')\n                out.element('target', data='jar')\n                out.element('clean-target', data='clean')\n                out.element('id', data='jar')\n                out.close('reference')\n\n        if not firstDep:\n            out.close('references')\n\n        out.close('configuration')\n        out.close('project')\n        updated = update_file(join(p.dir, 'nbproject', 'project.xml'), out.xml(indent='    ', newl='\\n')) or updated\n        files.append(join(p.dir, 'nbproject', 'project.xml'))\n\n        out = StringIO.StringIO()\n        jdkPlatform = 'JDK_' + str(jdk.version)\n\n        annotationProcessorEnabled = \"false\"\n        annotationProcessorReferences = \"\"\n        annotationProcessorSrcFolder = \"\"\n        if len(p.annotation_processors()) > 0:\n            annotationProcessorEnabled = \"true\"\n            annotationProcessorSrcFolder = \"src.ap-source-output.dir=${build.generated.sources.dir}/ap-source-output\"\n\n        content = \"\"\"\nannotation.processing.enabled=\"\"\" + annotationProcessorEnabled + \"\"\"\nannotation.processing.enabled.in.editor=\"\"\" + annotationProcessorEnabled + \"\"\"\nannotation.processing.processors.list=\nannotation.processing.run.all.processors=true\napplication.title=\"\"\" + p.name + \"\"\"\napplication.vendor=mx\nbuild.classes.dir=${build.dir}\nbuild.classes.excludes=**/*.java,**/*.form\n# This directory is removed when the project is cleaned:\nbuild.dir=bin\nbuild.generated.dir=${build.dir}/generated\nbuild.generated.sources.dir=${build.dir}/generated-sources\n# Only compile against the classpath explicitly listed here:\nbuild.sysclasspath=ignore\nbuild.test.classes.dir=${build.dir}/test/classes\nbuild.test.results.dir=${build.dir}/test/results\n# Uncomment to specify the preferred debugger connection transport:\n#debug.transport=dt_socket\ndebug.classpath=\\\\\n    ${run.classpath}\ndebug.test.classpath=\\\\\n    ${run.test.classpath}\n# This directory is removed when the project is cleaned:\ndist.dir=dist\ndist.jar=${dist.dir}/\"\"\" + p.name + \"\"\".jar\ndist.javadoc.dir=${dist.dir}/javadoc\nendorsed.classpath=\nexcludes=\nincludes=**\njar.compress=false\n# Space-separated list of extra javac options\njavac.compilerargs=\njavac.deprecation=false\njavac.source=1.7\njavac.target=1.7\njavac.test.classpath=\\\\\n    ${javac.classpath}:\\\\\n    ${build.classes.dir}\njavadoc.additionalparam=\njavadoc.author=false\njavadoc.encoding=${source.encoding}\njavadoc.noindex=false\njavadoc.nonavbar=false\njavadoc.notree=false\njavadoc.private=false\njavadoc.splitindex=true\njavadoc.use=true\njavadoc.version=false\njavadoc.windowtitle=\nmain.class=\nmanifest.file=manifest.mf\nmeta.inf.dir=${src.dir}/META-INF\nmkdist.disabled=false\nplatforms.\"\"\" + jdkPlatform + \"\"\".home=\"\"\" + jdk.jdk + \"\"\"\nplatform.active=\"\"\" + jdkPlatform + \"\"\"\nrun.classpath=\\\\\n    ${javac.classpath}:\\\\\n    ${build.classes.dir}\n# Space-separated list of JVM arguments used when running the project\n# (you may also define separate properties like run-sys-prop.name=value instead of -Dname=value\n# or test-sys-prop.name=value to set system properties for unit tests):\nrun.jvmargs=\nrun.test.classpath=\\\\\n    ${javac.test.classpath}:\\\\\n    ${build.test.classes.dir}\ntest.src.dir=./test\n\"\"\" + annotationProcessorSrcFolder + \"\"\"\nsource.encoding=UTF-8\"\"\".replace(':', os.pathsep).replace('/', os.sep)\n        print >> out, content\n\n        mainSrc = True\n        for src in p.srcDirs:\n            srcDir = join(p.dir, src)\n            if not exists(srcDir):\n                os.mkdir(srcDir)\n            ref = 'file.reference.' + p.name + '-' + src\n            print >> out, ref + '=' + src\n            if mainSrc:\n                print >> out, 'src.dir=${' + ref + '}'\n                mainSrc = False\n            else:\n                print >> out, 'src.' + src + '.dir=${' + ref + '}'\n\n        javacClasspath = []\n\n        deps = p.all_deps([], True)\n        annotationProcessorOnlyDeps = []\n        if len(p.annotation_processors()) > 0:\n            for ap in p.annotation_processors():\n                apDep = dependency(ap)\n                if not apDep in deps:\n                    deps.append(apDep)\n                    annotationProcessorOnlyDeps.append(apDep)\n\n        annotationProcessorReferences = []\n\n        for dep in deps:\n            if dep == p:\n                continue\n\n            if dep.isLibrary():\n                path = dep.get_path(resolve=True)\n                if path:\n                    if os.sep == '\\\\':\n                        path = path.replace('\\\\', '\\\\\\\\')\n                    ref = 'file.reference.' + dep.name + '-bin'\n                    print >> out, ref + '=' + path\n                    libFiles.append(path)\n\n            elif dep.isProject():\n                n = dep.name.replace('.', '_')\n                relDepPath = os.path.relpath(dep.dir, p.dir).replace(os.sep, '/')\n                ref = 'reference.' + n + '.jar'\n                print >> out, 'project.' + n + '=' + relDepPath\n                print >> out, ref + '=${project.' + n + '}/dist/' + dep.name + '.jar'\n\n            if not dep in annotationProcessorOnlyDeps:\n                javacClasspath.append('${' + ref + '}')\n            else:\n                annotationProcessorReferences.append('${' + ref + '}')\n\n        print >> out, 'javac.classpath=\\\\\\n    ' + (os.pathsep + '\\\\\\n    ').join(javacClasspath)\n        print >> out, 'javac.processorpath=' + (os.pathsep + '\\\\\\n    ').join(['${javac.classpath}'] + annotationProcessorReferences)\n        print >> out, 'javac.test.processorpath=' + (os.pathsep + '\\\\\\n    ').join(['${javac.test.classpath}'] + annotationProcessorReferences)\n\n        updated = update_file(join(p.dir, 'nbproject', 'project.properties'), out.getvalue()) or updated\n        out.close()\n        files.append(join(p.dir, 'nbproject', 'project.properties'))\n\n    if updated:\n        log('If using NetBeans:')\n        log('  1. Ensure that the following platform(s) are defined (Tools -> Java Platforms):')\n        for jdk in jdks:\n            log('        JDK_' + str(jdk.version))\n        log('  2. Open/create a Project Group for the directory containing the projects (File -> Project Group -> New Group... -> Folder of Projects)')\n\n    _zip_files(files, suite.dir, configZip.path)\n    _zip_files(libFiles, suite.dir, configLibsZip)\n\ndef intellijinit(args, refreshOnly=False):\n    \"\"\"(re)generate Intellij project configurations\"\"\"\n\n    for suite in suites(True):\n        _intellij_suite(args, suite, refreshOnly)\n\ndef _intellij_suite(args, suite, refreshOnly=False):\n\n    libraries = set()\n\n    ideaProjectDirectory = join(suite.dir, '.idea')\n\n    if not exists(ideaProjectDirectory):\n        os.mkdir(ideaProjectDirectory)\n    nameFile = join(ideaProjectDirectory, '.name')\n    update_file(nameFile, \"Graal\")\n    modulesXml = XMLDoc()\n    modulesXml.open('project', attributes={'version': '4'})\n    modulesXml.open('component', attributes={'name': 'ProjectModuleManager'})\n    modulesXml.open('modules')\n\n\n    def _intellij_exclude_if_exists(xml, p, name):\n        path = join(p.dir, name)\n        if exists(path):\n            xml.element('excludeFolder', attributes={'url':'file://$MODULE_DIR$/' + name})\n\n    annotationProcessorProfiles = {}\n\n    def _complianceToIntellijLanguageLevel(compliance):\n        return 'JDK_1_' + str(compliance.value)\n\n    # create the modules (1 module  = 1 Intellij project)\n    for p in suite.projects:\n        if p.native:\n            continue\n\n        assert java(p.javaCompliance)\n\n        if not exists(p.dir):\n            os.makedirs(p.dir)\n\n        annotationProcessorProfileKey = tuple(p.annotation_processors())\n\n        if not annotationProcessorProfileKey in annotationProcessorProfiles:\n            annotationProcessorProfiles[annotationProcessorProfileKey] = [p]\n        else:\n            annotationProcessorProfiles[annotationProcessorProfileKey].append(p)\n\n        intellijLanguageLevel = _complianceToIntellijLanguageLevel(p.javaCompliance)\n\n        moduleXml = XMLDoc()\n        moduleXml.open('module', attributes={'type': 'JAVA_MODULE', 'version': '4'})\n\n        moduleXml.open('component', attributes={'name': 'NewModuleRootManager', 'LANGUAGE_LEVEL': intellijLanguageLevel, 'inherit-compiler-output': 'false'})\n        moduleXml.element('output', attributes={'url': 'file://$MODULE_DIR$/bin'})\n        moduleXml.element('exclude-output')\n\n        moduleXml.open('content', attributes={'url': 'file://$MODULE_DIR$'})\n        for src in p.srcDirs:\n            srcDir = join(p.dir, src)\n            if not exists(srcDir):\n                os.mkdir(srcDir)\n            moduleXml.element('sourceFolder', attributes={'url':'file://$MODULE_DIR$/' + src, 'isTestSource': 'false'})\n\n        if len(p.annotation_processors()) > 0:\n            genDir = p.source_gen_dir()\n            if not exists(genDir):\n                os.mkdir(genDir)\n            moduleXml.element('sourceFolder', attributes={'url':'file://$MODULE_DIR$/' + os.path.relpath(genDir, p.dir), 'isTestSource': 'false'})\n\n        for name in ['.externalToolBuilders', '.settings', 'nbproject']:\n            _intellij_exclude_if_exists(moduleXml, p, name)\n        moduleXml.close('content')\n\n        moduleXml.element('orderEntry', attributes={'type': 'jdk', 'jdkType': 'JavaSDK', 'jdkName': str(p.javaCompliance)})\n        moduleXml.element('orderEntry', attributes={'type': 'sourceFolder', 'forTests': 'false'})\n\n        deps = p.all_deps([], True, includeAnnotationProcessors=True)\n        for dep in deps:\n            if dep == p:\n                continue\n\n            if dep.isLibrary():\n                libraries.add(dep)\n                moduleXml.element('orderEntry', attributes={'type': 'library', 'name': dep.name, 'level': 'project'})\n            elif dep.isProject():\n                moduleXml.element('orderEntry', attributes={'type': 'module', 'module-name': dep.name})\n\n        moduleXml.close('component')\n        moduleXml.close('module')\n        moduleFile = join(p.dir, p.name + '.iml')\n        update_file(moduleFile, moduleXml.xml(indent='  ', newl='\\n'))\n\n        moduleFilePath = \"$PROJECT_DIR$/\" + os.path.relpath(moduleFile, suite.dir)\n        modulesXml.element('module', attributes={'fileurl': 'file://' + moduleFilePath, 'filepath': moduleFilePath})\n\n    modulesXml.close('modules')\n    modulesXml.close('component')\n    modulesXml.close('project')\n    moduleXmlFile = join(ideaProjectDirectory, 'modules.xml')\n    update_file(moduleXmlFile, modulesXml.xml(indent='  ', newl='\\n'))\n\n    # TODO What about cross-suite dependencies?\n\n    librariesDirectory = join(ideaProjectDirectory, 'libraries')\n\n    if not exists(librariesDirectory):\n        os.mkdir(librariesDirectory)\n\n    # Setup the libraries that were used above\n    # TODO: setup all the libraries from the suite regardless of usage?\n    for library in libraries:\n        libraryXml = XMLDoc()\n\n        libraryXml.open('component', attributes={'name': 'libraryTable'})\n        libraryXml.open('library', attributes={'name': library.name})\n        libraryXml.open('CLASSES')\n        libraryXml.element('root', attributes={'url': 'jar://$PROJECT_DIR$/' + os.path.relpath(library.get_path(True), suite.dir) + '!/'})\n        libraryXml.close('CLASSES')\n        libraryXml.element('JAVADOC')\n        if library.sourcePath:\n            libraryXml.open('SOURCES')\n            libraryXml.element('root', attributes={'url': 'jar://$PROJECT_DIR$/' + os.path.relpath(library.get_source_path(True), suite.dir) + '!/'})\n            libraryXml.close('SOURCES')\n        else:\n            libraryXml.element('SOURCES')\n        libraryXml.close('library')\n        libraryXml.close('component')\n\n        libraryFile = join(librariesDirectory, library.name + '.xml')\n        update_file(libraryFile, libraryXml.xml(indent='  ', newl='\\n'))\n\n\n\n    # Set annotation processor profiles up, and link them to modules in compiler.xml\n    compilerXml = XMLDoc()\n    compilerXml.open('project', attributes={'version': '4'})\n    compilerXml.open('component', attributes={'name': 'CompilerConfiguration'})\n\n    compilerXml.element('option', attributes={'name': \"DEFAULT_COMPILER\", 'value': 'Javac'})\n    compilerXml.element('resourceExtensions')\n    compilerXml.open('wildcardResourcePatterns')\n    compilerXml.element('entry', attributes={'name': '!?*.java'})\n    compilerXml.close('wildcardResourcePatterns')\n\n    if annotationProcessorProfiles:\n        compilerXml.open('annotationProcessing')\n        for processors, modules in annotationProcessorProfiles.items():\n            compilerXml.open('profile', attributes={'default': 'false', 'name': '-'.join(processors), 'enabled': 'true'})\n            compilerXml.element('sourceOutputDir', attributes={'name': 'src_gen'})  # TODO use p.source_gen_dir() ?\n            compilerXml.element('outputRelativeToContentRoot', attributes={'value': 'true'})\n            compilerXml.open('processorPath', attributes={'useClasspath': 'false'})\n            for apName in processors:\n                pDep = dependency(apName)\n                for entry in pDep.all_deps([], True):\n                    if entry.isLibrary():\n                        compilerXml.element('entry', attributes={'name': '$PROJECT_DIR$/' + os.path.relpath(entry.path, suite.dir)})\n                    elif entry.isProject():\n                        assert entry.isProject()\n                        compilerXml.element('entry', attributes={'name': '$PROJECT_DIR$/' + os.path.relpath(entry.output_dir(), suite.dir)})\n            compilerXml.close('processorPath')\n            for module in modules:\n                compilerXml.element('module', attributes={'name': module.name})\n            compilerXml.close('profile')\n        compilerXml.close('annotationProcessing')\n\n    compilerXml.close('component')\n    compilerXml.close('project')\n    compilerFile = join(ideaProjectDirectory, 'compiler.xml')\n    update_file(compilerFile, compilerXml.xml(indent='  ', newl='\\n'))\n\n    # Wite misc.xml for global JDK config\n    miscXml = XMLDoc()\n    miscXml.open('project', attributes={'version': '4'})\n    miscXml.element('component', attributes={'name': 'ProjectRootManager', 'version': '2', 'languageLevel': _complianceToIntellijLanguageLevel(java().javaCompliance), 'project-jdk-name': str(java().javaCompliance), 'project-jdk-type': 'JavaSDK'})\n    miscXml.close('project')\n    miscFile = join(ideaProjectDirectory, 'misc.xml')\n    update_file(miscFile, miscXml.xml(indent='  ', newl='\\n'))\n\n\n    # TODO look into copyright settings\n    # TODO should add vcs.xml support\n\ndef ideclean(args):\n    \"\"\"remove all Eclipse and NetBeans project configurations\"\"\"\n    def rm(path):\n        if exists(path):\n            os.remove(path)\n\n    for s in suites():\n        rm(join(s.mxDir, 'eclipse-config.zip'))\n        rm(join(s.mxDir, 'netbeans-config.zip'))\n        shutil.rmtree(join(s.dir, '.idea'), ignore_errors=True)\n\n    for p in projects():\n        if p.native:\n            continue\n\n        shutil.rmtree(join(p.dir, '.settings'), ignore_errors=True)\n        shutil.rmtree(join(p.dir, '.externalToolBuilders'), ignore_errors=True)\n        shutil.rmtree(join(p.dir, 'nbproject'), ignore_errors=True)\n        rm(join(p.dir, '.classpath'))\n        rm(join(p.dir, '.checkstyle'))\n        rm(join(p.dir, '.project'))\n        rm(join(p.dir, '.factorypath'))\n        rm(join(p.dir, p.name + '.iml'))\n        rm(join(p.dir, 'build.xml'))\n        rm(join(p.dir, 'eclipse-build.xml'))\n        try:\n            rm(join(p.dir, p.name + '.jar'))\n        except:\n            log(\"Error removing {0}\".format(p.name + '.jar'))\n\n\ndef ideinit(args, refreshOnly=False, buildProcessorJars=True):\n    \"\"\"(re)generate Eclipse, NetBeans and Intellij project configurations\"\"\"\n    eclipseinit(args, refreshOnly=refreshOnly, buildProcessorJars=buildProcessorJars)\n    netbeansinit(args, refreshOnly=refreshOnly, buildProcessorJars=buildProcessorJars)\n    intellijinit(args, refreshOnly=refreshOnly)\n    if not refreshOnly:\n        fsckprojects([])\n\ndef fsckprojects(args):\n    \"\"\"find directories corresponding to deleted Java projects and delete them\"\"\"\n    for suite in suites(True):\n        projectDirs = [p.dir for p in suite.projects]\n        for dirpath, dirnames, files in os.walk(suite.dir):\n            if dirpath == suite.dir:\n                # no point in traversing .hg or lib/\n                dirnames[:] = [d for d in dirnames if d not in ['.hg', 'lib']]\n            elif dirpath in projectDirs:\n                # don't traverse subdirs of an existing project in this suite\n                dirnames[:] = []\n            else:\n                projectConfigFiles = frozenset(['.classpath', 'nbproject'])\n                indicators = projectConfigFiles.intersection(files)\n                if len(indicators) != 0:\n                    if not sys.stdout.isatty() or ask_yes_no(dirpath + ' looks like a removed project -- delete it', 'n'):\n                        shutil.rmtree(dirpath)\n                        log('Deleted ' + dirpath)\n\ndef javadoc(args, parser=None, docDir='javadoc', includeDeps=True, stdDoclet=True):\n    \"\"\"generate javadoc for some/all Java projects\"\"\"\n\n    parser = ArgumentParser(prog='mx javadoc') if parser is None else parser\n    parser.add_argument('-d', '--base', action='store', help='base directory for output')\n    parser.add_argument('--unified', action='store_true', help='put javadoc in a single directory instead of one per project')\n    parser.add_argument('--force', action='store_true', help='(re)generate javadoc even if package-list file exists')\n    parser.add_argument('--projects', action='store', help='comma separated projects to process (omit to process all projects)')\n    parser.add_argument('--Wapi', action='store_true', dest='warnAPI', help='show warnings about using internal APIs')\n    parser.add_argument('--argfile', action='store', help='name of file containing extra javadoc options')\n    parser.add_argument('--arg', action='append', dest='extra_args', help='extra Javadoc arguments (e.g. --arg @-use)', metavar='@<arg>', default=[])\n    parser.add_argument('-m', '--memory', action='store', help='-Xmx value to pass to underlying JVM')\n    parser.add_argument('--packages', action='store', help='comma separated packages to process (omit to process all packages)')\n    parser.add_argument('--exclude-packages', action='store', help='comma separated packages to exclude')\n\n    args = parser.parse_args(args)\n\n    # build list of projects to be processed\n    if args.projects is not None:\n        candidates = [project(name) for name in args.projects.split(',')]\n    else:\n        candidates = projects_opt_limit_to_suites()\n\n    # optionally restrict packages within a project\n    packages = []\n    if args.packages is not None:\n        packages = [name for name in args.packages.split(',')]\n\n    exclude_packages = []\n    if args.exclude_packages is not None:\n        exclude_packages = [name for name in args.exclude_packages.split(',')]\n\n    def outDir(p):\n        if args.base is None:\n            return join(p.dir, docDir)\n        return join(args.base, p.name, docDir)\n\n    def check_package_list(p):\n        return not exists(join(outDir(p), 'package-list'))\n\n    def assess_candidate(p, projects):\n        if p in projects:\n            return False\n        if args.force or args.unified or check_package_list(p):\n            projects.append(p)\n            return True\n        return False\n\n    projects = []\n    for p in candidates:\n        if not p.native:\n            if includeDeps:\n                deps = p.all_deps([], includeLibs=False, includeSelf=False)\n                for d in deps:\n                    assess_candidate(d, projects)\n            if not assess_candidate(p, projects):\n                logv('[package-list file exists - skipping {0}]'.format(p.name))\n\n\n    def find_packages(sourceDirs, pkgs=None):\n        if pkgs is None:\n            pkgs = set()\n        for sourceDir in sourceDirs:\n            for root, _, files in os.walk(sourceDir):\n                if len([name for name in files if name.endswith('.java')]) != 0:\n                    pkg = root[len(sourceDir) + 1:].replace(os.sep, '.')\n                    if len(packages) == 0 or pkg in packages:\n                        if len(exclude_packages) == 0 or not pkg in exclude_packages:\n                            pkgs.add(pkg)\n        return pkgs\n\n    extraArgs = [a.lstrip('@') for a in args.extra_args]\n    if args.argfile is not None:\n        extraArgs += ['@' + args.argfile]\n    memory = '2g'\n    if args.memory is not None:\n        memory = args.memory\n    memory = '-J-Xmx' + memory\n\n    if not args.unified:\n        for p in projects:\n            # The project must be built to ensure javadoc can find class files for all referenced classes\n            build(['--no-native', '--projects', p.name])\n\n            pkgs = find_packages(p.source_dirs(), set())\n            deps = p.all_deps([], includeLibs=False, includeSelf=False)\n            links = ['-link', 'http://docs.oracle.com/javase/' + str(p.javaCompliance.value) + '/docs/api/']\n            out = outDir(p)\n            for d in deps:\n                depOut = outDir(d)\n                links.append('-link')\n                links.append(os.path.relpath(depOut, out))\n            cp = classpath(p.name, includeSelf=True)\n            sp = os.pathsep.join(p.source_dirs())\n            overviewFile = join(p.dir, 'overview.html')\n            delOverviewFile = False\n            if not exists(overviewFile):\n                with open(overviewFile, 'w') as fp:\n                    print >> fp, '<html><body>Documentation for the <code>' + p.name + '</code> project.</body></html>'\n                delOverviewFile = True\n            nowarnAPI = []\n            if not args.warnAPI:\n                nowarnAPI.append('-XDignore.symbol.file')\n\n            # windowTitle onloy applies to the standard doclet processor\n            windowTitle = []\n            if stdDoclet:\n                windowTitle = ['-windowtitle', p.name + ' javadoc']\n            try:\n                log('Generating {2} for {0} in {1}'.format(p.name, out, docDir))\n                projectJava = java(p.javaCompliance)\n\n                # Once https://bugs.openjdk.java.net/browse/JDK-8041628 is fixed,\n                # this should be reverted to:\n                # javadocExe = java().javadoc\n                javadocExe = projectJava.javadoc\n\n                run([javadocExe, memory,\n                     '-XDignore.symbol.file',\n                     '-classpath', cp,\n                     '-quiet',\n                     '-d', out,\n                     '-overview', overviewFile,\n                     '-sourcepath', sp,\n                     '-source', str(projectJava.javaCompliance),\n                     '-bootclasspath', projectJava.bootclasspath(),\n                     '-extdirs', projectJava.extdirs()] +\n                     ([] if projectJava.javaCompliance < JavaCompliance('1.8') else ['-Xdoclint:none']) +\n                     links +\n                     extraArgs +\n                     nowarnAPI +\n                     windowTitle +\n                     list(pkgs))\n                log('Generated {2} for {0} in {1}'.format(p.name, out, docDir))\n            finally:\n                if delOverviewFile:\n                    os.remove(overviewFile)\n\n    else:\n        # The projects must be built to ensure javadoc can find class files for all referenced classes\n        build(['--no-native'])\n\n        pkgs = set()\n        sp = []\n        names = []\n        for p in projects:\n            find_packages(p.source_dirs(), pkgs)\n            sp += p.source_dirs()\n            names.append(p.name)\n\n        links = ['-link', 'http://docs.oracle.com/javase/' + str(java().javaCompliance.value) + '/docs/api/']\n        out = join(_primary_suite.dir, docDir)\n        if args.base is not None:\n            out = join(args.base, docDir)\n        cp = classpath()\n        sp = os.pathsep.join(sp)\n        nowarnAPI = []\n        if not args.warnAPI:\n            nowarnAPI.append('-XDignore.symbol.file')\n        log('Generating {2} for {0} in {1}'.format(', '.join(names), out, docDir))\n        run([java().javadoc, memory,\n             '-classpath', cp,\n             '-quiet',\n             '-d', out,\n             '-sourcepath', sp] +\n             ([] if java().javaCompliance < JavaCompliance('1.8') else ['-Xdoclint:none']) +\n             links +\n             extraArgs +\n             nowarnAPI +\n             list(pkgs))\n        log('Generated {2} for {0} in {1}'.format(', '.join(names), out, docDir))\n\ndef site(args):\n    \"\"\"creates a website containing javadoc and the project dependency graph\"\"\"\n\n    parser = ArgumentParser(prog='site')\n    parser.add_argument('-d', '--base', action='store', help='directory for generated site', required=True, metavar='<dir>')\n    parser.add_argument('--tmp', action='store', help='directory to use for intermediate results', metavar='<dir>')\n    parser.add_argument('--name', action='store', help='name of overall documentation', required=True, metavar='<name>')\n    parser.add_argument('--overview', action='store', help='path to the overview content for overall documentation', required=True, metavar='<path>')\n    parser.add_argument('--projects', action='store', help='comma separated projects to process (omit to process all projects)')\n    parser.add_argument('--jd', action='append', help='extra Javadoc arguments (e.g. --jd @-use)', metavar='@<arg>', default=[])\n    parser.add_argument('--exclude-packages', action='store', help='comma separated packages to exclude', metavar='<pkgs>')\n    parser.add_argument('--dot-output-base', action='store', help='base file name (relative to <dir>/all) for project dependency graph .svg and .jpg files generated by dot (omit to disable dot generation)', metavar='<path>')\n    parser.add_argument('--title', action='store', help='value used for -windowtitle and -doctitle javadoc args for overall documentation (default: \"<name>\")', metavar='<title>')\n    args = parser.parse_args(args)\n\n    args.base = os.path.abspath(args.base)\n    tmpbase = args.tmp if args.tmp else  tempfile.mkdtemp(prefix=basename(args.base) + '.', dir=dirname(args.base))\n    unified = join(tmpbase, 'all')\n\n    exclude_packages_arg = []\n    if args.exclude_packages is not None:\n        exclude_packages_arg = ['--exclude-packages', args.exclude_packages]\n\n    projects = sorted_deps()\n    projects_arg = []\n    if args.projects is not None:\n        projects_arg = ['--projects', args.projects]\n        projects = [project(name) for name in args.projects.split(',')]\n\n    extra_javadoc_args = []\n    for a in args.jd:\n        extra_javadoc_args.append('--arg')\n        extra_javadoc_args.append('@' + a)\n\n    try:\n        # Create javadoc for each project\n        javadoc(['--base', tmpbase] + exclude_packages_arg + projects_arg + extra_javadoc_args)\n\n        # Create unified javadoc for all projects\n        with open(args.overview) as fp:\n            content = fp.read()\n            idx = content.rfind('</body>')\n            if idx != -1:\n                args.overview = join(tmpbase, 'overview_with_projects.html')\n                with open(args.overview, 'w') as fp2:\n                    print >> fp2, content[0:idx]\n                    print >> fp2, \"\"\"<div class=\"contentContainer\">\n<table class=\"overviewSummary\" border=\"0\" cellpadding=\"3\" cellspacing=\"0\" summary=\"Projects table\">\n<caption><span>Projects</span><span class=\"tabEnd\">&nbsp;</span></caption>\n<tr><th class=\"colFirst\" scope=\"col\">Project</th><th class=\"colLast\" scope=\"col\">&nbsp;</th></tr>\n<tbody>\"\"\"\n                    color = 'row'\n                    for p in projects:\n                        print >> fp2, '<tr class=\"{1}Color\"><td class=\"colFirst\"><a href=\"../{0}/javadoc/index.html\",target = \"_top\">{0}</a></td><td class=\"colLast\">&nbsp;</td></tr>'.format(p.name, color)\n                        color = 'row' if color == 'alt' else 'alt'\n\n                    print >> fp2, '</tbody></table></div>'\n                    print >> fp2, content[idx:]\n\n        title = args.title if args.title is not None else args.name\n        javadoc(['--base', tmpbase,\n                 '--unified',\n                 '--arg', '@-windowtitle', '--arg', '@' + title,\n                 '--arg', '@-doctitle', '--arg', '@' + title,\n                 '--arg', '@-overview', '--arg', '@' + args.overview] + exclude_packages_arg + projects_arg + extra_javadoc_args)\n\n        if exists(unified):\n            shutil.rmtree(unified)\n        os.rename(join(tmpbase, 'javadoc'), unified)\n\n        # Generate dependency graph with Graphviz\n        if args.dot_output_base is not None:\n            dotErr = None\n            try:\n                if not 'version' in subprocess.check_output(['dot', '-V'], stderr=subprocess.STDOUT):\n                    dotErr = 'dot -V does not print a string containing \"version\"'\n            except subprocess.CalledProcessError as e:\n                dotErr = 'error calling \"dot -V\": {}'.format(e)\n            except OSError as e:\n                dotErr = 'error calling \"dot -V\": {}'.format(e)\n\n            if dotErr != None:\n                abort('cannot generate dependency graph: ' + dotErr)\n\n            dot = join(tmpbase, 'all', str(args.dot_output_base) + '.dot')\n            svg = join(tmpbase, 'all', str(args.dot_output_base) + '.svg')\n            jpg = join(tmpbase, 'all', str(args.dot_output_base) + '.jpg')\n            html = join(tmpbase, 'all', str(args.dot_output_base) + '.html')\n            with open(dot, 'w') as fp:\n                dim = len(projects)\n                print >> fp, 'digraph projects {'\n                print >> fp, 'rankdir=BT;'\n                print >> fp, 'size = \"' + str(dim) + ',' + str(dim) + '\";'\n                print >> fp, 'node [shape=rect, fontcolor=\"blue\"];'\n                # print >> fp, 'edge [color=\"green\"];'\n                for p in projects:\n                    print >> fp, '\"' + p.name + '\" [URL = \"../' + p.name + '/javadoc/index.html\", target = \"_top\"]'\n                    for dep in p.canonical_deps():\n                        if dep in [proj.name for proj in projects]:\n                            print >> fp, '\"' + p.name + '\" -> \"' + dep + '\"'\n                depths = dict()\n                for p in projects:\n                    d = p.max_depth()\n                    depths.setdefault(d, list()).append(p.name)\n                print >> fp, '}'\n\n            run(['dot', '-Tsvg', '-o' + svg, '-Tjpg', '-o' + jpg, dot])\n\n            # Post-process generated SVG to remove title elements which most browsers\n            # render as redundant (and annoying) tooltips.\n            with open(svg, 'r') as fp:\n                content = fp.read()\n            content = re.sub('<title>.*</title>', '', content)\n            content = re.sub('xlink:title=\"[^\"]*\"', '', content)\n            with open(svg, 'w') as fp:\n                fp.write(content)\n\n            # Create HTML that embeds the svg file in an <object> frame\n            with open(html, 'w') as fp:\n                print >> fp, '<html><body><object data=\"{}.svg\" type=\"image/svg+xml\"></object></body></html>'.format(args.dot_output_base)\n\n        if exists(args.base):\n            shutil.rmtree(args.base)\n        if args.tmp:\n            shutil.copytree(tmpbase, args.base)\n        else:\n            shutil.move(tmpbase, args.base)\n\n        print 'Created website - root is ' + join(args.base, 'all', 'index.html')\n\n    finally:\n        if not args.tmp and exists(tmpbase):\n            shutil.rmtree(tmpbase)\n\ndef _kwArg(kwargs):\n    if len(kwargs) > 0:\n        return kwargs.pop(0)\n    return None\n\ndef findclass(args, logToConsole=True, matcher=lambda string, classname: string in classname):\n    \"\"\"find all classes matching a given substring\"\"\"\n    matches = []\n    for entry, filename in classpath_walk(includeBootClasspath=True):\n        if filename.endswith('.class'):\n            if isinstance(entry, zipfile.ZipFile):\n                classname = filename.replace('/', '.')\n            else:\n                classname = filename.replace(os.sep, '.')\n            classname = classname[:-len('.class')]\n            for a in args:\n                if matcher(a, classname):\n                    matches.append(classname)\n                    if logToConsole:\n                        log(classname)\n    return matches\n\ndef select_items(items, descriptions=None, allowMultiple=True):\n    \"\"\"\n    Presents a command line interface for selecting one or more (if allowMultiple is true) items.\n\n    \"\"\"\n    if len(items) <= 1:\n        return items\n    else:\n        if allowMultiple:\n            log('[0] <all>')\n        for i in range(0, len(items)):\n            if descriptions is None:\n                log('[{0}] {1}'.format(i + 1, items[i]))\n            else:\n                assert len(items) == len(descriptions)\n                wrapper = textwrap.TextWrapper(subsequent_indent='    ')\n                log('\\n'.join(wrapper.wrap('[{0}] {1} - {2}'.format(i + 1, items[i], descriptions[i]))))\n        while True:\n            if allowMultiple:\n                s = raw_input('Enter number(s) of selection (separate multiple choices with spaces): ').split()\n            else:\n                s = [raw_input('Enter number of selection: ')]\n            try:\n                s = [int(x) for x in s]\n            except:\n                log('Selection contains non-numeric characters: \"' + ' '.join(s) + '\"')\n                continue\n\n            if allowMultiple and 0 in s:\n                return items\n\n            indexes = []\n            for n in s:\n                if n not in range(1, len(items) + 1):\n                    log('Invalid selection: ' + str(n))\n                    continue\n                else:\n                    indexes.append(n - 1)\n            if allowMultiple:\n                return [items[i] for i in indexes]\n            if len(indexes) == 1:\n                return items[indexes[0]]\n            return None\n\ndef exportlibs(args):\n    \"\"\"export libraries to an archive file\"\"\"\n\n    parser = ArgumentParser(prog='exportlibs')\n    parser.add_argument('-b', '--base', action='store', help='base name of archive (default: libs)', default='libs', metavar='<path>')\n    parser.add_argument('-a', '--include-all', action='store_true', help=\"include all defined libaries\")\n    parser.add_argument('--arc', action='store', choices=['tgz', 'tbz2', 'tar', 'zip'], default='tgz', help='the type of the archive to create')\n    parser.add_argument('--no-sha1', action='store_false', dest='sha1', help='do not create SHA1 signature of archive')\n    parser.add_argument('--no-md5', action='store_false', dest='md5', help='do not create MD5 signature of archive')\n    parser.add_argument('--include-system-libs', action='store_true', help='include system libraries (i.e., those not downloaded from URLs)')\n    parser.add_argument('extras', nargs=REMAINDER, help='extra files and directories to add to archive', metavar='files...')\n    args = parser.parse_args(args)\n\n    def createArchive(addMethod):\n        entries = {}\n        def add(path, arcname):\n            apath = os.path.abspath(path)\n            if not entries.has_key(arcname):\n                entries[arcname] = apath\n                logv('[adding ' + path + ']')\n                addMethod(path, arcname=arcname)\n            elif entries[arcname] != apath:\n                logv('[warning: ' + apath + ' collides with ' + entries[arcname] + ' as ' + arcname + ']')\n            else:\n                logv('[already added ' + path + ']')\n\n        libsToExport = set()\n        if args.include_all:\n            for lib in _libs.itervalues():\n                libsToExport.add(lib)\n        else:\n            def isValidLibrary(dep):\n                if dep in _libs.iterkeys():\n                    lib = _libs[dep]\n                    if len(lib.urls) != 0 or args.include_system_libs:\n                        return lib\n                return None\n\n            # iterate over all project dependencies and find used libraries\n            for p in _projects.itervalues():\n                for dep in p.deps:\n                    r = isValidLibrary(dep)\n                    if r:\n                        libsToExport.add(r)\n\n            # a library can have other libraries as dependency\n            size = 0\n            while size != len(libsToExport):\n                size = len(libsToExport)\n                for lib in libsToExport.copy():\n                    for dep in lib.deps:\n                        r = isValidLibrary(dep)\n                        if r:\n                            libsToExport.add(r)\n\n        for lib in libsToExport:\n            add(lib.get_path(resolve=True), lib.path)\n            if lib.sha1:\n                add(lib.get_path(resolve=True) + \".sha1\", lib.path + \".sha1\")\n            if lib.sourcePath:\n                add(lib.get_source_path(resolve=True), lib.sourcePath)\n                if lib.sourceSha1:\n                    add(lib.get_source_path(resolve=True) + \".sha1\", lib.sourcePath + \".sha1\")\n\n        if args.extras:\n            for e in args.extras:\n                if os.path.isdir(e):\n                    for root, _, filenames in os.walk(e):\n                        for name in filenames:\n                            f = join(root, name)\n                            add(f, f)\n                else:\n                    add(e, e)\n\n    if args.arc == 'zip':\n        path = args.base + '.zip'\n        with zipfile.ZipFile(path, 'w') as zf:\n            createArchive(zf.write)\n    else:\n        path = args.base + '.tar'\n        mode = 'w'\n        if args.arc != 'tar':\n            sfx = args.arc[1:]\n            mode = mode + ':' + sfx\n            path = path + '.' + sfx\n        with tarfile.open(path, mode) as tar:\n            createArchive(tar.add)\n    log('created ' + path)\n\n    def digest(enabled, path, factory, suffix):\n        if enabled:\n            d = factory()\n            with open(path, 'rb') as f:\n                while True:\n                    buf = f.read(4096)\n                    if not buf:\n                        break\n                    d.update(buf)\n            with open(path + '.' + suffix, 'w') as fp:\n                print >> fp, d.hexdigest()\n            log('created ' + path + '.' + suffix)\n\n    digest(args.sha1, path, hashlib.sha1, 'sha1')\n    digest(args.md5, path, hashlib.md5, 'md5')\n\ndef javap(args):\n    \"\"\"disassemble classes matching given pattern with javap\"\"\"\n\n    javapExe = java().javap\n    if not exists(javapExe):\n        abort('The javap executable does not exists: ' + javapExe)\n    else:\n        candidates = findclass(args, logToConsole=False)\n        if len(candidates) == 0:\n            log('no matches')\n        selection = select_items(candidates)\n        run([javapExe, '-private', '-verbose', '-classpath', classpath()] + selection)\n\ndef show_projects(args):\n    \"\"\"show all loaded projects\"\"\"\n    for s in suites():\n        projectsFile = join(s.mxDir, 'projects')\n        if exists(projectsFile):\n            log(projectsFile)\n            for p in s.projects:\n                log('\\t' + p.name)\n\ndef ask_yes_no(question, default=None):\n    \"\"\"\"\"\"\n    assert not default or default == 'y' or default == 'n'\n    if not sys.stdout.isatty():\n        if default:\n            return default\n        else:\n            abort(\"Can not answer '\" + question + \"?' if stdout is not a tty\")\n    questionMark = '? [yn]: '\n    if default:\n        questionMark = questionMark.replace(default, default.upper())\n    answer = raw_input(question + questionMark) or default\n    while not answer:\n        answer = raw_input(question + questionMark)\n    return answer.lower().startswith('y')\n\ndef add_argument(*args, **kwargs):\n    \"\"\"\n    Define how a single command-line argument.\n    \"\"\"\n    assert _argParser is not None\n    _argParser.add_argument(*args, **kwargs)\n\ndef update_commands(suite, new_commands):\n    for key, value in new_commands.iteritems():\n        if _commands.has_key(key):\n            warn(\"redefining command '\" + key + \"' in suite \" + suite.name)\n        _commands[key] = value\n\ndef warn(msg):\n    if _warn:\n        print 'WARNING: ' + msg\n\n# Table of commands in alphabetical order.\n# Keys are command names, value are lists: [<function>, <usage msg>, <format args to doc string of function>...]\n# If any of the format args are instances of Callable, then they are called with an 'env' are before being\n# used in the call to str.format().\n# Suite extensions should not update this table directly, but use update_commands\n_commands = {\n    'about': [about, ''],\n    'build': [build, '[options]'],\n    'checkstyle': [checkstyle, ''],\n    'canonicalizeprojects': [canonicalizeprojects, ''],\n    'clean': [clean, ''],\n    'eclipseinit': [eclipseinit, ''],\n    'eclipseformat': [eclipseformat, ''],\n    'exportlibs': [exportlibs, ''],\n    'findclass': [findclass, ''],\n    'fsckprojects': [fsckprojects, ''],\n    'help': [help_, '[command]'],\n    'ideclean': [ideclean, ''],\n    'ideinit': [ideinit, ''],\n    'intellijinit': [intellijinit, ''],\n    'archive': [_archive, '[options]'],\n    'projectgraph': [projectgraph, ''],\n    'pylint': [pylint, ''],\n    'javap': [javap, '<class name patterns>'],\n    'javadoc': [javadoc, '[options]'],\n    'site': [site, '[options]'],\n    'netbeansinit': [netbeansinit, ''],\n    'projects': [show_projects, ''],\n}\n\n_argParser = ArgParser()\n\ndef _suitename(mxDir):\n    base = os.path.basename(mxDir)\n    parts = base.split('.')\n    # temporary workaround until mx.graal exists\n    if len(parts) == 1:\n        return 'graal'\n    else:\n        return parts[1]\n\ndef _is_suite_dir(d, mxDirName=None):\n    \"\"\"\n    Checks if d contains a suite.\n    If mxDirName is None, matches any suite name, otherwise checks for exactly that suite.\n    \"\"\"\n    if os.path.isdir(d):\n        for f in os.listdir(d):\n            if (mxDirName == None and (f == 'mx' or fnmatch.fnmatch(f, 'mx.*'))) or f == mxDirName:\n                mxDir = join(d, f)\n                if exists(mxDir) and isdir(mxDir) and exists(join(mxDir, 'projects')):\n                    return mxDir\n\ndef _check_primary_suite():\n    if _primary_suite is None:\n        abort('no primary suite found')\n    else:\n        return _primary_suite\n\ndef _findPrimarySuiteMxDirFrom(d):\n    \"\"\" search for a suite directory upwards from 'd' \"\"\"\n    while d:\n        mxDir = _is_suite_dir(d)\n        if mxDir is not None:\n            return mxDir\n        parent = dirname(d)\n        if d == parent:\n            return None\n        d = parent\n\n    return None\n\ndef _findPrimarySuiteMxDir():\n    # check for explicit setting\n    if _primary_suite_path is not None:\n        mxDir = _is_suite_dir(_primary_suite_path)\n        if mxDir is not None:\n            return mxDir\n        else:\n            abort(_primary_suite_path + ' does not contain an mx suite')\n\n    # try current working directory first\n    mxDir = _findPrimarySuiteMxDirFrom(os.getcwd())\n    if mxDir is not None:\n        return mxDir\n    # backwards compatibility: search from path of this file\n    return _findPrimarySuiteMxDirFrom(dirname(__file__))\n\ndef main():\n    primarySuiteMxDir = _findPrimarySuiteMxDir()\n    if primarySuiteMxDir:\n        global _primary_suite\n        _primary_suite = _loadSuite(primarySuiteMxDir, True)\n    else:\n        abort('no primary suite found')\n\n    opts, commandAndArgs = _argParser._parse_cmd_line()\n\n    global _opts, _java_homes\n    _opts = opts\n    defaultJdk = JavaConfig(opts.java_home, opts.java_dbg_port)\n    _java_homes = [defaultJdk]\n    if opts.extra_java_homes:\n        for java_home in opts.extra_java_homes.split(os.pathsep):\n            extraJdk = JavaConfig(java_home, opts.java_dbg_port)\n            if extraJdk > defaultJdk:\n                abort('Secondary JDK ' + extraJdk.jdk + ' has higher compliance level than default JDK ' + defaultJdk.jdk)\n            _java_homes.append(extraJdk)\n\n    for s in suites():\n        s._post_init(opts)\n\n    if len(commandAndArgs) == 0:\n        _argParser.print_help()\n        return\n\n    command = commandAndArgs[0]\n    command_args = commandAndArgs[1:]\n\n    if not _commands.has_key(command):\n        hits = [c for c in _commands.iterkeys() if c.startswith(command)]\n        if len(hits) == 1:\n            command = hits[0]\n        elif len(hits) == 0:\n            abort('mx: unknown command \\'{0}\\'\\n{1}use \"mx help\" for more options'.format(command, _format_commands()))\n        else:\n            abort('mx: command \\'{0}\\' is ambiguous\\n    {1}'.format(command, ' '.join(hits)))\n\n    c, _ = _commands[command][:2]\n    def term_handler(signum, frame):\n        abort(1)\n    signal.signal(signal.SIGTERM, term_handler)\n\n    def quit_handler(signum, frame):\n        _send_sigquit()\n    if get_os() != 'windows':\n        signal.signal(signal.SIGQUIT, quit_handler)\n\n    try:\n        if opts.timeout != 0:\n            def alarm_handler(signum, frame):\n                abort('Command timed out after ' + str(opts.timeout) + ' seconds: ' + ' '.join(commandAndArgs))\n            signal.signal(signal.SIGALRM, alarm_handler)\n            signal.alarm(opts.timeout)\n        retcode = c(command_args)\n        if retcode is not None and retcode != 0:\n            abort(retcode)\n    except KeyboardInterrupt:\n        # no need to show the stack trace when the user presses CTRL-C\n        abort(1)\n\nversion = VersionSpec(\"1.0\")\n\ncurrentUmask = None\n\nif __name__ == '__main__':\n    # rename this module as 'mx' so it is not imported twice by the commands.py modules\n    sys.modules['mx'] = sys.modules.pop('__main__')\n\n    # Capture the current umask since there's no way to query it without mutating it.\n    currentUmask = os.umask(0)\n    os.umask(currentUmask)\n\n    main()\n","markers":{"markers":{"1":{"id":1,"range":[[216,24],[216,24]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":941,"goalBufferRange":null,"preserveFolds":true,"autoscroll":true},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/zwei/Workspace/oracle/fastr-svm-home/graal/mxtool/mx.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"7ea0056ecc178867071061ef2f8299d3efea9f9c","deserializer":"TextBuffer"},{"text":"suite=fastr\nmxversion=2.4.4\n\nlibrary@JDK_TOOLS@path=${JAVA_HOME}/lib/tools.jar\nlibrary@JDK_TOOLS@sha1=NOCHECK\n\nlibrary@CHECKSTYLE@path=lib/checkstyle-5.5-all.jar\nlibrary@CHECKSTYLE@urls=jar:http://sourceforge.net/projects/checkstyle/files/checkstyle/5.5/checkstyle-5.5-bin.zip/download!/checkstyle-5.5/checkstyle-5.5-all.jar\nlibrary@CHECKSTYLE@sha1=6f4bb2b3dafb9426a67fa9c47f96ffed3b44749a\n\nlibrary@ANTLR@path=lib/antlr-runtime-3.5.jar\nlibrary@ANTLR@urls=http://central.maven.org/maven2/org/antlr/antlr-runtime/3.5/antlr-runtime-3.5.jar\nlibrary@ANTLR@sha1=0baa82bff19059401e90e1b90020beb9c96305d7\n\nlibrary@NETLIB@path=lib/netlib-java-0.9.3.jar\nlibrary@NETLIB@urls=http://central.maven.org/maven2/com/googlecode/netlib-java/netlib-java/0.9.3/netlib-java-0.9.3.jar\nlibrary@NETLIB@sha1=1d41b60e5180f6bcb7db15e7353dde7147cd3928\n\nlibrary@ANTLR-C@path=lib/antlr-complete-3.5.1.jar\nlibrary@ANTLR-C@urls=http://central.maven.org/maven2/org/antlr/antlr-complete/3.5.1/antlr-complete-3.5.1.jar\nlibrary@ANTLR-C@sha1=ebb4b995fd67a9b291ea5b19379509160f56e154\n\nlibrary@JLINE@path=lib/jline-2.11.jar\nlibrary@JLINE@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jline-2.11.jar,http://repo1.maven.org/maven2/jline/jline/2.11/jline-2.11.jar\nlibrary@JLINE@sha1=9504d5e2da5d78237239c5226e8200ec21182040\n\nlibrary@JNR_POSIX@path=lib/jnr-posix-3.0.1.jar\nlibrary@JNR_POSIX@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jnr-posix-3.0.1.jar,http://repo1.maven.org/maven2/com/github/jnr/jnr-posix/3.0.1/jnr-posix-3.0.1.jar\nlibrary@JNR_POSIX@sha1=5ac18caed12108123c959c8acedef76ca4f28cb3\n\nlibrary@JNR_CONSTANTS@path=lib/jnr-constants-0.8.5.jar\nlibrary@JNR_CONSTANTS@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jnr-constants-0.8.5.jar,http://repo1.maven.org/maven2/com/github/jnr/jnr-constants/0.8.5/jnr-constants-0.8.5.jar\nlibrary@JNR_CONSTANTS@sha1=f84cca9e21f1f763a9eaf33de3d6a66a20ed7af0\n\nlibrary@JNR_FFI@path=lib/jnr-ffi-1.0.10.jar\nlibrary@JNR_FFI@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jnr-ffi-1.0.10.jar,http://repo1.maven.org/maven2/com/github/jnr/jnr-ffi/1.0.10/jnr-ffi-1.0.10.jar\nlibrary@JNR_FFI@sha1=646428e83a0e2ab4743091781ea98e3164c6d707\n\nlibrary@JFFI@path=lib/jffi-1.2.7.jar\nlibrary@JFFI@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jffi-1.2.7.jar,http://repo1.maven.org/maven2/com/github/jnr/jffi/1.2.7/jffi-1.2.7.jar\nlibrary@JFFI@sha1=acda5c46140404e08b3526f39db1504874b34b4c\n\nlibrary@JFFI_NATIVE@path=lib/jffi-1.2.7-native.jar\nlibrary@JFFI_NATIVE@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jffi-1.2.7-native.jar,http://search.maven.org/remotecontent?filepath=com/github/jnr/jffi/1.2.7/jffi-1.2.7-native.jar\nlibrary@JFFI_NATIVE@sha1=4e8c876383acb37da4347902a0a775aefd51de09\n\nlibrary@JNR_X86ASM@path=lib/jnr-x86asm-1.0.2.jar\nlibrary@JNR_X86ASM@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/jnr-x86asm-1.0.2.jar,http://repo1.maven.org/maven2/com/github/jnr/jnr-x86asm/1.0.2/jnr-x86asm-1.0.2.jar\nlibrary@JNR_X86ASM@sha1=006936bbd6c5b235665d87bd450f5e13b52d4b48\n\nlibrary@ASM@path=lib/asm-4.0.jar\nlibrary@ASM@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/asm-4.0.jar,http://repo1.maven.org/maven2/org/ow2/asm/asm/4.0/asm-4.0.jar\nlibrary@ASM@sha1=659add6efc75a4715d738e73f07505246edf4d66\n\nlibrary@ASM_ANALYSIS@path=lib/asm-analysis-4.0.jar\nlibrary@ASM_ANALYSIS@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/asm-analysis-4.0.jar,http://repo1.maven.org/maven2/org/ow2/asm/asm-analysis/4.0/asm-analysis-4.0.jar\nlibrary@ASM_ANALYSIS@sha1=1c45d52b6f6c638db13cf3ac12adeb56b254cdd7\n\nlibrary@ASM_COMMONS@path=lib/asm-commons-4.0.jar\nlibrary@ASM_COMMONS@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/asm-commons-4.0.jar,http://repo1.maven.org/maven2/org/ow2/asm/asm-commons/4.0/asm-commons-4.0.jar\nlibrary@ASM_COMMONS@sha1=a839ec6737d2b5ba7d1878e1a596b8f58aa545d9\n\nlibrary@ASM_TREE@path=lib/asm-tree-4.0.jar\nlibrary@ASM_TREE@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/asm-tree-4.0.jar,http://repo1.maven.org/maven2/org/ow2/asm/asm-tree/4.0/asm-tree-4.0.jar\nlibrary@ASM_TREE@sha1=67bd266cd17adcee486b76952ece4cc85fe248b8\n\nlibrary@ASM_UTIL@path=lib/asm-util-4.0.jar\nlibrary@ASM_UTIL@urls=http://lafo.ssw.uni-linz.ac.at/graal-external-deps/asm-util-4.0.jar,http://repo1.maven.org/maven2/org/ow2/asm/asm-util/4.0/asm-util-4.0.jar\nlibrary@ASM_UTIL@sha1=d7a65f54cda284f9706a750c23d64830bb740c39\n\nlibrary@JNR_INVOKE@path=lib/jnr-invoke-0.1.jar\nlibrary@JNR_INVOKE@urls=http://repo1.maven.org/maven2/com/github/jnr/jnr-invoke/0.1/jnr-invoke-0.1.jar\nlibrary@JNR_INVOKE@sha1=d0f846c3d3cb98dfd5e2bbd3cca236337fb0afa1\n\nlibrary@JNR_UDIS86@path=lib/jnr-udis86-0.1.jar\nlibrary@JNR_UDIS86@urls=http://repo1.maven.org/maven2/com/github/jnr/jnr-udis86/0.1/jnr-udis86-0.1.jar\nlibrary@JNR_UDIS86@sha1=88accfa82203ea74a4a82237061c28ac8b4224af\n\ndistribution@FASTR@path=fastr.jar\ndistribution@FASTR@sourcesPath=fastr-sources.jar\ndistribution@FASTR@dependencies=com.oracle.truffle.r.nodes\ndistribution@FASTR@exclude=JDK_TOOLS,FINDBUGS,NETLIB,ASM_UTIL,ASM_TREE,ASM_COMMONS,ASM_ANALYSIS,ASM,JNR_X86ASM,JFFI_NATIVE,JFFI,JNR_FFI,JNR_CONSTANTS,JNR_POSIX,JNR_INVOKE,JNR_UDIS86,JLINE,ANTLR-C,ANTLR\ndistribution@FASTR@distDependencies=TRUFFLE,GRAAL\n\n# com.oracle.truffle.r.parser.processor\nproject@com.oracle.truffle.r.parser.processor@sourceDirs=src\nproject@com.oracle.truffle.r.parser.processor@dependencies=JDK_TOOLS,ANTLR,ANTLR-C\nproject@com.oracle.truffle.r.parser.processor@checkstyle=com.oracle.truffle.r.runtime\nproject@com.oracle.truffle.r.parser.processor@javaCompliance=1.8\nproject@com.oracle.truffle.r.parser.processor@workingSets=Truffle,FastR\n\n# com.oracle.truffle.r.parser\nproject@com.oracle.truffle.r.parser@sourceDirs=src\nproject@com.oracle.truffle.r.parser@dependencies=com.oracle.truffle.r.parser.processor,com.oracle.truffle.r.runtime\nproject@com.oracle.truffle.r.parser@checkstyle=com.oracle.truffle.r.runtime\nproject@com.oracle.truffle.r.parser@javaCompliance=1.8\nproject@com.oracle.truffle.r.parser@annotationProcessors=com.oracle.truffle.r.parser.processor\nproject@com.oracle.truffle.r.parser@workingSets=Truffle,FastR\n\n# com.oracle.truffle.r.nodes\nproject@com.oracle.truffle.r.nodes@sourceDirs=src\nproject@com.oracle.truffle.r.nodes@dependencies=com.oracle.truffle.api.dsl,com.oracle.truffle.r.parser,com.oracle.truffle.r.options\nproject@com.oracle.truffle.r.nodes@checkstyle=com.oracle.truffle.r.runtime\nproject@com.oracle.truffle.r.nodes@javaCompliance=1.8\nproject@com.oracle.truffle.r.nodes@annotationProcessors=com.oracle.truffle.dsl.processor\nproject@com.oracle.truffle.r.nodes@workingSets=Truffle,FastR\n\n# com.oracle.truffle.r.test.ignore.processor\nproject@com.oracle.truffle.r.test.ignore.processor@sourceDirs=src\nproject@com.oracle.truffle.r.test.ignore.processor@dependencies=JUNIT,JDK_TOOLS\nproject@com.oracle.truffle.r.test.ignore.processor@checkstyle=com.oracle.truffle.r.runtime\nproject@com.oracle.truffle.r.test.ignore.processor@javaCompliance=1.8\nproject@com.oracle.truffle.r.test.ignore.processor@workingSets=Truffle,FastR\n\n# com.oracle.truffle.r.test\nproject@com.oracle.truffle.r.test@sourceDirs=src\nproject@com.oracle.truffle.r.test@dependencies=JUNIT,com.oracle.truffle.r.engine\nproject@com.oracle.truffle.r.test@checkstyle=com.oracle.truffle.r.runtime\nproject@com.oracle.truffle.r.test@javaCompliance=1.8\nproject@com.oracle.truffle.r.test@annotationProcessors=com.oracle.truffle.r.test.ignore.processor\nproject@com.oracle.truffle.r.test@workingSets=Truffle,FastR,Test\n\n# com.oracle.truffle.r.test.native\nproject@com.oracle.truffle.r.test.native@sourceDirs=\nproject@com.oracle.truffle.r.test.native@native=true\nproject@com.oracle.truffle.r.test.native@workingSets=FastR\n\n# com.oracle.truffle.r.engine\nproject@com.oracle.truffle.r.engine@sourceDirs=src\nproject@com.oracle.truffle.r.engine@dependencies=com.oracle.truffle.r.nodes\nproject@com.oracle.truffle.r.engine@checkstyle=com.oracle.truffle.r.runtime\nproject@com.oracle.truffle.r.engine@javaCompliance=1.8\nproject@com.oracle.truffle.r.engine@workingSets=Truffle,FastR\n\n# com.oracle.truffle.r.shell\nproject@com.oracle.truffle.r.shell@sourceDirs=src\nproject@com.oracle.truffle.r.shell@dependencies=com.oracle.truffle.r.engine,JLINE\nproject@com.oracle.truffle.r.shell@checkstyle=com.oracle.truffle.r.runtime\nproject@com.oracle.truffle.r.shell@javaCompliance=1.8\nproject@com.oracle.truffle.r.shell@workingSets=Truffle,FastR\n\n# com.oracle.truffle.r.runtime\nproject@com.oracle.truffle.r.runtime@sourceDirs=src\nproject@com.oracle.truffle.r.runtime@dependencies=com.oracle.truffle.api,ASM_ANALYSIS,JNR_POSIX,ASM_UTIL,JFFI,JNR_FFI,NETLIB,JNR_CONSTANTS,JFFI_NATIVE,JNR_INVOKE,JNR_UDIS86,ASM,ASM_TREE,ASM_COMMONS,JNR_X86ASM,com.oracle.graal.runtime\nproject@com.oracle.truffle.r.runtime@checkstyle=com.oracle.truffle.r.runtime\nproject@com.oracle.truffle.r.runtime@javaCompliance=1.8\nproject@com.oracle.truffle.r.runtime@workingSets=Truffle,FastR\n\n# com.oracle.truffle.r.native\nproject@com.oracle.truffle.r.native@sourceDirs=\nproject@com.oracle.truffle.r.native@native=true\nproject@com.oracle.truffle.r.native@workingSets=FastR\n\n# com.oracle.truffle.r.options\nproject@com.oracle.truffle.r.options@sourceDirs=src\nproject@com.oracle.truffle.r.options@dependencies=com.oracle.graal.options\nproject@com.oracle.truffle.r.options@checkstyle=com.oracle.truffle.r.runtime\nproject@com.oracle.truffle.r.options@javaCompliance=1.8\nproject@com.oracle.truffle.r.options@workingSets=FastR\n\n","markers":{"markers":{"1":{"id":1,"range":[[70,0],[70,0]],"tailed":false,"reversed":true,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":1783,"autoscroll":true,"goalBufferRange":null,"preserveFolds":true},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/zwei/Workspace/oracle/fastr-svm-home/fastr/mx.fastr/projects","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"a6574f25ff49aeb0718d0d4fe97d8313dcad3dec","deserializer":"TextBuffer"},{"text":"graal,8890d88ea6feb452ed1ff087803d75dc28eda25e,http://diy-3-16.us.oracle.com/hg/substratevm\nfastr,4c0a6c373bc16fca5d303ec4d42b4aa493d9b7a5,http://diy-3-16.us.oracle.com/hg/fastr\n","markers":{"markers":{"1":{"id":1,"range":[[2,0],[2,0]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":2373,"goalBufferRange":null,"preserveFolds":true},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/zwei/Workspace/oracle/fastr-svm-home/svm_fastr/mx.svm_fastr/imports","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"93f611ddaf21054682a9064df176bf5b133a3242","deserializer":"TextBuffer"},{"text":"#\n# Copyright (c) 2013, 2014, Oracle and/or its affiliates. All rights reserved.\n# DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n#\n# This code is free software; you can redistribute it and/or modify it\n# under the terms of the GNU General Public License version 2 only, as\n# published by the Free Software Foundation.\n#\n# This code is distributed in the hope that it will be useful, but WITHOUT\n# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n# version 2 for more details (a copy is included in the LICENSE file that\n# accompanied this code).\n#\n# You should have received a copy of the GNU General Public License version\n# 2 along with this work; if not, write to the Free Software Foundation,\n# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n#\n# Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n# or visit www.oracle.com if you need additional information or have any\n# questions.\n#\nfrom os import mkdir\nfrom os.path import exists, join\nimport subprocess\nimport mx\nimport mx_graal\n\n_image_dir = 'image'\n_image_name = 'svm_fastr'\n_props = ['-Dfastr.truffle.compile=false', '-Dfastr.ffi.factory.class=com.oracle.svm.truffle.r.SVM_RFFIFactory']\n\ndef _image_path():\n    return join(_image_dir, _image_name)\n\ndef image(args):\n    '''\n    Override the SVM image command to customize the arguments.\n    N.B. the SVM image command does not use ArgumentParser\n    '''\n    if not exists(_image_dir):\n        mkdir(_image_dir)\n\n    entry_class = '-class=com.oracle.svm.truffle.r.Main'\n    name = '-name=' + _image_name\n    image_path = '-path=' + _image_dir\n    mx_graal.image(_props + ['-Xmx6G', '--', entry_class, name, image_path] + args)\n\ndef _runR(args, command):\n    try:\n        command = [_image_path(), command] + args\n        subprocess.call(command)\n    except subprocess.CalledProcessError:\n        mx.abort(\"executing svm_fastr failed\")\n\ndef runRCommand(args):\n    '''run R shell'''\n    _runR(args, \"R\")\n\ndef runRscriptCommand(args):\n    '''run Rscript file'''\n    _runR(args, \"Rscript\")\n\ndef svmtest(args):\n    \"\"\"\n    Override the svmtest command to feed the correct classpaths.\n    \"\"\"\n    vmArgs, normalArgs = mx_graal._extract_VM_args(args, useDoubleDash=True, defaultAllVMArgs=False)\n    classpaths = mx.classpath(['com.oracle.svm.test', 'com.oracle.svm.truffle.r'])\n    mx_graal.vm(_props + ['-Xss10m', '-Xmx6G'] + vmArgs + ['-cp', classpaths, 'com.oracle.svm.test.runner.UnitTests', '-g'] + normalArgs)\n\ndef _gate_body(args, tasks):\n    t = mx_graal.Task('BuildHotSpotGraalServer: product')\n    mx_graal.buildvms(['--vms', 'server', '--builds', 'product'])\n    # make sure native projects are compiled\n    mx.build(['--source', '1.7'])\n    tasks.append(t.stop())\n\n    t = mx_graal.Task(\"Build SVM FastR image\")\n    with mx_graal.VM('server', 'product'):\n        image([])\n        tasks.append(t.stop())\n\n    t = mx_graal.Task(\"Say Hello\")\n    try:\n        hello = subprocess.check_output([_image_path(), 'Rscript', 'hello.r'])\n        if hello != '[1] \"Hello from FastR on SVM\"\\n':\n            mx.abort(\"hello test failed\")\n    except subprocess.CalledProcessError:\n        mx.abort(\"executing svm_fastr failed\")\n    tasks.append(t.stop())\n\n    t = mx_graal.Task('svmtest RFFI')\n    svmtest(['svm_truffle_r_test_SVM_RFFITests'])\n    tasks.append(t.stop())\n\ndef gate(args):\n    '''run the tests used to validate a push'''\n    # suppress the download meter\n    mx._opts.no_download_progress = True\n    # svm mx_graal.py doesn't pass pylint\n    mx.gate(args + ['-p'], _gate_body)\n\ndef mx_init(suite):\n    commands = {\n        'image' : [image, '[options]'],\n        'gate' : [gate, ''],\n        'r' : [runRCommand, '[options]'],\n        'R' : [runRCommand, '[options]'],\n        'rscript' : [runRscriptCommand, '[options]'],\n        'Rscript' : [runRscriptCommand, '[options]'],\n        'svmtest' : [svmtest, '[options]'],\n    }\n    mx.update_commands(suite, commands)\n","markers":{"markers":{"1":{"id":1,"range":[[29,13],[29,13]],"tailed":false,"reversed":true,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":2407,"goalBufferRange":null,"preserveFolds":true},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/zwei/Workspace/oracle/fastr-svm-home/svm_fastr/mx.svm_fastr/mx_svm_fastr.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"202eb56b9a0081c452a8c644122d33c0bbfceefa","deserializer":"TextBuffer"},{"text":"suite=svm_fastr\nmxversion=2.0\n\nproject@com.oracle.svm.truffle.r@sourceDirs=src\nproject@com.oracle.svm.truffle.r@dependencies=com.oracle.svm.test,com.oracle.truffle.r.shell\nproject@com.oracle.svm.truffle.r@checkstyle=com.oracle.truffle.r.runtime\nproject@com.oracle.svm.truffle.r@javaCompliance=1.8\nproject@com.oracle.svm.truffle.r@workingSets=SVM,FastR\n","markers":{"markers":{"1":{"id":1,"range":[[4,92],[4,92]],"tailed":false,"reversed":true,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":3516,"goalBufferRange":null,"preserveFolds":true},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/zwei/Workspace/oracle/fastr-svm-home/svm_fastr/mx.svm_fastr/projects","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"dac91e4db2997efffcdd189346e7755ea39cb75a","deserializer":"TextBuffer"},{"text":"#\n# Copyright (c) 2013, 2014, Oracle and/or its affiliates. All rights reserved.\n# DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n#\n# This code is free software; you can redistribute it and/or modify it\n# under the terms of the GNU General Public License version 2 only, as\n# published by the Free Software Foundation.\n#\n# This code is distributed in the hope that it will be useful, but WITHOUT\n# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n# FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n# version 2 for more details (a copy is included in the LICENSE file that\n# accompanied this code).\n#\n# You should have received a copy of the GNU General Public License version\n# 2 along with this work; if not, write to the Free Software Foundation,\n# Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n#\n# Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n# or visit www.oracle.com if you need additional information or have any\n# questions.\n#\nimport tempfile, shutil, filecmp, platform, zipfile, sys\nfrom os.path import join, sep, exists\nfrom argparse import ArgumentParser\nimport mx\nimport mx_graal\nimport os\n\n_fastr_suite = None\n\ndef _runR(args, className, nonZeroIsFatal=True, extraVmArgs=None, runBench=False):\n    # extraVmArgs is not normally necessary as the global --J option can be used running R/RScript\n    # However, the bench command invokes other Java VMs along the way, so it must use extraVmArgs\n    os.environ['R_HOME'] = _fastr_suite.dir\n    _set_libpath()\n    # Set up path for Lapack libraries\n    vmArgs = ['-cp', mx.classpath(\"com.oracle.truffle.r.shell\")]\n    if runBench == False:\n        vmArgs = vmArgs + ['-ea', '-esa']\n    if extraVmArgs:\n        vmArgs = vmArgs + extraVmArgs\n    return mx_graal.vm(vmArgs + [className] + args, nonZeroIsFatal=nonZeroIsFatal)\n\ndef runRCommand(args, nonZeroIsFatal=True, extraVmArgs=None, runBench=False):\n    '''run R shell'''\n    return _runR(args, \"com.oracle.truffle.r.shell.RCommand\", nonZeroIsFatal=nonZeroIsFatal, extraVmArgs=extraVmArgs, runBench=runBench)\n\ndef runRscriptCommand(args, nonZeroIsFatal=True):\n    '''run Rscript file'''\n    return _runR(args, \"com.oracle.truffle.r.shell.RscriptCommand\", nonZeroIsFatal=nonZeroIsFatal)\n\ndef _set_libpath():\n    osname = platform.system()\n    lib_base = join(_fastr_suite.dir, 'com.oracle.truffle.r.native', 'lib', osname.lower())\n    lib_value = lib_base\n    if osname == 'Darwin':\n        lib_env = 'DYLD_FALLBACK_LIBRARY_PATH'\n        lib_value = lib_value + os.pathsep + '/usr/lib'\n    else:\n        lib_env = 'LD_LIBRARY_PATH'\n    os.environ[lib_env] = lib_value\n\ndef findbugs(args):\n    '''run FindBugs against non-test Java projects'''\n    findBugsHome = mx.get_env('FINDBUGS_HOME', None)\n    if findBugsHome:\n        findbugsJar = join(findBugsHome, 'lib', 'findbugs.jar')\n    else:\n        findbugsLib = join(_fastr_suite.dir, 'lib', 'findbugs-3.0.0')\n        if not exists(findbugsLib):\n            tmp = tempfile.mkdtemp(prefix='findbugs-download-tmp', dir=_fastr_suite.dir)\n            try:\n                findbugsDist = join(tmp, 'findbugs.zip')\n                mx.download(findbugsDist, ['http://lafo.ssw.uni-linz.ac.at/graal-external-deps/findbugs-3.0.0.zip', 'http://sourceforge.net/projects/findbugs/files/findbugs/3.0.0/findbugs-3.0.0.zip'])\n                with zipfile.ZipFile(findbugsDist) as zf:\n                    candidates = [e for e in zf.namelist() if e.endswith('/lib/findbugs.jar')]\n                    assert len(candidates) == 1, candidates\n                    libDirInZip = os.path.dirname(candidates[0])\n                    zf.extractall(tmp)\n                shutil.copytree(join(tmp, libDirInZip), findbugsLib)\n            finally:\n                shutil.rmtree(tmp)\n        findbugsJar = join(findbugsLib, 'findbugs.jar')\n    assert exists(findbugsJar)\n    nonTestProjects = [p for p in _fastr_suite.projects if not p.name.endswith('.test') and not p.name.endswith('.processor') and not p.native]\n    outputDirs = [p.output_dir() for p in nonTestProjects]\n    findbugsResults = join(_fastr_suite.dir, 'findbugs.html')\n\n    cmd = ['-jar', findbugsJar, '-low', '-maxRank', '15', '-exclude', join(_fastr_suite.mxDir, 'findbugs-exclude.xml'), '-html']\n    if sys.stdout.isatty():\n        cmd.append('-progress')\n    cmd = cmd + ['-auxclasspath', mx.classpath([p.name for p in nonTestProjects]), '-output', findbugsResults, '-exitcode'] + args + outputDirs\n    exitcode = mx.run_java(cmd, nonZeroIsFatal=False)\n    return exitcode\n\ndef _fastr_gate_body(args, tasks):\n    _check_autogen_tests(False)\n\n    # workaround for Hotspot Mac OS X build problem\n    osname = platform.system()\n    if osname == 'Darwin':\n        os.environ['COMPILER_WARNINGS_FATAL'] = 'false'\n        os.environ['USE_CLANG'] = 'true'\n        os.environ['LFLAGS'] = '-Xlinker -lstdc++'\n\n    t = mx_graal.Task('BuildHotSpotGraalServer: product')\n    mx_graal.buildvms(['--vms', 'server', '--builds', 'product'])\n    tasks.append(t.stop())\n\n    # check that the expected test output file is up to date\n    t = mx.GateTask('UnitTests: ExpectedTestOutput file check')\n    junit(['--tests', _default_unit_tests(), '--check-expected-output'])\n    tasks.append(t.stop())\n    # temp disable\n    t = mx.GateTask('UnitTests: simple')\n    junit(['--tests', _default_unit_tests()])\n# temp disable check\n#    rc = junit(['--tests', _default_unit_tests()])\n#    if rc != 0:\n#        mx.abort('unit tests failed')\n    tasks.append(t.stop())\n\ndef gate(args):\n    '''Run the R gate'''\n    # suppress the download meter\n    mx._opts.no_download_progress = True\n\n    # ideally would be standard gate tasks - we do these early\n\n    t = mx.GateTask('Copyright check')\n    rc = mx.checkcopyrights(['--primary'])\n    t.stop()\n    if rc != 0:\n        mx.abort('copyright errors')\n\n# temp disable due to non-determinism\n#    t = mx.GateTask('FindBugs')\n#    rc = findbugs([])\n#    t.stop()\n#    if rc != 0:\n#        mx.abort('FindBugs warnings were found')\n\n    _check_autogen_tests(True)\n    mx.gate(args, _fastr_gate_body)\n\n_tempdir = None\n\ndef _check_autogen_tests(copy):\n    # make copies of AllTests and FailingTests, as these will be regenerated by the gate\n    # and may be out of sync\n    test_srcdir = _test_srcdir()\n    all_tests = join(test_srcdir, 'all', 'AllTests.java')\n    failing_tests = join(test_srcdir, 'failing', 'FailingTests.java')\n    global _tempdir\n    if copy:\n        _tempdir = tempfile.mkdtemp()\n        shutil.copy(all_tests, _tempdir)\n        shutil.copy(failing_tests, _tempdir)\n    else:\n        files_equal = filecmp.cmp(all_tests, join(_tempdir, 'AllTests.java')) and filecmp.cmp(failing_tests, join(_tempdir, 'FailingTests.java'))\n        shutil.rmtree(_tempdir)\n        if not files_equal:\n            mx.abort('AllTests.java and/or FailingTests.java are out of sync, regenerate with mx rtestgen')\n\ndef _test_srcdir():\n    tp = 'com.oracle.truffle.r.test'\n    return join(mx.project(tp).dir, 'src', tp.replace('.', sep))\n\ndef _junit_r_harness(args, vmArgs, junitArgs):\n    # always pass the directory where the expected output file should reside\n    runlistener_arg = 'expected=' + _test_srcdir()\n    # there should not be any unparsed arguments at this stage\n    if args.remainder:\n        mx.abort('unexpected arguments: ' + str(args.remainder).strip('[]') + '; did you forget --tests')\n\n    def add_arg_separator():\n        # can't update in Python 2.7\n        arg = runlistener_arg\n        if len(arg) > 0:\n            arg += ','\n        return arg\n\n    if args.gen_fastr_output:\n        runlistener_arg = add_arg_separator()\n        runlistener_arg += 'gen-fastr=' + args.gen_fastr_output\n\n    if args.check_expected_output:\n        args.gen_expected_output = True\n        runlistener_arg = add_arg_separator()\n        runlistener_arg += 'check-expected'\n\n    if args.gen_expected_output:\n        runlistener_arg = add_arg_separator()\n        runlistener_arg += 'gen-expected'\n        if args.keep_trailing_whitespace:\n            runlistener_arg = add_arg_separator()\n            runlistener_arg += 'keep-trailing-whitespace'\n\n    if args.gen_diff_output:\n        runlistener_arg = add_arg_separator()\n        runlistener_arg += 'gen-diff=' + args.gen_diff_output\n\n#    if args.test_methods:\n#        runlistener_arg = add_arg_separator()\n#        runlistener_arg = 'test-methods=' + args.test_methods\n\n    # use a custom junit.RunListener\n    runlistener = 'com.oracle.truffle.r.test.TestBase$RunListener'\n    if len(runlistener_arg) > 0:\n        runlistener += ':' + runlistener_arg\n\n    junitArgs += ['--runlistener', runlistener]\n\n    # suppress Truffle compilation by using a high threshold\n    vmArgs += ['-G:TruffleCompilationThreshold=100000']\n\n    _set_libpath()\n\n    return mx_graal.vm(vmArgs + junitArgs, vm=\"server\", nonZeroIsFatal=False)\n\ndef junit(args):\n    '''run R Junit tests'''\n    parser = ArgumentParser(prog='r junit')\n    parser.add_argument('--gen-expected-output', action='store_true', help='generate/update expected test output file')\n    parser.add_argument('--keep-trailing-whitespace', action='store_true', help='keep trailing whitespace in expected test output file')\n    parser.add_argument('--check-expected-output', action='store_true', help='check but do not update expected test output file')\n    parser.add_argument('--gen-fastr-output', action='store', metavar='<path>', help='generate FastR test output file')\n    parser.add_argument('--gen-diff-output', action='store', metavar='<path>', help='generate difference test output file ')\n    # parser.add_argument('--test-methods', action='store', help='pattern to match test methods in test classes')\n\n    if os.environ.has_key('R_PROFILE_USER'):\n        mx.abort('unset R_PROFILE_USER before running unit tests')\n\n    return mx.junit(args, _junit_r_harness, parser=parser)\n\ndef junit_simple(args):\n    return junit(['--tests', _default_unit_tests()] + args)\n\ndef _default_unit_tests():\n    return 'com.oracle.truffle.r.test.simple'\n\ndef testgen(args):\n    '''generate the expected output for unit tests, and All/Failing test classes'''\n    # clean the test project to invoke the test analyzer AP\n    testOnly = ['--projects', 'com.oracle.truffle.r.test']\n    mx.clean(['--no-dist', ] + testOnly)\n    mx.build(testOnly)\n    # now just invoke junit with the appropriate options\n    junit(args + ['--tests', _default_unit_tests(), '--gen-expected-output'])\n\ndef unittest(args):\n    print \"use 'junit --tests testclasses' or 'junitsimple' to run FastR unit tests\"\n\ndef rbcheck(args):\n    '''check FastR builtins against GnuR'''\n    parser = ArgumentParser(prog='mx rbcheck')\n    parser.add_argument('--check-internal', action='store_const', const='--check-internal', help='check .Internal functions')\n    parser.add_argument('--unknown-to-gnur', action='store_const', const='--unknown-to-gnur', help='list builtins not in GnuR FUNCTAB')\n    parser.add_argument('--todo', action='store_const', const='--todo', help='show unimplemented')\n    parser.add_argument('--no-eval-args', action='store_const', const='--no-eval-args', help='list functions that do not evaluate their args')\n    parser.add_argument('--visibility', action='store_const', const='--visibility', help='list visibility specification')\n    parser.add_argument('--printGnuRFunctions', action='store', help='ask GnuR to \"print\" value of functions')\n    args = parser.parse_args(args)\n\n    class_map = mx.project('com.oracle.truffle.r.nodes').find_classes_with_matching_source_line(None, lambda line: \"@RBuiltin\" in line, True)\n    classes = []\n    for className, path in class_map.iteritems():\n        classNameX = className.split(\"$\")[0] if '$' in className else className\n\n        if not classNameX.endswith('Factory'):\n            classes.append([className, path])\n\n    (_, testfile) = tempfile.mkstemp(\".classes\", \"mx\")\n    os.close(_)\n    with open(testfile, 'w') as f:\n        for c in classes:\n            f.write(c[0] + ',' + c[1] + '\\n')\n    analyzeArgs = []\n    if args.check_internal:\n        analyzeArgs.append(args.check_internal)\n    if args.unknown_to_gnur:\n        analyzeArgs.append(args.unknown_to_gnur)\n    if args.todo:\n        analyzeArgs.append(args.todo)\n    if args.no_eval_args:\n        analyzeArgs.append(args.no_eval_args)\n    if args.visibility:\n        analyzeArgs.append(args.visibility)\n    if args.printGnuRFunctions:\n        analyzeArgs.append('--printGnuRFunctions')\n        analyzeArgs.append(args.printGnuRFunctions)\n    analyzeArgs.append(testfile)\n    cp = mx.classpath([pcp.name for pcp in mx.projects_opt_limit_to_suites()])\n    mx.run_java(['-cp', cp, 'com.oracle.truffle.r.test.tools.AnalyzeRBuiltin'] + analyzeArgs)\n\ndef rcmplib(args):\n    '''compare FastR library R sources against GnuR'''\n    parser = ArgumentParser(prog='mx cmplibr')\n    parser.add_argument('--gnurhome', action='store', help='path to GnuR sources', required=True)\n    parser.add_argument('--lib', action='store', help='library to check', default=\"base\")\n    args = parser.parse_args(args)\n    cmpArgs = []\n    cmpArgs.append(\"--gnurhome\")\n    cmpArgs.append(args.gnurhome)\n    cmpArgs.append(\"--lib\")\n    cmpArgs.append(args.lib)\n    cp = mx.classpath([pcp.name for pcp in mx.projects_opt_limit_to_suites()])\n    mx.run_java(['-cp', cp, 'com.oracle.truffle.r.test.tools.cmpr.CompareLibR'] + cmpArgs)\n\ndef bench(args):\n    mx.abort(\"no benchmarks available\")\n\ndef mx_post_parse_cmd_line(opts):\n    # dynamically load the benchmarks suite\n    hg_base = mx.get_env('HG_BASE')\n    alternate = None if hg_base is None else join(hg_base, 'r_benchmarks')\n    bm_suite = _fastr_suite.import_suite('r_benchmarks', version=None, alternate=alternate)\n    if bm_suite:\n        mx.build_suite(bm_suite)\n\ndef mx_init(suite):\n    global _fastr_suite\n    _fastr_suite = suite\n    commands = {\n        # new commands\n        'r' : [runRCommand, '[options]'],\n        'R' : [runRCommand, '[options]'],\n        'rscript' : [runRscriptCommand, '[options]'],\n        'Rscript' : [runRscriptCommand, '[options]'],\n        'rtestgen' : [testgen, ''],\n        # core overrides\n        'bench' : [bench, ''],\n        'gate' : [gate, ''],\n        'junit' : [junit, ['options']],\n        'junitsimple' : [junit_simple, ['options']],\n        'unittest' : [unittest, ['options']],\n        'rbcheck' : [rbcheck, ['options']],\n        'rcmplib' : [rcmplib, ['options']],\n        'findbugs' : [findbugs, '']\n    }\n    mx.update_commands(suite, commands)\n","markers":{"markers":{"1":{"id":1,"range":[[0,0],[0,0]],"tailed":false,"reversed":false,"valid":true,"invalidate":"never","persistent":true,"properties":{"type":"selection","editorId":3603,"preserveFolds":true,"goalBufferRange":null},"deserializer":"Marker"}},"deserializer":"MarkerManager"},"history":{"undoStack":[],"redoStack":[],"deserializer":"History"},"filePath":"/Users/zwei/Workspace/oracle/fastr-svm-home/fastr/mx.fastr/mx_fastr.py","modifiedWhenLastPersisted":false,"digestWhenLastPersisted":"c940f52522b5ef90218bebb96f78c8f2fe9264a1","deserializer":"TextBuffer"}],"deserializer":"Project"},"workspace":{"paneContainer":{"root":{"id":3,"items":[{"id":302,"softTabs":true,"displayBuffer":{"id":303,"softWrap":true,"editorWidthInChars":null,"scrollTop":767,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/zwei/Workspace/oracle/fastr-svm-home/graal/mx/projects","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":1783,"softTabs":true,"displayBuffer":{"id":1784,"softWrap":false,"editorWidthInChars":null,"scrollTop":0,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/zwei/Workspace/oracle/fastr-svm-home/fastr/mx.fastr/projects","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":3516,"softTabs":true,"displayBuffer":{"id":3517,"softWrap":false,"editorWidthInChars":null,"scrollTop":0,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/zwei/Workspace/oracle/fastr-svm-home/svm_fastr/mx.svm_fastr/projects","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":2373,"softTabs":true,"displayBuffer":{"id":2374,"softWrap":false,"editorWidthInChars":null,"scrollTop":0,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/zwei/Workspace/oracle/fastr-svm-home/svm_fastr/mx.svm_fastr/imports","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":2407,"softTabs":true,"displayBuffer":{"id":2408,"softWrap":false,"editorWidthInChars":null,"scrollTop":112,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/zwei/Workspace/oracle/fastr-svm-home/svm_fastr/mx.svm_fastr/mx_svm_fastr.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":3603,"softTabs":true,"displayBuffer":{"id":3604,"softWrap":false,"editorWidthInChars":null,"scrollTop":3895,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/zwei/Workspace/oracle/fastr-svm-home/fastr/mx.fastr/mx_fastr.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":745,"softTabs":true,"displayBuffer":{"id":746,"softWrap":false,"editorWidthInChars":null,"scrollTop":12145,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/zwei/Workspace/oracle/fastr-svm-home/graal/mx/mx_graal.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"id":941,"softTabs":true,"displayBuffer":{"id":942,"softWrap":false,"editorWidthInChars":null,"scrollTop":2727,"scrollLeft":0,"tokenizedBuffer":{"bufferPath":"/Users/zwei/Workspace/oracle/fastr-svm-home/graal/mxtool/mx.py","tabLength":2,"deserializer":"TokenizedBuffer"},"deserializer":"DisplayBuffer"},"deserializer":"Editor"},{"deserializer":"SettingsView","version":2,"activePanelName":"Settings","uri":"atom://config"}],"activeItemUri":"atom://config","focused":false,"deserializer":"Pane"},"activePaneId":3,"deserializer":"PaneContainer","version":1},"fullScreen":false,"packagesWithActiveGrammars":["language-python"],"deserializer":"Workspace"},"packageStates":{"fuzzy-finder":{"/Users/zwei/Workspace/oracle/fastr-svm-home/graal/mx/projects":1408479454246,"/Users/zwei/Workspace/oracle/fastr-svm-home/fastr/mx.fastr/projects":1407978157352,"/Users/zwei/Workspace/oracle/fastr-svm-home/svm_fastr/mx.svm_fastr/projects":1408474692558,"/Users/zwei/Workspace/oracle/fastr-svm-home/svm_fastr/mx.svm_fastr/imports":1408480625950,"/Users/zwei/Workspace/oracle/fastr-svm-home/svm_fastr/mx.svm_fastr/mx_svm_fastr.py":1408062944897,"/Users/zwei/Workspace/oracle/fastr-svm-home/fastr/mx.fastr/mx_fastr.py":1408062760237,"/Users/zwei/Workspace/oracle/fastr-svm-home/graal/mx/mx_graal.py":1408063269166,"/Users/zwei/Workspace/oracle/fastr-svm-home/graal/mxtool/mx.py":1408480870474},"keybinding-resolver":{"attached":false},"metrics":{"sessionLength":12575},"tree-view":{"directoryExpansionStates":{"fastr":{"com.oracle.truffle.r.runtime":{},"mx.fastr":{}},"graal":{"mx":{},"mxtool":{}},"svm_fastr":{"mx.svm_fastr":{}}},"selectedPath":"/Users/zwei/Workspace/oracle/fastr-svm-home/fastr","hasFocus":true,"attached":true,"scrollLeft":0,"scrollTop":0,"width":282},"find-and-replace":{"viewState":{"findHistory":["apache_common","spec_jcommon","xalan","ganymed","daca[p","dacapo","dacapo_ecli","jruby","jruby@","lucene","library@SPEC_ANT_LAUNCHER@sha1=9c1f7dd6a21962e80ed7f720fc73e04454606e45","library@SPEC_ANT_LAUNCHER","library@JDK_TOOLS","library@JDK","jdk_tools",".ffi","svm.ffi","svm.jnr","jffi","JFFI_NATIVE","svm.jnr","jnr.posix","svm.truffle","classPath","append_to_classpath"],"replaceHistory":[],"modelState":{"useRegex":false,"inCurrentSelection":false,"caseSensitive":false}}}}}